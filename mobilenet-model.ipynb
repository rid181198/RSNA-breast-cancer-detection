{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport tensorflow as tf\n#import tensorflow_io as tfio\nimport os\nfrom tqdm import tqdm\nimport cv2\nfrom PIL import Image\nfrom joblib import Parallel, delayed\nimport gc\nfrom PIL import Image as im\nimport random\nfrom scipy import ndimage\n","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:38:22.614833Z","iopub.execute_input":"2023-02-15T12:38:22.615139Z","iopub.status.idle":"2023-02-15T12:38:29.108591Z","shell.execute_reply.started":"2023-02-15T12:38:22.615086Z","shell.execute_reply":"2023-02-15T12:38:29.107645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\n!{sys.executable} -m pip install dicomsdl\n#!pip install /kaggle/input/rsnapacks/dicomsdl-0.109.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\n#import pydicom as dicom\nimport dicomsdl as dicom\nimport tensorflow as tf\n\nfrom PIL import Image as im\nimport os\nfrom tqdm import tqdm\nimport cv2\nfrom PIL import Image\nfrom joblib import Parallel, delayed\nimport gc\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:38:29.110147Z","iopub.execute_input":"2023-02-15T12:38:29.110957Z","iopub.status.idle":"2023-02-15T12:38:39.065712Z","shell.execute_reply.started":"2023-02-15T12:38:29.110923Z","shell.execute_reply":"2023-02-15T12:38:39.064568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datasetPath = '/kaggle/input/rsna-breast-cancer-detection/train.csv'\nimgPath = '/kaggle/input/rsna-breast-cancer-detection/train_images/'\n\ndef crop(sideName, imgName):\n    \"\"\"\n    This function is used to crop the breast images. It takes two arguments.\n    \n    Input:-\n    :sideName = Laterality of breast if it is right or left\n    :imgName = Image pixel data of the DCM images\n    \n    Output:-\n    :return = Output after cropping the image.\n    \n    \"\"\"\n    if sideName == 'L':\n        colind=[]\n        for r,row in enumerate(imgName):\n            for c,col in enumerate(row):\n                if col==0:\n                    colind.append(c)\n                    break\n        crop_size = max(colind)\n        imgName = imgName[0:512,0:crop_size]\n        imgName = cv2.resize(imgName,(128,128))\n        \n    if sideName == 'R':\n        colind=[]\n        for r,row in enumerate(imgName):\n            for c,col in enumerate(row):\n                if col!=0:\n                    colind.append(c)\n                    break\n        crop_size = min(colind)\n        imgName = imgName[0:512,crop_size:512]\n        imgName = cv2.resize(imgName,(128,128))\n    \n    return imgName    \n\n    gc.collect()\n    \ndef crop_reverse(sideName, imgName):\n    \n    \"\"\"\n    This function is used to crop the breast images but in the reverse order.\n    Because the laterality is defined wrongly for some images. It takes two arguments.\n    \n    Input:-\n    :sideName = Laterality of breast if it is right or left\n    :imgName = Image pixel data of the DCM images\n    \n    Output:-\n    :return = Output after cropping the image.\n    \n    \"\"\"\n    \n    if sideName == 'R':\n        colind=[]\n        for r,row in enumerate(imgName):\n            for c,col in enumerate(row):\n                if col==0:\n                    colind.append(c)\n                    break\n        crop_size = max(colind)\n        imgName = imgName[0:512,0:crop_size]\n        imgName = cv2.resize(imgName,(128,128))\n        \n    if sideName == 'L':\n        colind=[]\n        for r,row in enumerate(imgName):\n            for c,col in enumerate(row):\n                if col!=0:\n                    colind.append(c)\n                    break\n        crop_size = min(colind)\n        imgName = imgName[0:512,crop_size:512]\n        imgName = cv2.resize(imgName,(128,128))\n    \n    return imgName    \n\n    gc.collect()\n    \n\ndef img_process(i,filename,sides):\n    \n    \"\"\"\n    This function is used to process the images which will be used for the training/test dataset. It takes three arguments.\n    \n    Input:-\n    :i = Index of the image in the dataframe\n    :filename = Path of the image\n    :sides = List of all images' laterality\n    \n    Output:-\n    :return = Output after cropping the image.\n    \n    \"\"\"\n    \n    \n    #ds = dicom.dcmread(filename)\n    dsraw = dicom.open(filename)\n    ds = dsraw.pixelData()\n    \n    ds = (ds - ds.min()) / (ds.max() - ds.min())\n    if dsraw.PhotometricInterpretation == \"MONOCHROME1\":  \n        ds = 1 - ds\n    ds = (ds * 255).astype(np.uint8)\n\n    \n    #ds = cv2.normalize(ds, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    ds = cv2.resize(ds,(512,512))\n    \n    #ds = np.where(ds >= 0.999, 0,ds)\n    \n    try:\n        ds = np.array(crop(sides[i], ds))   \n    except:\n        ds = np.array(crop_reverse(sides[i], ds))\n    \n\n    #train_data.loc[i,'img_data'] = [img_fin]\n    #train_data.to_csv('/kaggle/working/training_img_data.csv') \n    return ds\n    gc.collect()\n\ndef dcmToPix(datasetPath, imgPath):\n    \n    \"\"\"\n    This function is used to process all the images which will be used for the training/test dataset. It takes two arguments.\n    \n    Input:-\n    :datasetPath = Path of the cancer dataset\n    :imgPath = Path of the image dataset\n   \n    Output:-\n    :return = Array of all the processed images\n    \n    \"\"\"\n    \n    \n    dataset = pd.read_csv(datasetPath)\n    \n    patient_ids = dataset['patient_id']\n    image_ids = dataset['image_id']\n    sides  = dataset['laterality']\n\n    imgData = []\n\n    for pi, ii, leng in zip(patient_ids, image_ids, range(len(patient_ids))):\n        imgData.append(imgPath + str(pi) + '/' + str(ii) + '.dcm')\n\n    dataset['img_data'] = \" \"\n    \n    result = Parallel(n_jobs=128)(\\\n    delayed(img_process)(i, fname, sides) for i, fname in zip(range(len(imgData)),tqdm(imgData))\\\n    )\n    \n    dataset['img_data'] = result\n    dataset.to_pickle('imgData.pkl' )\n    \n    return result\n    ","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:38:39.067636Z","iopub.execute_input":"2023-02-15T12:38:39.067926Z","iopub.status.idle":"2023-02-15T12:38:39.091680Z","shell.execute_reply.started":"2023-02-15T12:38:39.067894Z","shell.execute_reply":"2023-02-15T12:38:39.090728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with (open('/kaggle/input/output/imgData.pkl', \"rb\")) as openfile:\n     imgData = pickle.load(openfile)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-15T12:38:39.095793Z","iopub.execute_input":"2023-02-15T12:38:39.096132Z","iopub.status.idle":"2023-02-15T12:38:58.931499Z","shell.execute_reply.started":"2023-02-15T12:38:39.096075Z","shell.execute_reply":"2023-02-15T12:38:58.930696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#datacancer = pd.read_csv(datasetPath)\n#imgDataFrame = {'cancer':datacancer['cancer'][:50], 'img_data':imgData}\n#imgData2 = pd.DataFrame(imgDataFrame)\n\n#imgData=imgData2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgdata_pos = imgData[imgData['cancer'] == 1]\nimgdata_neg = imgData[imgData['cancer'] == 0]\n\nimgdata_pos = imgdata_pos.sample(frac = 1)\nimgdata_neg = imgdata_neg.sample(frac = 1)\n\nimgdata_neg = imgdata_neg.sample(frac= 1)\n\nframes = 2*[imgdata_pos]\nframes.append(imgdata_neg)\nimgdata_shuff = pd.concat(frames)\nimgdata_shuff = imgdata_shuff.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:38:58.932552Z","iopub.execute_input":"2023-02-15T12:38:58.932760Z","iopub.status.idle":"2023-02-15T12:38:59.054806Z","shell.execute_reply.started":"2023-02-15T12:38:58.932735Z","shell.execute_reply":"2023-02-15T12:38:59.053968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(imgdata_shuff['cancer'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:38:59.055837Z","iopub.execute_input":"2023-02-15T12:38:59.056103Z","iopub.status.idle":"2023-02-15T12:38:59.067441Z","shell.execute_reply.started":"2023-02-15T12:38:59.056062Z","shell.execute_reply":"2023-02-15T12:38:59.066563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\n\ndef random_rotate(imgData):\n    #thresh = 0.15\n    \n    imgData = imgData.reshape(128,128)\n    \n    \n    \n    clahe = cv2.createCLAHE(clipLimit=3, tileGridSize=(8,8))\n    imgData = cv2.equalizeHist(clahe.apply(imgData))\n    \n    #pca = PCA(25)\n    #imgData = pca.fit_transform(imgData)\n    #imgData = pca.inverse_transform(imgData)\n    \n    \n    imgData = ndimage.rotate(imgData, random.randint(-30, 30), reshape=False)\n\n    #imgData = np.clip(imgData,thresh,1)\n    imgData = imgData[15:110,15:110]\n    \n    #imgData = cv2.resize(imgData,(528,528))\n    \n    \n    #imgData = im.fromarray(imgData)\n    #imgData = np.asarray(imgData.rotate(random.randint(-20, 20)))\n    return imgData","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:39:32.861393Z","iopub.execute_input":"2023-02-15T12:39:32.861744Z","iopub.status.idle":"2023-02-15T12:39:33.066750Z","shell.execute_reply.started":"2023-02-15T12:39:32.861709Z","shell.execute_reply":"2023-02-15T12:39:33.065900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgDataList=[]\nfor j in tqdm(imgdata_shuff['img_data']):\n    imgDataList.append(random_rotate(j))\nimgdata_shuff['img_data'] = imgDataList","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:39:34.922552Z","iopub.execute_input":"2023-02-15T12:39:34.922857Z","iopub.status.idle":"2023-02-15T12:43:44.142760Z","shell.execute_reply.started":"2023-02-15T12:39:34.922828Z","shell.execute_reply":"2023-02-15T12:43:44.140432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain,test = train_test_split(imgdata_shuff, test_size=0.3, random_state=42, shuffle=True)\n\n\n\ntrain_target = np.array(train['cancer'])\ntrain_features=[]\nfor i in train['img_data']:\n    i=np.array(i)\n    train_features.append(i)\ntrain_features=np.array(train_features)\n\n\n\n#featureTransform = train_features.reshape(len(train_features), 6400)\n\n#from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n#featureTransform = scaler.fit_transform(featureTransform)\nnorm_features= []\nfor i in range(len(train_features)):\n        norm_features.append(scaler.fit_transform(train_features[i]))\ntrain_features=np.array(norm_features)\n\n\n\n\n#backTransform = featureTransform.reshape(len(train_features),80,80)\n#train_features = backTransform.reshape(len(train_features),80,80,1)\ntrain_features = train_features.reshape(len(train_features),95,95,1)\n#train_features = np.repeat(train_features[..., np.newaxis], 3, -1)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:44:14.750489Z","iopub.execute_input":"2023-02-15T12:44:14.750794Z","iopub.status.idle":"2023-02-15T12:44:38.970310Z","shell.execute_reply.started":"2023-02-15T12:44:14.750764Z","shell.execute_reply":"2023-02-15T12:44:38.968231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten,\\\nDepthwiseConv2D, MaxPooling2D, Dropout, BatchNormalization,\\\nGlobalAveragePooling2D, ReLU, Input\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nimport tensorflow as tf\nfrom tensorflow import keras\n\n\ndef depth_block(x, strides):\n    x = DepthwiseConv2D(3,strides=strides,padding='same',  use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    return x\ndef single_conv_block(x,filters):\n    x = Conv2D(filters, 1,use_bias=False)(x)\n    x= BatchNormalization()(x)\n    x = ReLU()(x)\n    return x\ndef combo_layer(x,filters,strides):\n    x = depth_block(x,strides)\n    x = single_conv_block(x, filters)\n    return x\n\n\ndef MobileNet(input_shape=(224,224,3),n_classes = 1000):\n    input = Input(input_shape)\n    x = Conv2D(32,3,strides=(2,2),padding = 'same', use_bias=False)(input)\n    x =  BatchNormalization()(x)\n    x = ReLU()(x)\n    x = combo_layer(x,64, strides=(1,1))\n    x = combo_layer(x,128,strides=(2,2))\n    x = combo_layer(x,128,strides=(1,1))\n    x = combo_layer(x,256,strides=(2,2))\n    x = combo_layer(x,256,strides=(1,1))\n    x = combo_layer(x,512,strides=(2,2))\n    for _ in range(5):\n        x = combo_layer(x,512,strides=(1,1))\n    x = combo_layer(x,1024,strides=(2,2))\n    x = combo_layer(x,1024,strides=(1,1))\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(512,activation='relu')(x)\n    output = Dense(n_classes,activation='sigmoid')(x)\n    \n    model = tf.keras.Model(input, output)\n    return model\n\nn_classes = 1\ninput_shape = (95,95,1)\n\n\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\nwith tpu_strategy.scope():\n    model = MobileNet(input_shape,n_classes)\n\n\n    model.compile(\\\n        loss=\"binary_crossentropy\",\\\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\\\n        metrics=[\"acc\"],\\\n    )\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:46:27.102369Z","iopub.execute_input":"2023-02-15T12:46:27.103285Z","iopub.status.idle":"2023-02-15T12:46:36.151879Z","shell.execute_reply.started":"2023-02-15T12:46:27.103238Z","shell.execute_reply":"2023-02-15T12:46:36.150894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:46:36.153973Z","iopub.execute_input":"2023-02-15T12:46:36.154356Z","iopub.status.idle":"2023-02-15T12:46:36.193404Z","shell.execute_reply.started":"2023-02-15T12:46:36.154321Z","shell.execute_reply":"2023-02-15T12:46:36.190814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from tensorflow import keras\n#model = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#datagen = ImageDataGenerator(\\\n#    rescale=1/255,\\\n#    validation_split=0.10,\\\n#    rotation_range=40,\\\n#    width_shift_range=0.2,\\\n#    height_shift_range=0.2,\\\n#    shear_range=0.2,\\\n#    zoom_range=0.2,\\\n#    horizontal_flip=True,\\\n#    fill_mode='nearest'\\\n#)\n\n\n#datagen.fit(train_features)\n#weights = {0:1, 1:6.5}\n\n\n\nmodel.fit(train_features, train_target,batch_size=64,validation_split=0.3,\\\n           epochs=200)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:48:05.636076Z","iopub.execute_input":"2023-02-15T12:48:05.636465Z","iopub.status.idle":"2023-02-15T12:49:32.628583Z","shell.execute_reply.started":"2023-02-15T12:48:05.636429Z","shell.execute_reply":"2023-02-15T12:49:32.627188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"/kaggle/working/trained_model_breast_cancer3.h5\")\n","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:36:37.626226Z","iopub.execute_input":"2023-02-15T12:36:37.627180Z","iopub.status.idle":"2023-02-15T12:36:39.048200Z","shell.execute_reply.started":"2023-02-15T12:36:37.627137Z","shell.execute_reply":"2023-02-15T12:36:39.047059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from tensorflow import keras\n#savedModel = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features=[]\nfor i in test['img_data']:\n    i=np.array(i)\n    test_features.append(i)\ntest_features=np.array(test_features)\n \n\n    \n#featureTransform = test_features.reshape(len(test_features), 6400)\nscaler = MinMaxScaler()\n#featureTransform =scaler.fit_transform(featureTransform)\nnorm_features= []\nfor i in range(len(test_features)):\n    norm_features.append(scaler.fit_transform(test_features[i]))\ntest_features=np.array(norm_features)\n\n\n#backTransform = featureTransform.reshape(len(test_features),80,80)\ntest_features = test_features.reshape(len(test_features),95,95,1)\n\n\n\n\n\ntest_target = np.array(test['cancer'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npred = model.predict(test_features)\nbin_pred = []\nfor i in pred:\n    if i>=0.5:\n        bin_pred.append(1)\n    else:\n        bin_pred.append(0)\nbin_pred = np.array(bin_pred)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nacc = sklearn.metrics.accuracy_score(test_target, bin_pred)\nprint(acc)\n\ncountzero=0\ncountone=0\ncountzerot=0\ncountonet=0\nfor i, j in zip(test_target, bin_pred):\n    if i==0 and j==0:\n        countzero+=1\n    if i==1 and j==1:\n        countone+=1\n    if i==1:\n        countonet+=1\n    if i==0:\n        countzerot+=1\nprint(countzero/countzerot,countone/countonet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef recall_m(y_true, y_pred):\n    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n    possible_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives )\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives )\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall))\n\n\nprint(f1_m(test_target,bin_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}