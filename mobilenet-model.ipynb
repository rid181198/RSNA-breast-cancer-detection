{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daba28d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:14:03.148895Z",
     "iopub.status.busy": "2023-02-16T01:14:03.148062Z",
     "iopub.status.idle": "2023-02-16T01:14:10.500686Z",
     "shell.execute_reply": "2023-02-16T01:14:10.499975Z",
     "shell.execute_reply.started": "2023-02-16T01:12:30.095907Z"
    },
    "papermill": {
     "duration": 7.385519,
     "end_time": "2023-02-16T01:14:10.500875",
     "exception": false,
     "start_time": "2023-02-16T01:14:03.115356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 01:14:04.958869: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2023-02-16 01:14:04.959001: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "#import tensorflow_io as tfio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "from PIL import Image as im\n",
    "import random\n",
    "from scipy import ndimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9267b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:14:10.540756Z",
     "iopub.status.busy": "2023-02-16T01:14:10.539996Z",
     "iopub.status.idle": "2023-02-16T01:14:20.959715Z",
     "shell.execute_reply": "2023-02-16T01:14:20.960220Z",
     "shell.execute_reply.started": "2023-02-16T01:12:37.629546Z"
    },
    "papermill": {
     "duration": 10.441043,
     "end_time": "2023-02-16T01:14:20.960422",
     "exception": false,
     "start_time": "2023-02-16T01:14:10.519379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dicomsdl\r\n",
      "  Downloading dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.4 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 2.1 MB/s \r\n",
      "\u001b[?25hInstalling collected packages: dicomsdl\r\n",
      "Successfully installed dicomsdl-0.109.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install dicomsdl\n",
    "#!pip install /kaggle/input/rsnapacks/dicomsdl-0.109.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "#import pydicom as dicom\n",
    "import dicomsdl as dicom\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image as im\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f28dd2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:14:21.022831Z",
     "iopub.status.busy": "2023-02-16T01:14:21.021865Z",
     "iopub.status.idle": "2023-02-16T01:14:21.024804Z",
     "shell.execute_reply": "2023-02-16T01:14:21.024193Z",
     "shell.execute_reply.started": "2023-02-16T01:12:46.201563Z"
    },
    "papermill": {
     "duration": 0.045643,
     "end_time": "2023-02-16T01:14:21.024958",
     "exception": false,
     "start_time": "2023-02-16T01:14:20.979315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasetPath = '/kaggle/input/rsna-breast-cancer-detection/train.csv'\n",
    "imgPath = '/kaggle/input/rsna-breast-cancer-detection/train_images/'\n",
    "\n",
    "def crop(sideName, imgName):\n",
    "    \"\"\"\n",
    "    This function is used to crop the breast images. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :sideName = Laterality of breast if it is right or left\n",
    "    :imgName = Image pixel data of the DCM images\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    if sideName == 'L':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col==0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = max(colind)\n",
    "        imgName = imgName[0:512,0:crop_size]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "        \n",
    "    if sideName == 'R':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col!=0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = min(colind)\n",
    "        imgName = imgName[0:512,crop_size:512]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "    \n",
    "    return imgName    \n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "def crop_reverse(sideName, imgName):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to crop the breast images but in the reverse order.\n",
    "    Because the laterality is defined wrongly for some images. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :sideName = Laterality of breast if it is right or left\n",
    "    :imgName = Image pixel data of the DCM images\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if sideName == 'R':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col==0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = max(colind)\n",
    "        imgName = imgName[0:512,0:crop_size]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "        \n",
    "    if sideName == 'L':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col!=0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = min(colind)\n",
    "        imgName = imgName[0:512,crop_size:512]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "    \n",
    "    return imgName    \n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "def img_process(i,filename,sides):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to process the images which will be used for the training/test dataset. It takes three arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :i = Index of the image in the dataframe\n",
    "    :filename = Path of the image\n",
    "    :sides = List of all images' laterality\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #ds = dicom.dcmread(filename)\n",
    "    dsraw = dicom.open(filename)\n",
    "    ds = dsraw.pixelData()\n",
    "    \n",
    "    ds = (ds - ds.min()) / (ds.max() - ds.min())\n",
    "    if dsraw.PhotometricInterpretation == \"MONOCHROME1\":  \n",
    "        ds = 1 - ds\n",
    "    ds = (ds * 255).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    #ds = cv2.normalize(ds, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    ds = cv2.resize(ds,(512,512))\n",
    "    \n",
    "    #ds = np.where(ds >= 0.999, 0,ds)\n",
    "    \n",
    "    try:\n",
    "        ds = np.array(crop(sides[i], ds))   \n",
    "    except:\n",
    "        ds = np.array(crop_reverse(sides[i], ds))\n",
    "    \n",
    "\n",
    "    #train_data.loc[i,'img_data'] = [img_fin]\n",
    "    #train_data.to_csv('/kaggle/working/training_img_data.csv') \n",
    "    return ds\n",
    "    gc.collect()\n",
    "\n",
    "def dcmToPix(datasetPath, imgPath):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to process all the images which will be used for the training/test dataset. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :datasetPath = Path of the cancer dataset\n",
    "    :imgPath = Path of the image dataset\n",
    "   \n",
    "    Output:-\n",
    "    :return = Array of all the processed images\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    dataset = pd.read_csv(datasetPath)\n",
    "    \n",
    "    patient_ids = dataset['patient_id']\n",
    "    image_ids = dataset['image_id']\n",
    "    sides  = dataset['laterality']\n",
    "\n",
    "    imgData = []\n",
    "\n",
    "    for pi, ii, leng in zip(patient_ids, image_ids, range(len(patient_ids))):\n",
    "        imgData.append(imgPath + str(pi) + '/' + str(ii) + '.dcm')\n",
    "\n",
    "    dataset['img_data'] = \" \"\n",
    "    \n",
    "    result = Parallel(n_jobs=128)(\\\n",
    "    delayed(img_process)(i, fname, sides) for i, fname in zip(range(len(imgData)),tqdm(imgData))\\\n",
    "    )\n",
    "    \n",
    "    dataset['img_data'] = result\n",
    "    dataset.to_pickle('imgData.pkl' )\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc8d469b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-16T01:14:21.068621Z",
     "iopub.status.busy": "2023-02-16T01:14:21.067882Z",
     "iopub.status.idle": "2023-02-16T01:14:31.164710Z",
     "shell.execute_reply": "2023-02-16T01:14:31.163215Z",
     "shell.execute_reply.started": "2023-02-16T01:12:46.224706Z"
    },
    "papermill": {
     "duration": 10.12156,
     "end_time": "2023-02-16T01:14:31.165022",
     "exception": false,
     "start_time": "2023-02-16T01:14:21.043462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with (open('/kaggle/input/output/imgData.pkl', \"rb\")) as openfile:\n",
    "     imgData = pickle.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6704e20f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:14:31.210461Z",
     "iopub.status.busy": "2023-02-16T01:14:31.208728Z",
     "iopub.status.idle": "2023-02-16T01:14:31.211251Z",
     "shell.execute_reply": "2023-02-16T01:14:31.211766Z"
    },
    "papermill": {
     "duration": 0.027018,
     "end_time": "2023-02-16T01:14:31.211958",
     "exception": false,
     "start_time": "2023-02-16T01:14:31.184940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#datacancer = pd.read_csv(datasetPath)\n",
    "#imgDataFrame = {'cancer':datacancer['cancer'][:50], 'img_data':imgData}\n",
    "#imgData2 = pd.DataFrame(imgDataFrame)\n",
    "\n",
    "#imgData=imgData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e1c62d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:14:31.268920Z",
     "iopub.status.busy": "2023-02-16T01:14:31.267469Z",
     "iopub.status.idle": "2023-02-16T01:14:31.392854Z",
     "shell.execute_reply": "2023-02-16T01:14:31.391451Z",
     "shell.execute_reply.started": "2023-02-16T01:13:17.835955Z"
    },
    "papermill": {
     "duration": 0.160616,
     "end_time": "2023-02-16T01:14:31.393020",
     "exception": false,
     "start_time": "2023-02-16T01:14:31.232404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgdata_pos = imgData[imgData['cancer'] == 1]\n",
    "imgdata_neg = imgData[imgData['cancer'] == 0]\n",
    "\n",
    "imgdata_pos = imgdata_pos.sample(frac = 1)\n",
    "imgdata_neg = imgdata_neg.sample(frac = 1)\n",
    "\n",
    "imgdata_neg = imgdata_neg.sample(frac= 0.55)\n",
    "\n",
    "frames = 25*[imgdata_pos]\n",
    "frames.append(imgdata_neg)\n",
    "imgdata_shuff = pd.concat(frames)\n",
    "imgdata_shuff = imgdata_shuff.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e82537",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:14:31.447251Z",
     "iopub.status.busy": "2023-02-16T01:14:31.444997Z",
     "iopub.status.idle": "2023-02-16T01:14:31.449921Z",
     "shell.execute_reply": "2023-02-16T01:14:31.449353Z",
     "shell.execute_reply.started": "2023-02-16T01:13:19.041949Z"
    },
    "papermill": {
     "duration": 0.037389,
     "end_time": "2023-02-16T01:14:31.450067",
     "exception": false,
     "start_time": "2023-02-16T01:14:31.412678",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    29451\n",
      "1    28950\n",
      "Name: cancer, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(imgdata_shuff['cancer'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1940cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:14:31.496663Z",
     "iopub.status.busy": "2023-02-16T01:14:31.495622Z",
     "iopub.status.idle": "2023-02-16T01:14:31.934137Z",
     "shell.execute_reply": "2023-02-16T01:14:31.933596Z",
     "shell.execute_reply.started": "2023-02-15T12:39:32.861709Z"
    },
    "papermill": {
     "duration": 0.464522,
     "end_time": "2023-02-16T01:14:31.934293",
     "exception": false,
     "start_time": "2023-02-16T01:14:31.469771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def random_rotate(imgData):\n",
    "    #thresh = 0.15\n",
    "    \n",
    "    imgData = imgData.reshape(128,128)\n",
    "    \n",
    "    \n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=3, tileGridSize=(8,8))\n",
    "    imgData = cv2.equalizeHist(clahe.apply(imgData))\n",
    "    \n",
    "    #pca = PCA(25)\n",
    "    #imgData = pca.fit_transform(imgData)\n",
    "    #imgData = pca.inverse_transform(imgData)\n",
    "    \n",
    "    \n",
    "    imgData = ndimage.rotate(imgData, random.randint(-30, 30), reshape=False)\n",
    "\n",
    "    #imgData = np.clip(imgData,thresh,1)\n",
    "    imgData = imgData[15:110,15:110]\n",
    "    \n",
    "    #imgData = cv2.resize(imgData,(528,528))\n",
    "    \n",
    "    \n",
    "    #imgData = im.fromarray(imgData)\n",
    "    #imgData = np.asarray(imgData.rotate(random.randint(-20, 20)))\n",
    "    return imgData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bda5e44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:14:31.978929Z",
     "iopub.status.busy": "2023-02-16T01:14:31.978132Z",
     "iopub.status.idle": "2023-02-16T01:18:20.005784Z",
     "shell.execute_reply": "2023-02-16T01:18:20.005167Z",
     "shell.execute_reply.started": "2023-02-15T12:39:34.922828Z"
    },
    "papermill": {
     "duration": 228.052432,
     "end_time": "2023-02-16T01:18:20.005956",
     "exception": false,
     "start_time": "2023-02-16T01:14:31.953524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58401/58401 [03:48<00:00, 256.14it/s]\n"
     ]
    }
   ],
   "source": [
    "imgDataList=[]\n",
    "for j in tqdm(imgdata_shuff['img_data']):\n",
    "    imgDataList.append(random_rotate(j))\n",
    "imgdata_shuff['img_data'] = imgDataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d2a8ce9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:18:21.298424Z",
     "iopub.status.busy": "2023-02-16T01:18:21.297737Z",
     "iopub.status.idle": "2023-02-16T01:18:35.852934Z",
     "shell.execute_reply": "2023-02-16T01:18:35.852277Z",
     "shell.execute_reply.started": "2023-02-15T12:44:14.750764Z"
    },
    "papermill": {
     "duration": 15.209304,
     "end_time": "2023-02-16T01:18:35.853096",
     "exception": false,
     "start_time": "2023-02-16T01:18:20.643792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test = train_test_split(imgdata_shuff, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "train_target = np.array(train['cancer'])\n",
    "train_features=[]\n",
    "for i in train['img_data']:\n",
    "    i=np.array(i)\n",
    "    train_features.append(i)\n",
    "train_features=np.array(train_features)\n",
    "\n",
    "\n",
    "\n",
    "#featureTransform = train_features.reshape(len(train_features), 6400)\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#featureTransform = scaler.fit_transform(featureTransform)\n",
    "norm_features= []\n",
    "for i in range(len(train_features)):\n",
    "        norm_features.append(scaler.fit_transform(train_features[i]))\n",
    "train_features=np.array(norm_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#backTransform = featureTransform.reshape(len(train_features),80,80)\n",
    "#train_features = backTransform.reshape(len(train_features),80,80,1)\n",
    "train_features = train_features.reshape(len(train_features),95,95,1)\n",
    "#train_features = np.repeat(train_features[..., np.newaxis], 3, -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10de4963",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:18:37.196990Z",
     "iopub.status.busy": "2023-02-16T01:18:37.195915Z",
     "iopub.status.idle": "2023-02-16T01:18:45.905801Z",
     "shell.execute_reply": "2023-02-16T01:18:45.905174Z",
     "shell.execute_reply.started": "2023-02-15T12:46:27.103238Z"
    },
    "papermill": {
     "duration": 9.349412,
     "end_time": "2023-02-16T01:18:45.905976",
     "exception": false,
     "start_time": "2023-02-16T01:18:36.556564",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 01:18:37.209189: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-16 01:18:37.212910: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n",
      "2023-02-16 01:18:37.212955: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-16 01:18:37.212985: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (73e3f126b105): /proc/driver/nvidia/version does not exist\n",
      "2023-02-16 01:18:37.216428: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-16 01:18:37.218430: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-16 01:18:37.225069: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-02-16 01:18:37.252583: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2023-02-16 01:18:37.252643: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30019}\n",
      "2023-02-16 01:18:37.279704: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n",
      "2023-02-16 01:18:37.279791: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30019}\n",
      "2023-02-16 01:18:37.281403: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30019\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten,\\\n",
    "DepthwiseConv2D, MaxPooling2D, Dropout, BatchNormalization,\\\n",
    "GlobalAveragePooling2D, ReLU, Input\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "def depth_block(x, strides):\n",
    "    x = DepthwiseConv2D(3,strides=strides,padding='same',  use_bias=False)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "def single_conv_block(x,filters):\n",
    "    x = Conv2D(filters, 1,use_bias=False)(x)\n",
    "    x= BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    return x\n",
    "def combo_layer(x,filters,strides):\n",
    "    x = depth_block(x,strides)\n",
    "    x = single_conv_block(x, filters)\n",
    "    return x\n",
    "\n",
    "\n",
    "def MobileNet(input_shape=(224,224,3),n_classes = 1000):\n",
    "    input = Input(input_shape)\n",
    "    x = Conv2D(32,3,strides=(2,2),padding = 'same', use_bias=False)(input)\n",
    "    x =  BatchNormalization()(x)\n",
    "    x = ReLU()(x)\n",
    "    x = combo_layer(x,64, strides=(1,1))\n",
    "    x = combo_layer(x,128,strides=(2,2))\n",
    "    x = combo_layer(x,128,strides=(1,1))\n",
    "    x = combo_layer(x,256,strides=(2,2))\n",
    "    x = combo_layer(x,256,strides=(1,1))\n",
    "    x = combo_layer(x,512,strides=(2,2))\n",
    "    for _ in range(5):\n",
    "        x = combo_layer(x,512,strides=(1,1))\n",
    "    x = combo_layer(x,1024,strides=(2,2))\n",
    "    x = combo_layer(x,1024,strides=(1,1))\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512,activation='relu')(x)\n",
    "    output = Dense(n_classes,activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.Model(input, output)\n",
    "    return model\n",
    "\n",
    "n_classes = 1\n",
    "input_shape = (95,95,1)\n",
    "\n",
    "\n",
    "\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n",
    "# instantiate a distribution strategy\n",
    "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "with tpu_strategy.scope():\n",
    "    model = MobileNet(input_shape,n_classes)\n",
    "\n",
    "\n",
    "    model.compile(\\\n",
    "        loss=\"binary_crossentropy\",\\\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\\\n",
    "        metrics=[\"acc\"],\\\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3ea8c60",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:18:47.182101Z",
     "iopub.status.busy": "2023-02-16T01:18:47.177745Z",
     "iopub.status.idle": "2023-02-16T01:18:47.226810Z",
     "shell.execute_reply": "2023-02-16T01:18:47.226065Z",
     "shell.execute_reply.started": "2023-02-15T12:46:36.154321Z"
    },
    "papermill": {
     "duration": 0.688686,
     "end_time": "2023-02-16T01:18:47.227048",
     "exception": false,
     "start_time": "2023-02-16T01:18:46.538362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 95, 95, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 48, 48, 32)        288       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d (DepthwiseC (None, 48, 48, 32)        288       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        2048      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_1 (Depthwis (None, 24, 24, 64)        576       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       8192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_4 (ReLU)               (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_2 (Depthwis (None, 24, 24, 128)       1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_5 (ReLU)               (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 24, 24, 128)       16384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_6 (ReLU)               (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_3 (Depthwis (None, 12, 12, 128)       1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_7 (ReLU)               (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 256)       32768     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_8 (ReLU)               (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_4 (Depthwis (None, 12, 12, 256)       2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_9 (ReLU)               (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 256)       65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_10 (ReLU)              (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_5 (Depthwis (None, 6, 6, 256)         2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "re_lu_11 (ReLU)              (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 6, 6, 512)         131072    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_12 (ReLU)              (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_6 (Depthwis (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_13 (ReLU)              (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_14 (ReLU)              (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_7 (Depthwis (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_15 (ReLU)              (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_16 (ReLU)              (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_8 (Depthwis (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_17 (ReLU)              (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_18 (ReLU)              (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_9 (Depthwis (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_19 (ReLU)              (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_20 (ReLU)              (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_10 (Depthwi (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_21 (ReLU)              (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_22 (ReLU)              (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_11 (Depthwi (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "re_lu_23 (ReLU)              (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 3, 3, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_24 (ReLU)              (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_12 (Depthwi (None, 3, 3, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_25 (ReLU)              (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 3, 3, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "re_lu_26 (ReLU)              (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,753,601\n",
      "Trainable params: 3,731,713\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb1be735",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:18:48.538004Z",
     "iopub.status.busy": "2023-02-16T01:18:48.537272Z",
     "iopub.status.idle": "2023-02-16T01:18:48.540301Z",
     "shell.execute_reply": "2023-02-16T01:18:48.539791Z"
    },
    "papermill": {
     "duration": 0.65519,
     "end_time": "2023-02-16T01:18:48.540453",
     "exception": false,
     "start_time": "2023-02-16T01:18:47.885263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "#model = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a9579f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:18:49.844680Z",
     "iopub.status.busy": "2023-02-16T01:18:49.843705Z",
     "iopub.status.idle": "2023-02-16T01:59:11.587446Z",
     "shell.execute_reply": "2023-02-16T01:59:11.586804Z",
     "shell.execute_reply.started": "2023-02-15T12:48:05.636429Z"
    },
    "papermill": {
     "duration": 2422.416029,
     "end_time": "2023-02-16T01:59:11.587646",
     "exception": false,
     "start_time": "2023-02-16T01:18:49.171617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 01:18:50.395514: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1033037600 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "448/448 [==============================] - 42s 54ms/step - loss: 0.6989 - acc: 0.5220 - val_loss: 0.7479 - val_acc: 0.5077\n",
      "Epoch 2/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.6917 - acc: 0.5369 - val_loss: 0.6999 - val_acc: 0.5247\n",
      "Epoch 3/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.6874 - acc: 0.5409 - val_loss: 0.7628 - val_acc: 0.5303\n",
      "Epoch 4/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.6864 - acc: 0.5497 - val_loss: 0.6923 - val_acc: 0.5420\n",
      "Epoch 5/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.6816 - acc: 0.5576 - val_loss: 0.7372 - val_acc: 0.5409\n",
      "Epoch 6/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.6720 - acc: 0.5784 - val_loss: 0.7513 - val_acc: 0.5354\n",
      "Epoch 7/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.6670 - acc: 0.5874 - val_loss: 0.7203 - val_acc: 0.5235\n",
      "Epoch 8/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.6584 - acc: 0.6025 - val_loss: 0.7619 - val_acc: 0.5389\n",
      "Epoch 9/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.6456 - acc: 0.6249 - val_loss: 0.7248 - val_acc: 0.5522\n",
      "Epoch 10/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.6315 - acc: 0.6410 - val_loss: 0.7338 - val_acc: 0.5516\n",
      "Epoch 11/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.6139 - acc: 0.6589 - val_loss: 0.7132 - val_acc: 0.5528\n",
      "Epoch 12/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.5913 - acc: 0.6867 - val_loss: 0.7258 - val_acc: 0.5579\n",
      "Epoch 13/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.5730 - acc: 0.7021 - val_loss: 0.7699 - val_acc: 0.5563\n",
      "Epoch 14/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.5527 - acc: 0.7183 - val_loss: 0.8014 - val_acc: 0.5585\n",
      "Epoch 15/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.5239 - acc: 0.7418 - val_loss: 0.7678 - val_acc: 0.5650\n",
      "Epoch 16/200\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 0.4966 - acc: 0.7615 - val_loss: 0.8176 - val_acc: 0.5696\n",
      "Epoch 17/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.4681 - acc: 0.7797 - val_loss: 0.8259 - val_acc: 0.5754\n",
      "Epoch 18/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.4482 - acc: 0.7921 - val_loss: 0.9345 - val_acc: 0.5621\n",
      "Epoch 19/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.4236 - acc: 0.8057 - val_loss: 0.8913 - val_acc: 0.5808\n",
      "Epoch 20/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.4008 - acc: 0.8164 - val_loss: 0.9116 - val_acc: 0.5868\n",
      "Epoch 21/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.3809 - acc: 0.8293 - val_loss: 0.8924 - val_acc: 0.5849\n",
      "Epoch 22/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.3566 - acc: 0.8432 - val_loss: 0.9204 - val_acc: 0.5842\n",
      "Epoch 23/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.3304 - acc: 0.8585 - val_loss: 0.9117 - val_acc: 0.5868\n",
      "Epoch 24/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.3244 - acc: 0.8580 - val_loss: 0.9961 - val_acc: 0.5951\n",
      "Epoch 25/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.2926 - acc: 0.8754 - val_loss: 1.0453 - val_acc: 0.5891\n",
      "Epoch 26/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.2782 - acc: 0.8845 - val_loss: 1.0121 - val_acc: 0.5956\n",
      "Epoch 27/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.2578 - acc: 0.8933 - val_loss: 1.0448 - val_acc: 0.5997\n",
      "Epoch 28/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.2385 - acc: 0.9024 - val_loss: 1.0181 - val_acc: 0.5960\n",
      "Epoch 29/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.2219 - acc: 0.9099 - val_loss: 1.1588 - val_acc: 0.5942\n",
      "Epoch 30/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.2164 - acc: 0.9143 - val_loss: 1.1024 - val_acc: 0.5919\n",
      "Epoch 31/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.2037 - acc: 0.9191 - val_loss: 1.2939 - val_acc: 0.5884\n",
      "Epoch 32/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1739 - acc: 0.9318 - val_loss: 1.1805 - val_acc: 0.6009\n",
      "Epoch 33/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1742 - acc: 0.9286 - val_loss: 1.1782 - val_acc: 0.5947\n",
      "Epoch 34/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1850 - acc: 0.9284 - val_loss: 1.1949 - val_acc: 0.5952\n",
      "Epoch 35/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1701 - acc: 0.9377 - val_loss: 1.1925 - val_acc: 0.5952\n",
      "Epoch 36/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1633 - acc: 0.9348 - val_loss: 1.2044 - val_acc: 0.5953\n",
      "Epoch 37/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1533 - acc: 0.9408 - val_loss: 1.1259 - val_acc: 0.5964\n",
      "Epoch 38/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1454 - acc: 0.9431 - val_loss: 1.3238 - val_acc: 0.5962\n",
      "Epoch 39/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1433 - acc: 0.9437 - val_loss: 1.2508 - val_acc: 0.5840\n",
      "Epoch 40/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1258 - acc: 0.9521 - val_loss: 1.2204 - val_acc: 0.6013\n",
      "Epoch 41/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1352 - acc: 0.9479 - val_loss: 1.2288 - val_acc: 0.6026\n",
      "Epoch 42/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.1315 - acc: 0.9497 - val_loss: 1.3309 - val_acc: 0.5849\n",
      "Epoch 43/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1245 - acc: 0.9527 - val_loss: 1.2604 - val_acc: 0.5970\n",
      "Epoch 44/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1182 - acc: 0.9558 - val_loss: 1.2444 - val_acc: 0.6000\n",
      "Epoch 45/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1157 - acc: 0.9554 - val_loss: 1.3034 - val_acc: 0.5987\n",
      "Epoch 46/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.1207 - acc: 0.9520 - val_loss: 1.4005 - val_acc: 0.5967\n",
      "Epoch 47/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.1109 - acc: 0.9578 - val_loss: 1.3086 - val_acc: 0.6044\n",
      "Epoch 48/200\n",
      "448/448 [==============================] - 11s 26ms/step - loss: 0.1037 - acc: 0.9612 - val_loss: 1.3782 - val_acc: 0.5938\n",
      "Epoch 49/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0997 - acc: 0.9614 - val_loss: 1.4336 - val_acc: 0.6071\n",
      "Epoch 50/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.1051 - acc: 0.9607 - val_loss: 1.3013 - val_acc: 0.5897\n",
      "Epoch 51/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.1003 - acc: 0.9611 - val_loss: 1.4250 - val_acc: 0.6013\n",
      "Epoch 52/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0974 - acc: 0.9624 - val_loss: 1.4230 - val_acc: 0.6023\n",
      "Epoch 53/200\n",
      "448/448 [==============================] - 12s 28ms/step - loss: 0.0895 - acc: 0.9668 - val_loss: 1.3632 - val_acc: 0.6062\n",
      "Epoch 54/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0891 - acc: 0.9676 - val_loss: 1.4190 - val_acc: 0.6096\n",
      "Epoch 55/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.1020 - acc: 0.9615 - val_loss: 1.6076 - val_acc: 0.5899\n",
      "Epoch 56/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0899 - acc: 0.9665 - val_loss: 1.4227 - val_acc: 0.6084\n",
      "Epoch 57/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0869 - acc: 0.9683 - val_loss: 1.3846 - val_acc: 0.6069\n",
      "Epoch 58/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0935 - acc: 0.9657 - val_loss: 1.4809 - val_acc: 0.6142\n",
      "Epoch 59/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0909 - acc: 0.9664 - val_loss: 1.4833 - val_acc: 0.6080\n",
      "Epoch 60/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0834 - acc: 0.9687 - val_loss: 1.4471 - val_acc: 0.6027\n",
      "Epoch 61/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0820 - acc: 0.9684 - val_loss: 1.5127 - val_acc: 0.6108\n",
      "Epoch 62/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0779 - acc: 0.9711 - val_loss: 1.2861 - val_acc: 0.6081\n",
      "Epoch 63/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0697 - acc: 0.9732 - val_loss: 1.3331 - val_acc: 0.6152\n",
      "Epoch 64/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0877 - acc: 0.9671 - val_loss: 1.3208 - val_acc: 0.6077\n",
      "Epoch 65/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0843 - acc: 0.9687 - val_loss: 1.4864 - val_acc: 0.6058\n",
      "Epoch 66/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0720 - acc: 0.9726 - val_loss: 1.4413 - val_acc: 0.6141\n",
      "Epoch 67/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0729 - acc: 0.9727 - val_loss: 1.4986 - val_acc: 0.6124\n",
      "Epoch 68/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0716 - acc: 0.9735 - val_loss: 1.3948 - val_acc: 0.6086\n",
      "Epoch 69/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0717 - acc: 0.9721 - val_loss: 1.3655 - val_acc: 0.6011\n",
      "Epoch 70/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0704 - acc: 0.9739 - val_loss: 1.4263 - val_acc: 0.6036\n",
      "Epoch 71/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0641 - acc: 0.9777 - val_loss: 1.5405 - val_acc: 0.6072\n",
      "Epoch 72/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0825 - acc: 0.9695 - val_loss: 1.4916 - val_acc: 0.6033\n",
      "Epoch 73/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0752 - acc: 0.9725 - val_loss: 1.4586 - val_acc: 0.6008\n",
      "Epoch 74/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0633 - acc: 0.9768 - val_loss: 1.5615 - val_acc: 0.6033\n",
      "Epoch 75/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0704 - acc: 0.9748 - val_loss: 1.4768 - val_acc: 0.6068\n",
      "Epoch 76/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0641 - acc: 0.9748 - val_loss: 1.3962 - val_acc: 0.6161\n",
      "Epoch 77/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0730 - acc: 0.9724 - val_loss: 1.4503 - val_acc: 0.6084\n",
      "Epoch 78/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0545 - acc: 0.9802 - val_loss: 1.4805 - val_acc: 0.6132\n",
      "Epoch 79/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0597 - acc: 0.9771 - val_loss: 1.4745 - val_acc: 0.6164\n",
      "Epoch 80/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0638 - acc: 0.9767 - val_loss: 1.5797 - val_acc: 0.6142\n",
      "Epoch 81/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0627 - acc: 0.9766 - val_loss: 1.5854 - val_acc: 0.6098\n",
      "Epoch 82/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0522 - acc: 0.9819 - val_loss: 1.4554 - val_acc: 0.6239\n",
      "Epoch 83/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0567 - acc: 0.9786 - val_loss: 1.6152 - val_acc: 0.6146\n",
      "Epoch 84/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0543 - acc: 0.9809 - val_loss: 1.5753 - val_acc: 0.6224\n",
      "Epoch 85/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0555 - acc: 0.9804 - val_loss: 1.5211 - val_acc: 0.6215\n",
      "Epoch 86/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0566 - acc: 0.9793 - val_loss: 1.5525 - val_acc: 0.6216\n",
      "Epoch 87/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0636 - acc: 0.9767 - val_loss: 1.6129 - val_acc: 0.6233\n",
      "Epoch 88/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0547 - acc: 0.9796 - val_loss: 1.4216 - val_acc: 0.6155\n",
      "Epoch 89/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0573 - acc: 0.9778 - val_loss: 1.5182 - val_acc: 0.6146\n",
      "Epoch 90/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0496 - acc: 0.9807 - val_loss: 1.5223 - val_acc: 0.6291\n",
      "Epoch 91/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0500 - acc: 0.9821 - val_loss: 1.5458 - val_acc: 0.6252\n",
      "Epoch 92/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0531 - acc: 0.9799 - val_loss: 1.9084 - val_acc: 0.6137\n",
      "Epoch 93/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0501 - acc: 0.9831 - val_loss: 1.4899 - val_acc: 0.6183\n",
      "Epoch 94/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0526 - acc: 0.9812 - val_loss: 1.5597 - val_acc: 0.6235\n",
      "Epoch 95/200\n",
      "448/448 [==============================] - 12s 28ms/step - loss: 0.0501 - acc: 0.9810 - val_loss: 1.6697 - val_acc: 0.6074\n",
      "Epoch 96/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0536 - acc: 0.9809 - val_loss: 1.6607 - val_acc: 0.6109\n",
      "Epoch 97/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0568 - acc: 0.9787 - val_loss: 1.5679 - val_acc: 0.6190\n",
      "Epoch 98/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0522 - acc: 0.9805 - val_loss: 1.5357 - val_acc: 0.6213\n",
      "Epoch 99/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0471 - acc: 0.9822 - val_loss: 1.6961 - val_acc: 0.6177\n",
      "Epoch 100/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0516 - acc: 0.9801 - val_loss: 1.4938 - val_acc: 0.6217\n",
      "Epoch 101/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0509 - acc: 0.9817 - val_loss: 1.4828 - val_acc: 0.6288\n",
      "Epoch 102/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0447 - acc: 0.9835 - val_loss: 1.5293 - val_acc: 0.6206\n",
      "Epoch 103/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0452 - acc: 0.9834 - val_loss: 1.6877 - val_acc: 0.6107\n",
      "Epoch 104/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0499 - acc: 0.9826 - val_loss: 1.5076 - val_acc: 0.6175\n",
      "Epoch 105/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0469 - acc: 0.9828 - val_loss: 1.6488 - val_acc: 0.6175\n",
      "Epoch 106/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0454 - acc: 0.9834 - val_loss: 1.5707 - val_acc: 0.6176\n",
      "Epoch 107/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0450 - acc: 0.9835 - val_loss: 1.7134 - val_acc: 0.6055\n",
      "Epoch 108/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0429 - acc: 0.9850 - val_loss: 1.5708 - val_acc: 0.6210\n",
      "Epoch 109/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0392 - acc: 0.9860 - val_loss: 1.5386 - val_acc: 0.6173\n",
      "Epoch 110/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0431 - acc: 0.9846 - val_loss: 1.5151 - val_acc: 0.6231\n",
      "Epoch 111/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0420 - acc: 0.9856 - val_loss: 1.6663 - val_acc: 0.6217\n",
      "Epoch 112/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0409 - acc: 0.9850 - val_loss: 1.8878 - val_acc: 0.6023\n",
      "Epoch 113/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0493 - acc: 0.9820 - val_loss: 1.5352 - val_acc: 0.6243\n",
      "Epoch 114/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0423 - acc: 0.9844 - val_loss: 1.5799 - val_acc: 0.6312\n",
      "Epoch 115/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0390 - acc: 0.9857 - val_loss: 1.7392 - val_acc: 0.6168\n",
      "Epoch 116/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0450 - acc: 0.9829 - val_loss: 1.6079 - val_acc: 0.6342\n",
      "Epoch 117/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0518 - acc: 0.9805 - val_loss: 1.6152 - val_acc: 0.6233\n",
      "Epoch 118/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0415 - acc: 0.9853 - val_loss: 1.6030 - val_acc: 0.6248\n",
      "Epoch 119/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0421 - acc: 0.9855 - val_loss: 1.5543 - val_acc: 0.6195\n",
      "Epoch 120/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0333 - acc: 0.9884 - val_loss: 1.7290 - val_acc: 0.6159\n",
      "Epoch 121/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0310 - acc: 0.9892 - val_loss: 1.5917 - val_acc: 0.6221\n",
      "Epoch 122/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0438 - acc: 0.9839 - val_loss: 1.6579 - val_acc: 0.6158\n",
      "Epoch 123/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0382 - acc: 0.9863 - val_loss: 1.6885 - val_acc: 0.6199\n",
      "Epoch 124/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0354 - acc: 0.9871 - val_loss: 1.7870 - val_acc: 0.6283\n",
      "Epoch 125/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0493 - acc: 0.9817 - val_loss: 1.5605 - val_acc: 0.6310\n",
      "Epoch 126/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0372 - acc: 0.9874 - val_loss: 1.5675 - val_acc: 0.6252\n",
      "Epoch 127/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0361 - acc: 0.9876 - val_loss: 1.5787 - val_acc: 0.6244\n",
      "Epoch 128/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0402 - acc: 0.9848 - val_loss: 1.7740 - val_acc: 0.6232\n",
      "Epoch 129/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0349 - acc: 0.9877 - val_loss: 1.5671 - val_acc: 0.6243\n",
      "Epoch 130/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0336 - acc: 0.9873 - val_loss: 1.7203 - val_acc: 0.6176\n",
      "Epoch 131/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0350 - acc: 0.9866 - val_loss: 1.6898 - val_acc: 0.6199\n",
      "Epoch 132/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0292 - acc: 0.9890 - val_loss: 1.6870 - val_acc: 0.6186\n",
      "Epoch 133/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0331 - acc: 0.9881 - val_loss: 1.8196 - val_acc: 0.6158\n",
      "Epoch 134/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0442 - acc: 0.9846 - val_loss: 1.6101 - val_acc: 0.6309\n",
      "Epoch 135/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0332 - acc: 0.9878 - val_loss: 1.5717 - val_acc: 0.6275\n",
      "Epoch 136/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0430 - acc: 0.9845 - val_loss: 1.5615 - val_acc: 0.6281\n",
      "Epoch 137/200\n",
      "448/448 [==============================] - 13s 29ms/step - loss: 0.0378 - acc: 0.9870 - val_loss: 1.7057 - val_acc: 0.6318\n",
      "Epoch 138/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0455 - acc: 0.9838 - val_loss: 1.6384 - val_acc: 0.6252\n",
      "Epoch 139/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0346 - acc: 0.9877 - val_loss: 1.7170 - val_acc: 0.6273\n",
      "Epoch 140/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0381 - acc: 0.9863 - val_loss: 1.7428 - val_acc: 0.6243\n",
      "Epoch 141/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0336 - acc: 0.9877 - val_loss: 1.6570 - val_acc: 0.6189\n",
      "Epoch 142/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0329 - acc: 0.9884 - val_loss: 1.6671 - val_acc: 0.6257\n",
      "Epoch 143/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0364 - acc: 0.9871 - val_loss: 1.8375 - val_acc: 0.6232\n",
      "Epoch 144/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0247 - acc: 0.9905 - val_loss: 1.6565 - val_acc: 0.6309\n",
      "Epoch 145/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0362 - acc: 0.9868 - val_loss: 1.7461 - val_acc: 0.6252\n",
      "Epoch 146/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0248 - acc: 0.9908 - val_loss: 1.6668 - val_acc: 0.6235\n",
      "Epoch 147/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0319 - acc: 0.9886 - val_loss: 1.5968 - val_acc: 0.6305\n",
      "Epoch 148/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0307 - acc: 0.9882 - val_loss: 1.5467 - val_acc: 0.6326\n",
      "Epoch 149/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0306 - acc: 0.9894 - val_loss: 1.7681 - val_acc: 0.6263\n",
      "Epoch 150/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0389 - acc: 0.9852 - val_loss: 1.7662 - val_acc: 0.6333\n",
      "Epoch 151/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0262 - acc: 0.9903 - val_loss: 1.8351 - val_acc: 0.6230\n",
      "Epoch 152/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0344 - acc: 0.9868 - val_loss: 1.6136 - val_acc: 0.6276\n",
      "Epoch 153/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0285 - acc: 0.9900 - val_loss: 1.7543 - val_acc: 0.6265\n",
      "Epoch 154/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0302 - acc: 0.9889 - val_loss: 1.6944 - val_acc: 0.6336\n",
      "Epoch 155/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0310 - acc: 0.9891 - val_loss: 1.6217 - val_acc: 0.6329\n",
      "Epoch 156/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0266 - acc: 0.9912 - val_loss: 1.5972 - val_acc: 0.6325\n",
      "Epoch 157/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0349 - acc: 0.9866 - val_loss: 1.5258 - val_acc: 0.6308\n",
      "Epoch 158/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0288 - acc: 0.9886 - val_loss: 1.6254 - val_acc: 0.6344\n",
      "Epoch 159/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0233 - acc: 0.9916 - val_loss: 1.7777 - val_acc: 0.6312\n",
      "Epoch 160/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0349 - acc: 0.9868 - val_loss: 1.7152 - val_acc: 0.6310\n",
      "Epoch 161/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0247 - acc: 0.9910 - val_loss: 1.7722 - val_acc: 0.6350\n",
      "Epoch 162/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0231 - acc: 0.9919 - val_loss: 1.8297 - val_acc: 0.6327\n",
      "Epoch 163/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0298 - acc: 0.9901 - val_loss: 1.6090 - val_acc: 0.6377\n",
      "Epoch 164/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0241 - acc: 0.9914 - val_loss: 1.7599 - val_acc: 0.6349\n",
      "Epoch 165/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0291 - acc: 0.9900 - val_loss: 1.8080 - val_acc: 0.6263\n",
      "Epoch 166/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0262 - acc: 0.9910 - val_loss: 1.6610 - val_acc: 0.6350\n",
      "Epoch 167/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0276 - acc: 0.9896 - val_loss: 1.7901 - val_acc: 0.6274\n",
      "Epoch 168/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0315 - acc: 0.9883 - val_loss: 1.7592 - val_acc: 0.6329\n",
      "Epoch 169/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0259 - acc: 0.9909 - val_loss: 1.7769 - val_acc: 0.6369\n",
      "Epoch 170/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0244 - acc: 0.9909 - val_loss: 1.9486 - val_acc: 0.6290\n",
      "Epoch 171/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0275 - acc: 0.9904 - val_loss: 1.6702 - val_acc: 0.6375\n",
      "Epoch 172/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0211 - acc: 0.9918 - val_loss: 1.7961 - val_acc: 0.6318\n",
      "Epoch 173/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0258 - acc: 0.9906 - val_loss: 1.6953 - val_acc: 0.6375\n",
      "Epoch 174/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0230 - acc: 0.9920 - val_loss: 1.7759 - val_acc: 0.6402\n",
      "Epoch 175/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0314 - acc: 0.9889 - val_loss: 1.7077 - val_acc: 0.6437\n",
      "Epoch 176/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0323 - acc: 0.9885 - val_loss: 1.6990 - val_acc: 0.6376\n",
      "Epoch 177/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0260 - acc: 0.9908 - val_loss: 1.5730 - val_acc: 0.6398\n",
      "Epoch 178/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0233 - acc: 0.9920 - val_loss: 1.6348 - val_acc: 0.6402\n",
      "Epoch 179/200\n",
      "448/448 [==============================] - 12s 28ms/step - loss: 0.0234 - acc: 0.9915 - val_loss: 1.6713 - val_acc: 0.6289\n",
      "Epoch 180/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0228 - acc: 0.9915 - val_loss: 1.7629 - val_acc: 0.6344\n",
      "Epoch 181/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0324 - acc: 0.9892 - val_loss: 1.7898 - val_acc: 0.6388\n",
      "Epoch 182/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0279 - acc: 0.9894 - val_loss: 1.5931 - val_acc: 0.6356\n",
      "Epoch 183/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0218 - acc: 0.9915 - val_loss: 1.5734 - val_acc: 0.6381\n",
      "Epoch 184/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0306 - acc: 0.9903 - val_loss: 1.7097 - val_acc: 0.6399\n",
      "Epoch 185/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0265 - acc: 0.9910 - val_loss: 1.7779 - val_acc: 0.6379\n",
      "Epoch 186/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0256 - acc: 0.9911 - val_loss: 1.6099 - val_acc: 0.6387\n",
      "Epoch 187/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0265 - acc: 0.9910 - val_loss: 1.6217 - val_acc: 0.6390\n",
      "Epoch 188/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0200 - acc: 0.9925 - val_loss: 1.7673 - val_acc: 0.6319\n",
      "Epoch 189/200\n",
      "448/448 [==============================] - 12s 27ms/step - loss: 0.0271 - acc: 0.9905 - val_loss: 1.7660 - val_acc: 0.6391\n",
      "Epoch 190/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0217 - acc: 0.9920 - val_loss: 1.9472 - val_acc: 0.6442\n",
      "Epoch 191/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0244 - acc: 0.9926 - val_loss: 1.8729 - val_acc: 0.6260\n",
      "Epoch 192/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0261 - acc: 0.9909 - val_loss: 1.6676 - val_acc: 0.6406\n",
      "Epoch 193/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0200 - acc: 0.9930 - val_loss: 1.6911 - val_acc: 0.6385\n",
      "Epoch 194/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0236 - acc: 0.9921 - val_loss: 1.7026 - val_acc: 0.6452\n",
      "Epoch 195/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0274 - acc: 0.9906 - val_loss: 1.8200 - val_acc: 0.6423\n",
      "Epoch 196/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0248 - acc: 0.9918 - val_loss: 1.6876 - val_acc: 0.6394\n",
      "Epoch 197/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0205 - acc: 0.9930 - val_loss: 1.7124 - val_acc: 0.6461\n",
      "Epoch 198/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0222 - acc: 0.9917 - val_loss: 1.5570 - val_acc: 0.6407\n",
      "Epoch 199/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0226 - acc: 0.9924 - val_loss: 1.5758 - val_acc: 0.6391\n",
      "Epoch 200/200\n",
      "448/448 [==============================] - 12s 26ms/step - loss: 0.0215 - acc: 0.9926 - val_loss: 1.6950 - val_acc: 0.6380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc726f36310>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#datagen = ImageDataGenerator(\\\n",
    "#    rescale=1/255,\\\n",
    "#    validation_split=0.10,\\\n",
    "#    rotation_range=40,\\\n",
    "#    width_shift_range=0.2,\\\n",
    "#    height_shift_range=0.2,\\\n",
    "#    shear_range=0.2,\\\n",
    "#    zoom_range=0.2,\\\n",
    "#    horizontal_flip=True,\\\n",
    "#    fill_mode='nearest'\\\n",
    "#)\n",
    "\n",
    "\n",
    "#datagen.fit(train_features)\n",
    "#weights = {0:1, 1:6.5}\n",
    "\n",
    "\n",
    "\n",
    "model.fit(train_features, train_target,batch_size=64,validation_split=0.3,\\\n",
    "           epochs=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53f41ded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:59:30.765044Z",
     "iopub.status.busy": "2023-02-16T01:59:30.759459Z",
     "iopub.status.idle": "2023-02-16T01:59:32.150219Z",
     "shell.execute_reply": "2023-02-16T01:59:32.149615Z",
     "shell.execute_reply.started": "2023-02-15T12:36:37.627137Z"
    },
    "papermill": {
     "duration": 10.995364,
     "end_time": "2023-02-16T01:59:32.150368",
     "exception": false,
     "start_time": "2023-02-16T01:59:21.155004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"/kaggle/working/trained_model_breast_cancer3.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e984cb50",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T01:59:51.398163Z",
     "iopub.status.busy": "2023-02-16T01:59:51.397149Z",
     "iopub.status.idle": "2023-02-16T01:59:51.400344Z",
     "shell.execute_reply": "2023-02-16T01:59:51.401010Z"
    },
    "papermill": {
     "duration": 9.634837,
     "end_time": "2023-02-16T01:59:51.401246",
     "exception": false,
     "start_time": "2023-02-16T01:59:41.766409",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "#savedModel = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "035df730",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T02:00:10.540092Z",
     "iopub.status.busy": "2023-02-16T02:00:10.539392Z",
     "iopub.status.idle": "2023-02-16T02:00:15.512739Z",
     "shell.execute_reply": "2023-02-16T02:00:15.513259Z"
    },
    "papermill": {
     "duration": 14.517814,
     "end_time": "2023-02-16T02:00:15.513459",
     "exception": false,
     "start_time": "2023-02-16T02:00:00.995645",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_features=[]\n",
    "for i in test['img_data']:\n",
    "    i=np.array(i)\n",
    "    test_features.append(i)\n",
    "test_features=np.array(test_features)\n",
    " \n",
    "\n",
    "    \n",
    "#featureTransform = test_features.reshape(len(test_features), 6400)\n",
    "scaler = MinMaxScaler()\n",
    "#featureTransform =scaler.fit_transform(featureTransform)\n",
    "norm_features= []\n",
    "for i in range(len(test_features)):\n",
    "    norm_features.append(scaler.fit_transform(test_features[i]))\n",
    "test_features=np.array(norm_features)\n",
    "\n",
    "\n",
    "#backTransform = featureTransform.reshape(len(test_features),80,80)\n",
    "test_features = test_features.reshape(len(test_features),95,95,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_target = np.array(test['cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4612383",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T02:00:34.366654Z",
     "iopub.status.busy": "2023-02-16T02:00:34.365924Z",
     "iopub.status.idle": "2023-02-16T02:00:48.638205Z",
     "shell.execute_reply": "2023-02-16T02:00:48.637633Z"
    },
    "papermill": {
     "duration": 23.676509,
     "end_time": "2023-02-16T02:00:48.638381",
     "exception": false,
     "start_time": "2023-02-16T02:00:24.961872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 02:00:34.543519: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 632508100 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = model.predict(test_features)\n",
    "bin_pred = []\n",
    "for i in pred:\n",
    "    if i>=0.5:\n",
    "        bin_pred.append(1)\n",
    "    else:\n",
    "        bin_pred.append(0)\n",
    "bin_pred = np.array(bin_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a170160",
   "metadata": {
    "papermill": {
     "duration": 9.395582,
     "end_time": "2023-02-16T02:01:07.810315",
     "exception": false,
     "start_time": "2023-02-16T02:00:58.414733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5db572af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T02:01:26.638135Z",
     "iopub.status.busy": "2023-02-16T02:01:26.637433Z",
     "iopub.status.idle": "2023-02-16T02:01:26.675749Z",
     "shell.execute_reply": "2023-02-16T02:01:26.675017Z"
    },
    "papermill": {
     "duration": 9.447336,
     "end_time": "2023-02-16T02:01:26.675911",
     "exception": false,
     "start_time": "2023-02-16T02:01:17.228575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6410022259003482\n",
      "0.6167800453514739 0.6655556832547983\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "acc = sklearn.metrics.accuracy_score(test_target, bin_pred)\n",
    "print(acc)\n",
    "\n",
    "countzero=0\n",
    "countone=0\n",
    "countzerot=0\n",
    "countonet=0\n",
    "for i, j in zip(test_target, bin_pred):\n",
    "    if i==0 and j==0:\n",
    "        countzero+=1\n",
    "    if i==1 and j==1:\n",
    "        countone+=1\n",
    "    if i==1:\n",
    "        countonet+=1\n",
    "    if i==0:\n",
    "        countzerot+=1\n",
    "print(countzero/countzerot,countone/countonet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6284525",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-16T02:01:45.830631Z",
     "iopub.status.busy": "2023-02-16T02:01:45.829555Z",
     "iopub.status.idle": "2023-02-16T02:01:45.834273Z",
     "shell.execute_reply": "2023-02-16T02:01:45.835066Z"
    },
    "papermill": {
     "duration": 9.565632,
     "end_time": "2023-02-16T02:01:45.835276",
     "exception": false,
     "start_time": "2023-02-16T02:01:36.269644",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6480528200537155\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives )\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives )\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "\n",
    "print(f1_m(test_target,bin_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2883.711745,
   "end_time": "2023-02-16T02:01:58.390439",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-16T01:13:54.678694",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
