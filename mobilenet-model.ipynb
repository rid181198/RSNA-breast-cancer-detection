{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport tensorflow as tf\n#import tensorflow_io as tfio\nimport os\nfrom tqdm import tqdm\nimport cv2\nfrom PIL import Image\nfrom joblib import Parallel, delayed\nimport gc\nfrom PIL import Image as im\nimport random\nfrom scipy import ndimage\n","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:38:22.614833Z","iopub.execute_input":"2023-02-15T12:38:22.615139Z","iopub.status.idle":"2023-02-15T12:38:29.108591Z","shell.execute_reply.started":"2023-02-15T12:38:22.615086Z","shell.execute_reply":"2023-02-15T12:38:29.107645Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2023-02-15 12:38:24.092554: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2023-02-15 12:38:24.092676: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n","output_type":"stream"}]},{"cell_type":"code","source":"import sys\n!{sys.executable} -m pip install dicomsdl\n#!pip install /kaggle/input/rsnapacks/dicomsdl-0.109.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\n#import pydicom as dicom\nimport dicomsdl as dicom\nimport tensorflow as tf\n\nfrom PIL import Image as im\nimport os\nfrom tqdm import tqdm\nimport cv2\nfrom PIL import Image\nfrom joblib import Parallel, delayed\nimport gc\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:38:29.110147Z","iopub.execute_input":"2023-02-15T12:38:29.110957Z","iopub.status.idle":"2023-02-15T12:38:39.065712Z","shell.execute_reply.started":"2023-02-15T12:38:29.110923Z","shell.execute_reply":"2023-02-15T12:38:39.064568Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting dicomsdl\n  Downloading dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.4 MB)\n\u001b[K     |████████████████████████████████| 1.4 MB 2.1 MB/s eta 0:00:01\n\u001b[?25hInstalling collected packages: dicomsdl\nSuccessfully installed dicomsdl-0.109.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"datasetPath = '/kaggle/input/rsna-breast-cancer-detection/train.csv'\nimgPath = '/kaggle/input/rsna-breast-cancer-detection/train_images/'\n\ndef crop(sideName, imgName):\n    \"\"\"\n    This function is used to crop the breast images. It takes two arguments.\n    \n    Input:-\n    :sideName = Laterality of breast if it is right or left\n    :imgName = Image pixel data of the DCM images\n    \n    Output:-\n    :return = Output after cropping the image.\n    \n    \"\"\"\n    if sideName == 'L':\n        colind=[]\n        for r,row in enumerate(imgName):\n            for c,col in enumerate(row):\n                if col==0:\n                    colind.append(c)\n                    break\n        crop_size = max(colind)\n        imgName = imgName[0:512,0:crop_size]\n        imgName = cv2.resize(imgName,(128,128))\n        \n    if sideName == 'R':\n        colind=[]\n        for r,row in enumerate(imgName):\n            for c,col in enumerate(row):\n                if col!=0:\n                    colind.append(c)\n                    break\n        crop_size = min(colind)\n        imgName = imgName[0:512,crop_size:512]\n        imgName = cv2.resize(imgName,(128,128))\n    \n    return imgName    \n\n    gc.collect()\n    \ndef crop_reverse(sideName, imgName):\n    \n    \"\"\"\n    This function is used to crop the breast images but in the reverse order.\n    Because the laterality is defined wrongly for some images. It takes two arguments.\n    \n    Input:-\n    :sideName = Laterality of breast if it is right or left\n    :imgName = Image pixel data of the DCM images\n    \n    Output:-\n    :return = Output after cropping the image.\n    \n    \"\"\"\n    \n    if sideName == 'R':\n        colind=[]\n        for r,row in enumerate(imgName):\n            for c,col in enumerate(row):\n                if col==0:\n                    colind.append(c)\n                    break\n        crop_size = max(colind)\n        imgName = imgName[0:512,0:crop_size]\n        imgName = cv2.resize(imgName,(128,128))\n        \n    if sideName == 'L':\n        colind=[]\n        for r,row in enumerate(imgName):\n            for c,col in enumerate(row):\n                if col!=0:\n                    colind.append(c)\n                    break\n        crop_size = min(colind)\n        imgName = imgName[0:512,crop_size:512]\n        imgName = cv2.resize(imgName,(128,128))\n    \n    return imgName    \n\n    gc.collect()\n    \n\ndef img_process(i,filename,sides):\n    \n    \"\"\"\n    This function is used to process the images which will be used for the training/test dataset. It takes three arguments.\n    \n    Input:-\n    :i = Index of the image in the dataframe\n    :filename = Path of the image\n    :sides = List of all images' laterality\n    \n    Output:-\n    :return = Output after cropping the image.\n    \n    \"\"\"\n    \n    \n    #ds = dicom.dcmread(filename)\n    dsraw = dicom.open(filename)\n    ds = dsraw.pixelData()\n    \n    ds = (ds - ds.min()) / (ds.max() - ds.min())\n    if dsraw.PhotometricInterpretation == \"MONOCHROME1\":  \n        ds = 1 - ds\n    ds = (ds * 255).astype(np.uint8)\n\n    \n    #ds = cv2.normalize(ds, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    ds = cv2.resize(ds,(512,512))\n    \n    #ds = np.where(ds >= 0.999, 0,ds)\n    \n    try:\n        ds = np.array(crop(sides[i], ds))   \n    except:\n        ds = np.array(crop_reverse(sides[i], ds))\n    \n\n    #train_data.loc[i,'img_data'] = [img_fin]\n    #train_data.to_csv('/kaggle/working/training_img_data.csv') \n    return ds\n    gc.collect()\n\ndef dcmToPix(datasetPath, imgPath):\n    \n    \"\"\"\n    This function is used to process all the images which will be used for the training/test dataset. It takes two arguments.\n    \n    Input:-\n    :datasetPath = Path of the cancer dataset\n    :imgPath = Path of the image dataset\n   \n    Output:-\n    :return = Array of all the processed images\n    \n    \"\"\"\n    \n    \n    dataset = pd.read_csv(datasetPath)\n    \n    patient_ids = dataset['patient_id']\n    image_ids = dataset['image_id']\n    sides  = dataset['laterality']\n\n    imgData = []\n\n    for pi, ii, leng in zip(patient_ids, image_ids, range(len(patient_ids))):\n        imgData.append(imgPath + str(pi) + '/' + str(ii) + '.dcm')\n\n    dataset['img_data'] = \" \"\n    \n    result = Parallel(n_jobs=128)(\\\n    delayed(img_process)(i, fname, sides) for i, fname in zip(range(len(imgData)),tqdm(imgData))\\\n    )\n    \n    dataset['img_data'] = result\n    dataset.to_pickle('imgData.pkl' )\n    \n    return result\n    ","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:38:39.067636Z","iopub.execute_input":"2023-02-15T12:38:39.067926Z","iopub.status.idle":"2023-02-15T12:38:39.091680Z","shell.execute_reply.started":"2023-02-15T12:38:39.067894Z","shell.execute_reply":"2023-02-15T12:38:39.090728Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"with (open('/kaggle/input/output/imgData.pkl', \"rb\")) as openfile:\n     imgData = pickle.load(openfile)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-15T12:38:39.095793Z","iopub.execute_input":"2023-02-15T12:38:39.096132Z","iopub.status.idle":"2023-02-15T12:38:58.931499Z","shell.execute_reply.started":"2023-02-15T12:38:39.096075Z","shell.execute_reply":"2023-02-15T12:38:58.930696Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#datacancer = pd.read_csv(datasetPath)\n#imgDataFrame = {'cancer':datacancer['cancer'][:50], 'img_data':imgData}\n#imgData2 = pd.DataFrame(imgDataFrame)\n\n#imgData=imgData2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imgdata_pos = imgData[imgData['cancer'] == 1]\nimgdata_neg = imgData[imgData['cancer'] == 0]\n\nimgdata_pos = imgdata_pos.sample(frac = 1)\nimgdata_neg = imgdata_neg.sample(frac = 1)\n\nimgdata_neg = imgdata_neg.sample(frac= 1)\n\nframes = 10*[imgdata_pos]\nframes.append(imgdata_neg)\nimgdata_shuff = pd.concat(frames)\nimgdata_shuff = imgdata_shuff.sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:38:58.932552Z","iopub.execute_input":"2023-02-15T12:38:58.932760Z","iopub.status.idle":"2023-02-15T12:38:59.054806Z","shell.execute_reply.started":"2023-02-15T12:38:58.932735Z","shell.execute_reply":"2023-02-15T12:38:59.053968Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(imgdata_shuff['cancer'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:38:59.055837Z","iopub.execute_input":"2023-02-15T12:38:59.056103Z","iopub.status.idle":"2023-02-15T12:38:59.067441Z","shell.execute_reply.started":"2023-02-15T12:38:59.056062Z","shell.execute_reply":"2023-02-15T12:38:59.066563Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"0    53548\n1    11580\nName: cancer, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.decomposition import PCA\n\n\ndef random_rotate(imgData):\n    #thresh = 0.15\n    \n    imgData = imgData.reshape(128,128)\n    \n    \n    \n    clahe = cv2.createCLAHE(clipLimit=3, tileGridSize=(8,8))\n    imgData = cv2.equalizeHist(clahe.apply(imgData))\n    \n    #pca = PCA(25)\n    #imgData = pca.fit_transform(imgData)\n    #imgData = pca.inverse_transform(imgData)\n    \n    \n    imgData = ndimage.rotate(imgData, random.randint(-30, 30), reshape=False)\n\n    #imgData = np.clip(imgData,thresh,1)\n    imgData = imgData[15:110,15:110]\n    \n    #imgData = cv2.resize(imgData,(528,528))\n    \n    \n    #imgData = im.fromarray(imgData)\n    #imgData = np.asarray(imgData.rotate(random.randint(-20, 20)))\n    return imgData","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:39:32.861393Z","iopub.execute_input":"2023-02-15T12:39:32.861744Z","iopub.status.idle":"2023-02-15T12:39:33.066750Z","shell.execute_reply.started":"2023-02-15T12:39:32.861709Z","shell.execute_reply":"2023-02-15T12:39:33.065900Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"imgDataList=[]\nfor j in tqdm(imgdata_shuff['img_data']):\n    imgDataList.append(random_rotate(j))\nimgdata_shuff['img_data'] = imgDataList","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:39:34.922552Z","iopub.execute_input":"2023-02-15T12:39:34.922857Z","iopub.status.idle":"2023-02-15T12:43:44.142760Z","shell.execute_reply.started":"2023-02-15T12:39:34.922828Z","shell.execute_reply":"2023-02-15T12:43:44.140432Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 65128/65128 [04:09<00:00, 261.36it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain,test = train_test_split(imgdata_shuff, test_size=0.3, random_state=42, shuffle=True)\n\n\n\ntrain_target = np.array(train['cancer'])\ntrain_features=[]\nfor i in train['img_data']:\n    i=np.array(i)\n    train_features.append(i)\ntrain_features=np.array(train_features)\n\n\n\n#featureTransform = train_features.reshape(len(train_features), 6400)\n\n#from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\n#featureTransform = scaler.fit_transform(featureTransform)\nnorm_features= []\nfor i in range(len(train_features)):\n        norm_features.append(scaler.fit_transform(train_features[i]))\ntrain_features=np.array(norm_features)\n\n\n\n\n#backTransform = featureTransform.reshape(len(train_features),80,80)\n#train_features = backTransform.reshape(len(train_features),80,80,1)\ntrain_features = train_features.reshape(len(train_features),95,95,1)\n#train_features = np.repeat(train_features[..., np.newaxis], 3, -1)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:44:14.750489Z","iopub.execute_input":"2023-02-15T12:44:14.750794Z","iopub.status.idle":"2023-02-15T12:44:38.970310Z","shell.execute_reply.started":"2023-02-15T12:44:14.750764Z","shell.execute_reply":"2023-02-15T12:44:38.968231Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LeakyReLU\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten,\\\nDepthwiseConv2D, MaxPooling2D, Dropout, BatchNormalization,\\\nGlobalAveragePooling2D, ReLU, Input\nfrom tensorflow.keras.applications import *\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import optimizers\nimport tensorflow as tf\nfrom tensorflow import keras\n\n\ndef depth_block(x, strides):\n    x = DepthwiseConv2D(3,strides=strides,padding='same',  use_bias=False)(x)\n    x = BatchNormalization()(x)\n    x = ReLU()(x)\n    return x\ndef single_conv_block(x,filters):\n    x = Conv2D(filters, 1,use_bias=False)(x)\n    x= BatchNormalization()(x)\n    x = ReLU()(x)\n    return x\ndef combo_layer(x,filters,strides):\n    x = depth_block(x,strides)\n    x = single_conv_block(x, filters)\n    return x\n\n\ndef MobileNet(input_shape=(224,224,3),n_classes = 1000):\n    input = Input(input_shape)\n    x = Conv2D(32,3,strides=(2,2),padding = 'same', use_bias=False)(input)\n    x =  BatchNormalization()(x)\n    x = ReLU()(x)\n    x = combo_layer(x,64, strides=(1,1))\n    x = combo_layer(x,128,strides=(2,2))\n    x = combo_layer(x,128,strides=(1,1))\n    x = combo_layer(x,256,strides=(2,2))\n    x = combo_layer(x,256,strides=(1,1))\n    x = combo_layer(x,512,strides=(2,2))\n    for _ in range(5):\n        x = combo_layer(x,512,strides=(1,1))\n    x = combo_layer(x,1024,strides=(2,2))\n    x = combo_layer(x,1024,strides=(1,1))\n    x = GlobalAveragePooling2D()(x)\n    x = Dense(512,activation='relu')(x)\n    output = Dense(n_classes,activation='sigmoid')(x)\n    \n    model = tf.keras.Model(input, output)\n    return model\n\nn_classes = 1\ninput_shape = (95,95,1)\n\n\n\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\nwith tpu_strategy.scope():\n    model = MobileNet(input_shape,n_classes)\n\n\n    model.compile(\\\n        loss=\"binary_crossentropy\",\\\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\\\n        metrics=[\"acc\"],\\\n    )\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:46:27.102369Z","iopub.execute_input":"2023-02-15T12:46:27.103285Z","iopub.status.idle":"2023-02-15T12:46:36.151879Z","shell.execute_reply.started":"2023-02-15T12:46:27.103238Z","shell.execute_reply":"2023-02-15T12:46:36.150894Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"2023-02-15 12:46:27.128499: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2023-02-15 12:46:27.135310: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/conda/lib\n2023-02-15 12:46:27.135391: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n2023-02-15 12:46:27.135458: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (5ea7dff0d694): /proc/driver/nvidia/version does not exist\n2023-02-15 12:46:27.141794: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-02-15 12:46:27.145360: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n2023-02-15 12:46:27.190797: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2023-02-15 12:46:27.190877: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n2023-02-15 12:46:27.214341: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> 10.0.0.2:8470}\n2023-02-15 12:46:27.214400: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job localhost -> {0 -> localhost:30020}\n2023-02-15 12:46:27.217314: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:30020\n","output_type":"stream"}]},{"cell_type":"code","source":"\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:46:36.153973Z","iopub.execute_input":"2023-02-15T12:46:36.154356Z","iopub.status.idle":"2023-02-15T12:46:36.193404Z","shell.execute_reply.started":"2023-02-15T12:46:36.154321Z","shell.execute_reply":"2023-02-15T12:46:36.190814Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 95, 95, 1)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 48, 48, 32)        288       \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 48, 48, 32)        128       \n_________________________________________________________________\nre_lu (ReLU)                 (None, 48, 48, 32)        0         \n_________________________________________________________________\ndepthwise_conv2d (DepthwiseC (None, 48, 48, 32)        288       \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 48, 48, 32)        128       \n_________________________________________________________________\nre_lu_1 (ReLU)               (None, 48, 48, 32)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 48, 48, 64)        2048      \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 48, 48, 64)        256       \n_________________________________________________________________\nre_lu_2 (ReLU)               (None, 48, 48, 64)        0         \n_________________________________________________________________\ndepthwise_conv2d_1 (Depthwis (None, 24, 24, 64)        576       \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 24, 24, 64)        256       \n_________________________________________________________________\nre_lu_3 (ReLU)               (None, 24, 24, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 24, 24, 128)       8192      \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 24, 24, 128)       512       \n_________________________________________________________________\nre_lu_4 (ReLU)               (None, 24, 24, 128)       0         \n_________________________________________________________________\ndepthwise_conv2d_2 (Depthwis (None, 24, 24, 128)       1152      \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 24, 24, 128)       512       \n_________________________________________________________________\nre_lu_5 (ReLU)               (None, 24, 24, 128)       0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 24, 24, 128)       16384     \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 24, 24, 128)       512       \n_________________________________________________________________\nre_lu_6 (ReLU)               (None, 24, 24, 128)       0         \n_________________________________________________________________\ndepthwise_conv2d_3 (Depthwis (None, 12, 12, 128)       1152      \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 12, 12, 128)       512       \n_________________________________________________________________\nre_lu_7 (ReLU)               (None, 12, 12, 128)       0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 12, 12, 256)       32768     \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 12, 12, 256)       1024      \n_________________________________________________________________\nre_lu_8 (ReLU)               (None, 12, 12, 256)       0         \n_________________________________________________________________\ndepthwise_conv2d_4 (Depthwis (None, 12, 12, 256)       2304      \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 12, 12, 256)       1024      \n_________________________________________________________________\nre_lu_9 (ReLU)               (None, 12, 12, 256)       0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 12, 12, 256)       65536     \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 12, 12, 256)       1024      \n_________________________________________________________________\nre_lu_10 (ReLU)              (None, 12, 12, 256)       0         \n_________________________________________________________________\ndepthwise_conv2d_5 (Depthwis (None, 6, 6, 256)         2304      \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 6, 6, 256)         1024      \n_________________________________________________________________\nre_lu_11 (ReLU)              (None, 6, 6, 256)         0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 6, 6, 512)         131072    \n_________________________________________________________________\nbatch_normalization_12 (Batc (None, 6, 6, 512)         2048      \n_________________________________________________________________\nre_lu_12 (ReLU)              (None, 6, 6, 512)         0         \n_________________________________________________________________\ndepthwise_conv2d_6 (Depthwis (None, 6, 6, 512)         4608      \n_________________________________________________________________\nbatch_normalization_13 (Batc (None, 6, 6, 512)         2048      \n_________________________________________________________________\nre_lu_13 (ReLU)              (None, 6, 6, 512)         0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 6, 6, 512)         262144    \n_________________________________________________________________\nbatch_normalization_14 (Batc (None, 6, 6, 512)         2048      \n_________________________________________________________________\nre_lu_14 (ReLU)              (None, 6, 6, 512)         0         \n_________________________________________________________________\ndepthwise_conv2d_7 (Depthwis (None, 6, 6, 512)         4608      \n_________________________________________________________________\nbatch_normalization_15 (Batc (None, 6, 6, 512)         2048      \n_________________________________________________________________\nre_lu_15 (ReLU)              (None, 6, 6, 512)         0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 6, 6, 512)         262144    \n_________________________________________________________________\nbatch_normalization_16 (Batc (None, 6, 6, 512)         2048      \n_________________________________________________________________\nre_lu_16 (ReLU)              (None, 6, 6, 512)         0         \n_________________________________________________________________\ndepthwise_conv2d_8 (Depthwis (None, 6, 6, 512)         4608      \n_________________________________________________________________\nbatch_normalization_17 (Batc (None, 6, 6, 512)         2048      \n_________________________________________________________________\nre_lu_17 (ReLU)              (None, 6, 6, 512)         0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, 6, 6, 512)         262144    \n_________________________________________________________________\nbatch_normalization_18 (Batc (None, 6, 6, 512)         2048      \n_________________________________________________________________\nre_lu_18 (ReLU)              (None, 6, 6, 512)         0         \n_________________________________________________________________\ndepthwise_conv2d_9 (Depthwis (None, 6, 6, 512)         4608      \n_________________________________________________________________\nbatch_normalization_19 (Batc (None, 6, 6, 512)         2048      \n_________________________________________________________________\nre_lu_19 (ReLU)              (None, 6, 6, 512)         0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 6, 6, 512)         262144    \n_________________________________________________________________\nbatch_normalization_20 (Batc (None, 6, 6, 512)         2048      \n_________________________________________________________________\nre_lu_20 (ReLU)              (None, 6, 6, 512)         0         \n_________________________________________________________________\ndepthwise_conv2d_10 (Depthwi (None, 6, 6, 512)         4608      \n_________________________________________________________________\nbatch_normalization_21 (Batc (None, 6, 6, 512)         2048      \n_________________________________________________________________\nre_lu_21 (ReLU)              (None, 6, 6, 512)         0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 6, 6, 512)         262144    \n_________________________________________________________________\nbatch_normalization_22 (Batc (None, 6, 6, 512)         2048      \n_________________________________________________________________\nre_lu_22 (ReLU)              (None, 6, 6, 512)         0         \n_________________________________________________________________\ndepthwise_conv2d_11 (Depthwi (None, 3, 3, 512)         4608      \n_________________________________________________________________\nbatch_normalization_23 (Batc (None, 3, 3, 512)         2048      \n_________________________________________________________________\nre_lu_23 (ReLU)              (None, 3, 3, 512)         0         \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, 3, 3, 1024)        524288    \n_________________________________________________________________\nbatch_normalization_24 (Batc (None, 3, 3, 1024)        4096      \n_________________________________________________________________\nre_lu_24 (ReLU)              (None, 3, 3, 1024)        0         \n_________________________________________________________________\ndepthwise_conv2d_12 (Depthwi (None, 3, 3, 1024)        9216      \n_________________________________________________________________\nbatch_normalization_25 (Batc (None, 3, 3, 1024)        4096      \n_________________________________________________________________\nre_lu_25 (ReLU)              (None, 3, 3, 1024)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 3, 3, 1024)        1048576   \n_________________________________________________________________\nbatch_normalization_26 (Batc (None, 3, 3, 1024)        4096      \n_________________________________________________________________\nre_lu_26 (ReLU)              (None, 3, 3, 1024)        0         \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 1024)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               524800    \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 513       \n=================================================================\nTotal params: 3,753,601\nTrainable params: 3,731,713\nNon-trainable params: 21,888\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"#from tensorflow import keras\n#model = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n#datagen = ImageDataGenerator(\\\n#    rescale=1/255,\\\n#    validation_split=0.10,\\\n#    rotation_range=40,\\\n#    width_shift_range=0.2,\\\n#    height_shift_range=0.2,\\\n#    shear_range=0.2,\\\n#    zoom_range=0.2,\\\n#    horizontal_flip=True,\\\n#    fill_mode='nearest'\\\n#)\n\n\n#datagen.fit(train_features)\nweights = {0:1, 1:7}\n\n\n\nmodel.fit(train_features, train_target,class_weight = weights,batch_size=64,validation_split=0.3,\\\n           epochs=200)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:48:05.636076Z","iopub.execute_input":"2023-02-15T12:48:05.636465Z","iopub.status.idle":"2023-02-15T12:49:32.628583Z","shell.execute_reply.started":"2023-02-15T12:48:05.636429Z","shell.execute_reply":"2023-02-15T12:49:32.627188Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stderr","text":"2023-02-15 12:48:06.811686: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1152023200 exceeds 10% of free system memory.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/150\n499/499 [==============================] - 38s 54ms/step - loss: 1.4029 - acc: 0.2699 - val_loss: 0.5806 - val_acc: 0.8271\nEpoch 2/150\n499/499 [==============================] - 14s 28ms/step - loss: 1.3888 - acc: 0.2741 - val_loss: 0.8525 - val_acc: 0.3570\nEpoch 3/150\n499/499 [==============================] - 14s 28ms/step - loss: 1.3755 - acc: 0.2938 - val_loss: 0.8547 - val_acc: 0.2873\nEpoch 4/150\n454/499 [==========================>...] - ETA: 1s - loss: 1.3631 - acc: 0.3177","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_20/3927249004.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m model.fit(train_features, train_target,class_weight = weights,batch_size=64,validation_split=0.3,\\\n\u001b[0;32m---> 22\u001b[0;31m            epochs=150)\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1103\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    452\u001b[0m     \"\"\"\n\u001b[1;32m    453\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unrecognized hook: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_supports_tf_logs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnumpy_logs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Only convert once.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1084\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1085\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    508\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1069\u001b[0m     \"\"\"\n\u001b[1;32m   1070\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1035\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"model.save(\"/kaggle/working/trained_model_breast_cancer3.h5\")\n","metadata":{"execution":{"iopub.status.busy":"2023-02-15T12:36:37.626226Z","iopub.execute_input":"2023-02-15T12:36:37.627180Z","iopub.status.idle":"2023-02-15T12:36:39.048200Z","shell.execute_reply.started":"2023-02-15T12:36:37.627137Z","shell.execute_reply":"2023-02-15T12:36:39.047059Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#from tensorflow import keras\n#savedModel = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_features=[]\nfor i in test['img_data']:\n    i=np.array(i)\n    test_features.append(i)\ntest_features=np.array(test_features)\n \n\n    \n#featureTransform = test_features.reshape(len(test_features), 6400)\nscaler = MinMaxScaler()\n#featureTransform =scaler.fit_transform(featureTransform)\nnorm_features= []\nfor i in range(len(test_features)):\n    norm_features.append(scaler.fit_transform(test_features[i]))\ntest_features=np.array(norm_features)\n\n\n#backTransform = featureTransform.reshape(len(test_features),80,80)\ntest_features = test_features.reshape(len(test_features),95,95,1)\n\n\n\n\n\ntest_target = np.array(test['cancer'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\npred = model.predict(test_features)\nbin_pred = []\nfor i in pred:\n    if i>=0.5:\n        bin_pred.append(1)\n    else:\n        bin_pred.append(0)\nbin_pred = np.array(bin_pred)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nacc = sklearn.metrics.accuracy_score(test_target, bin_pred)\nprint(acc)\n\ncountzero=0\ncountone=0\ncountzerot=0\ncountonet=0\nfor i, j in zip(test_target, bin_pred):\n    if i==0 and j==0:\n        countzero+=1\n    if i==1 and j==1:\n        countone+=1\n    if i==1:\n        countonet+=1\n    if i==0:\n        countzerot+=1\nprint(countzero/countzerot,countone/countonet)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef recall_m(y_true, y_pred):\n    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n    possible_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives )\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives )\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall))\n\n\nprint(f1_m(test_target,bin_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}