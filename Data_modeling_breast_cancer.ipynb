{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "120c96e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T14:52:41.606396Z",
     "iopub.status.busy": "2023-02-11T14:52:41.604931Z",
     "iopub.status.idle": "2023-02-11T14:52:51.393744Z",
     "shell.execute_reply": "2023-02-11T14:52:51.392120Z"
    },
    "papermill": {
     "duration": 9.801659,
     "end_time": "2023-02-11T14:52:51.397103",
     "exception": false,
     "start_time": "2023-02-11T14:52:41.595444",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "from PIL import Image as im\n",
    "import random\n",
    "from scipy import ndimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ea91d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T14:52:51.413675Z",
     "iopub.status.busy": "2023-02-11T14:52:51.412878Z",
     "iopub.status.idle": "2023-02-11T14:53:08.663899Z",
     "shell.execute_reply": "2023-02-11T14:53:08.662317Z"
    },
    "papermill": {
     "duration": 17.263692,
     "end_time": "2023-02-11T14:53:08.667355",
     "exception": false,
     "start_time": "2023-02-11T14:52:51.403663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dicomsdl\r\n",
      "  Downloading dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: dicomsdl\r\n",
      "Successfully installed dicomsdl-0.109.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install dicomsdl\n",
    "#!pip install /kaggle/input/rsnapacks/dicomsdl-0.109.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "#import pydicom as dicom\n",
    "import dicomsdl as dicom\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from PIL import Image as im\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "467e420b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T14:53:08.685525Z",
     "iopub.status.busy": "2023-02-11T14:53:08.684471Z",
     "iopub.status.idle": "2023-02-11T14:53:08.712247Z",
     "shell.execute_reply": "2023-02-11T14:53:08.710727Z"
    },
    "papermill": {
     "duration": 0.040856,
     "end_time": "2023-02-11T14:53:08.715641",
     "exception": false,
     "start_time": "2023-02-11T14:53:08.674785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasetPath = '/kaggle/input/rsna-breast-cancer-detection/train.csv'\n",
    "imgPath = '/kaggle/input/rsna-breast-cancer-detection/train_images/'\n",
    "\n",
    "def crop(sideName, imgName):\n",
    "    \"\"\"\n",
    "    This function is used to crop the breast images. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :sideName = Laterality of breast if it is right or left\n",
    "    :imgName = Image pixel data of the DCM images\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    if sideName == 'L':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col==0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = max(colind)\n",
    "        imgName = imgName[0:512,0:crop_size]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "        \n",
    "    if sideName == 'R':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col!=0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = min(colind)\n",
    "        imgName = imgName[0:512,crop_size:512]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "    \n",
    "    return imgName    \n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "def crop_reverse(sideName, imgName):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to crop the breast images but in the reverse order.\n",
    "    Because the laterality is defined wrongly for some images. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :sideName = Laterality of breast if it is right or left\n",
    "    :imgName = Image pixel data of the DCM images\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if sideName == 'R':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col==0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = max(colind)\n",
    "        imgName = imgName[0:512,0:crop_size]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "        \n",
    "    if sideName == 'L':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col!=0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = min(colind)\n",
    "        imgName = imgName[0:512,crop_size:512]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "    \n",
    "    return imgName    \n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "def img_process(i,filename,sides):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to process the images which will be used for the training/test dataset. It takes three arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :i = Index of the image in the dataframe\n",
    "    :filename = Path of the image\n",
    "    :sides = List of all images' laterality\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #ds = dicom.dcmread(filename)\n",
    "    dsraw = dicom.open(filename)\n",
    "    ds = dsraw.pixelData()\n",
    "    \n",
    "    ds = (ds - ds.min()) / (ds.max() - ds.min())\n",
    "    if dsraw.PhotometricInterpretation == \"MONOCHROME1\":  \n",
    "        ds = 1 - ds\n",
    "    ds = (ds * 255).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    #ds = cv2.normalize(ds, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    ds = cv2.resize(ds,(512,512))\n",
    "    \n",
    "    #ds = np.where(ds >= 0.999, 0,ds)\n",
    "    \n",
    "    try:\n",
    "        ds = np.array(crop(sides[i], ds))   \n",
    "    except:\n",
    "        ds = np.array(crop_reverse(sides[i], ds))\n",
    "    \n",
    "\n",
    "    #train_data.loc[i,'img_data'] = [img_fin]\n",
    "    #train_data.to_csv('/kaggle/working/training_img_data.csv') \n",
    "    return ds\n",
    "    gc.collect()\n",
    "\n",
    "def dcmToPix(datasetPath, imgPath):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to process all the images which will be used for the training/test dataset. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :datasetPath = Path of the cancer dataset\n",
    "    :imgPath = Path of the image dataset\n",
    "   \n",
    "    Output:-\n",
    "    :return = Array of all the processed images\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    dataset = pd.read_csv(datasetPath)\n",
    "    \n",
    "    patient_ids = dataset['patient_id']\n",
    "    image_ids = dataset['image_id']\n",
    "    sides  = dataset['laterality']\n",
    "\n",
    "    imgData = []\n",
    "\n",
    "    for pi, ii, leng in zip(patient_ids, image_ids, range(len(patient_ids))):\n",
    "        imgData.append(imgPath + str(pi) + '/' + str(ii) + '.dcm')\n",
    "\n",
    "    dataset['img_data'] = \" \"\n",
    "    \n",
    "    result = Parallel(n_jobs=128)(\\\n",
    "    delayed(img_process)(i, fname, sides) for i, fname in zip(range(len(imgData)),tqdm(imgData))\\\n",
    "    )\n",
    "    \n",
    "    dataset['img_data'] = result\n",
    "    dataset.to_pickle('imgData.pkl' )\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78616f0b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-11T14:53:08.732285Z",
     "iopub.status.busy": "2023-02-11T14:53:08.731778Z",
     "iopub.status.idle": "2023-02-11T14:53:21.647200Z",
     "shell.execute_reply": "2023-02-11T14:53:21.645830Z"
    },
    "papermill": {
     "duration": 12.92773,
     "end_time": "2023-02-11T14:53:21.650496",
     "exception": false,
     "start_time": "2023-02-11T14:53:08.722766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with (open('/kaggle/input/output/imgData.pkl', \"rb\")) as openfile:\n",
    "     imgData = pickle.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9bf7f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T14:53:21.668236Z",
     "iopub.status.busy": "2023-02-11T14:53:21.666814Z",
     "iopub.status.idle": "2023-02-11T14:53:21.673312Z",
     "shell.execute_reply": "2023-02-11T14:53:21.671837Z"
    },
    "papermill": {
     "duration": 0.018977,
     "end_time": "2023-02-11T14:53:21.676828",
     "exception": false,
     "start_time": "2023-02-11T14:53:21.657851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#datacancer = pd.read_csv(datasetPath)\n",
    "#imgDataFrame = {'cancer':datacancer['cancer'][:50], 'img_data':imgData}\n",
    "#imgData2 = pd.DataFrame(imgDataFrame)\n",
    "\n",
    "#imgData=imgData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dcf97ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T14:53:21.693656Z",
     "iopub.status.busy": "2023-02-11T14:53:21.693171Z",
     "iopub.status.idle": "2023-02-11T14:53:21.811735Z",
     "shell.execute_reply": "2023-02-11T14:53:21.810072Z"
    },
    "papermill": {
     "duration": 0.131341,
     "end_time": "2023-02-11T14:53:21.815423",
     "exception": false,
     "start_time": "2023-02-11T14:53:21.684082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgdata_pos = imgData[imgData['cancer'] == 1]\n",
    "imgdata_neg = imgData[imgData['cancer'] == 0]\n",
    "\n",
    "imgdata_pos = imgdata_pos.sample(frac = 1)\n",
    "imgdata_neg = imgdata_neg.sample(frac = 1)\n",
    "\n",
    "imgdata_neg = imgdata_neg.sample(frac= 0.7)\n",
    "\n",
    "frames = 5*[imgdata_pos]\n",
    "frames.append(imgdata_neg)\n",
    "imgdata_shuff = pd.concat(frames)\n",
    "imgdata_shuff = imgdata_shuff.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8deac6d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T14:53:21.833148Z",
     "iopub.status.busy": "2023-02-11T14:53:21.832024Z",
     "iopub.status.idle": "2023-02-11T14:53:21.845949Z",
     "shell.execute_reply": "2023-02-11T14:53:21.844421Z"
    },
    "papermill": {
     "duration": 0.02806,
     "end_time": "2023-02-11T14:53:21.850946",
     "exception": false,
     "start_time": "2023-02-11T14:53:21.822886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    37484\n",
      "1     5790\n",
      "Name: cancer, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(imgdata_shuff['cancer'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3f53f64",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T14:53:21.868754Z",
     "iopub.status.busy": "2023-02-11T14:53:21.868294Z",
     "iopub.status.idle": "2023-02-11T14:53:22.245460Z",
     "shell.execute_reply": "2023-02-11T14:53:22.243785Z"
    },
    "papermill": {
     "duration": 0.390801,
     "end_time": "2023-02-11T14:53:22.250042",
     "exception": false,
     "start_time": "2023-02-11T14:53:21.859241",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def random_rotate(imgData):\n",
    "    #thresh = 0.15\n",
    "    \n",
    "    imgData = imgData.reshape(128,128)\n",
    "    clahe = cv2.createCLAHE(clipLimit=5, tileGridSize=(3,3))\n",
    "    imgData = clahe.apply(imgData)\n",
    "    imgData = ndimage.rotate(imgData, random.randint(-30, 30), reshape=False)\n",
    "\n",
    "    #imgData = np.clip(imgData,thresh,1)\n",
    "    imgData = imgData[15:110,15:110]\n",
    "    pca = PCA(25)\n",
    "    imgData = pca.fit_transform(imgData)\n",
    "    imgData = pca.inverse_transform(imgData)\n",
    "    #imgData = cv2.resize(imgData,(528,528))\n",
    "    \n",
    "    \n",
    "    #imgData = im.fromarray(imgData)\n",
    "    #imgData = np.asarray(imgData.rotate(random.randint(-20, 20)))\n",
    "    return imgData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e729425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T14:53:22.294260Z",
     "iopub.status.busy": "2023-02-11T14:53:22.293350Z",
     "iopub.status.idle": "2023-02-11T15:06:14.744233Z",
     "shell.execute_reply": "2023-02-11T15:06:14.742810Z"
    },
    "papermill": {
     "duration": 772.477919,
     "end_time": "2023-02-11T15:06:14.753732",
     "exception": false,
     "start_time": "2023-02-11T14:53:22.275813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 29235/43274 [08:39<05:15, 44.47it/s]/opt/conda/lib/python3.7/site-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 70%|██████▉   | 30176/43274 [08:56<04:32, 48.01it/s]/opt/conda/lib/python3.7/site-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      " 73%|███████▎  | 31402/43274 [09:17<02:43, 72.48it/s]/opt/conda/lib/python3.7/site-packages/sklearn/decomposition/_pca.py:501: RuntimeWarning: invalid value encountered in true_divide\n",
      "  explained_variance_ratio_ = explained_variance_ / total_var\n",
      "100%|██████████| 43274/43274 [12:52<00:00, 56.03it/s]\n"
     ]
    }
   ],
   "source": [
    "imgDataList=[]\n",
    "for j in tqdm(imgdata_shuff['img_data']):\n",
    "    imgDataList.append(random_rotate(j))\n",
    "imgdata_shuff['img_data'] = imgDataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da2bb8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T15:06:15.679224Z",
     "iopub.status.busy": "2023-02-11T15:06:15.678708Z",
     "iopub.status.idle": "2023-02-11T15:06:32.720672Z",
     "shell.execute_reply": "2023-02-11T15:06:32.719350Z"
    },
    "papermill": {
     "duration": 17.485416,
     "end_time": "2023-02-11T15:06:32.723971",
     "exception": false,
     "start_time": "2023-02-11T15:06:15.238555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test = train_test_split(imgdata_shuff, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "train_target = np.array(train['cancer'])\n",
    "train_features=[]\n",
    "for i in train['img_data']:\n",
    "    i=np.array(i)\n",
    "    train_features.append(i)\n",
    "train_features=np.array(train_features)\n",
    "\n",
    "\n",
    "\n",
    "#featureTransform = train_features.reshape(len(train_features), 6400)\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#featureTransform = scaler.fit_transform(featureTransform)\n",
    "norm_features= []\n",
    "for i in range(len(train_features)):\n",
    "        norm_features.append(scaler.fit_transform(train_features[i]))\n",
    "train_features=np.array(norm_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#backTransform = featureTransform.reshape(len(train_features),80,80)\n",
    "#train_features = backTransform.reshape(len(train_features),80,80,1)\n",
    "train_features = train_features.reshape(len(train_features),95,95,1)\n",
    "#train_features = np.repeat(train_features[..., np.newaxis], 3, -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dc56eb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T15:06:33.660052Z",
     "iopub.status.busy": "2023-02-11T15:06:33.659591Z",
     "iopub.status.idle": "2023-02-11T15:06:37.779422Z",
     "shell.execute_reply": "2023-02-11T15:06:37.777737Z"
    },
    "papermill": {
     "duration": 4.625585,
     "end_time": "2023-02-11T15:06:37.783176",
     "exception": false,
     "start_time": "2023-02-11T15:06:33.157591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 15:06:33.805398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 15:06:33.945603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 15:06:33.947874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 15:06:33.951886: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-11 15:06:33.952827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 15:06:33.954768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 15:06:33.956390: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 15:06:37.011032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 15:06:37.012264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 15:06:37.013354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-02-11 15:06:37.015560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dense, Conv2D, Flatten,MaxPooling2D, Dropout, BatchNormalization, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#conv_base = EfficientNetB6(weights='imagenet', include_top=False, input_shape=(95,95,3),drop_connect_rate=0.2)\n",
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(Conv2D(16, 3, activation = \"relu\", input_shape = (95,95,1)))\n",
    "#model.add(MaxPooling2D())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, 3, activation = \"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(32, 3, activation = \"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(LeakyReLU(alpha=0.1))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(32, 3, activation = \"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Conv2D(32, 3, activation = \"relu\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#model.add(Dense(1024, activation = 'relu')) \n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(512, activation = 'relu')) \n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(Dense(512, activation = 'relu')) \n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "#model.add(Dropout(0.1))\n",
    "\n",
    "#model.add(Dense(1024, activation = 'relu',kernel_regularizer=keras.regularizers.l1_l2(l1=0.1, l2=0.01))) \n",
    "#model.add(LeakyReLU(alpha=0.2))\n",
    "#model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256, activation = 'relu')) \n",
    "model.add(LeakyReLU(alpha=0.2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "\n",
    "#conv_base.trainable = True\n",
    "\n",
    "#model.compile(optimizer =tf.keras.optimizers.Adam(learning_rate=0.0001),\\\n",
    "#          loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.compile(\\\n",
    "    loss=\"binary_crossentropy\",\\\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\\\n",
    "    metrics=[\"acc\"],\\\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40cfd18e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T15:06:38.664778Z",
     "iopub.status.busy": "2023-02-11T15:06:38.664324Z",
     "iopub.status.idle": "2023-02-11T15:06:38.674856Z",
     "shell.execute_reply": "2023-02-11T15:06:38.673301Z"
    },
    "papermill": {
     "duration": 0.451411,
     "end_time": "2023-02-11T15:06:38.681010",
     "exception": false,
     "start_time": "2023-02-11T15:06:38.229599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 93, 93, 16)        160       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 93, 93, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 93, 93, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 91, 91, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 45, 45, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 43, 43, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 21, 21, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 19, 19, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 9, 9, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               147968    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 312,097\n",
      "Trainable params: 312,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9b57f66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T15:06:39.615920Z",
     "iopub.status.busy": "2023-02-11T15:06:39.615439Z",
     "iopub.status.idle": "2023-02-11T15:06:39.622089Z",
     "shell.execute_reply": "2023-02-11T15:06:39.620523Z"
    },
    "papermill": {
     "duration": 0.447954,
     "end_time": "2023-02-11T15:06:39.626798",
     "exception": false,
     "start_time": "2023-02-11T15:06:39.178844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "#model = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20c2df48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T15:06:40.500521Z",
     "iopub.status.busy": "2023-02-11T15:06:40.500026Z",
     "iopub.status.idle": "2023-02-11T16:14:09.189683Z",
     "shell.execute_reply": "2023-02-11T16:14:09.188197Z"
    },
    "papermill": {
     "duration": 4049.126397,
     "end_time": "2023-02-11T16:14:09.192894",
     "exception": false,
     "start_time": "2023-02-11T15:06:40.066497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 15:06:40.910166: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 765428300 exceeds 10% of free system memory.\n",
      "2023-02-11 15:06:42.097103: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 765428300 exceeds 10% of free system memory.\n",
      "2023-02-11 15:06:42.923476: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 15:06:46.141265: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332/332 [==============================] - ETA: 0s - loss: 1.2959 - acc: 0.1891"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 15:06:59.767324: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 328076800 exceeds 10% of free system memory.\n",
      "2023-02-11 15:07:00.282715: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 328076800 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332/332 [==============================] - 18s 25ms/step - loss: 1.2959 - acc: 0.1891 - val_loss: 0.7042 - val_acc: 0.1372\n",
      "Epoch 2/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2950 - acc: 0.1356 - val_loss: 0.7130 - val_acc: 0.1372\n",
      "Epoch 3/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2922 - acc: 0.1785 - val_loss: 0.6840 - val_acc: 0.8078\n",
      "Epoch 4/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 1.2873 - acc: 0.2999 - val_loss: 0.6955 - val_acc: 0.5669\n",
      "Epoch 5/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 1.2844 - acc: 0.3687 - val_loss: 0.6703 - val_acc: 0.7995\n",
      "Epoch 6/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2807 - acc: 0.4089 - val_loss: 0.6900 - val_acc: 0.6270\n",
      "Epoch 7/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2789 - acc: 0.4211 - val_loss: 0.6886 - val_acc: 0.6005\n",
      "Epoch 8/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 1.2746 - acc: 0.4443 - val_loss: 0.6951 - val_acc: 0.5852\n",
      "Epoch 9/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2732 - acc: 0.4479 - val_loss: 0.7019 - val_acc: 0.5566\n",
      "Epoch 10/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2721 - acc: 0.4544 - val_loss: 0.6973 - val_acc: 0.5544\n",
      "Epoch 11/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2683 - acc: 0.4730 - val_loss: 0.7195 - val_acc: 0.4712\n",
      "Epoch 12/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2656 - acc: 0.4630 - val_loss: 0.6773 - val_acc: 0.6326\n",
      "Epoch 13/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2606 - acc: 0.5019 - val_loss: 0.7214 - val_acc: 0.4257\n",
      "Epoch 14/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2589 - acc: 0.4821 - val_loss: 0.7054 - val_acc: 0.4286\n",
      "Epoch 15/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 1.2558 - acc: 0.4634 - val_loss: 0.6701 - val_acc: 0.6388\n",
      "Epoch 16/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2535 - acc: 0.4968 - val_loss: 0.6804 - val_acc: 0.6253\n",
      "Epoch 17/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2506 - acc: 0.5071 - val_loss: 0.7043 - val_acc: 0.4583\n",
      "Epoch 18/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2482 - acc: 0.5118 - val_loss: 0.7040 - val_acc: 0.5150\n",
      "Epoch 19/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2425 - acc: 0.4984 - val_loss: 0.6735 - val_acc: 0.5782\n",
      "Epoch 20/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2387 - acc: 0.5085 - val_loss: 0.7188 - val_acc: 0.4788\n",
      "Epoch 21/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2413 - acc: 0.5062 - val_loss: 0.6753 - val_acc: 0.5651\n",
      "Epoch 22/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2291 - acc: 0.5157 - val_loss: 0.6791 - val_acc: 0.5627\n",
      "Epoch 23/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2271 - acc: 0.5202 - val_loss: 0.6786 - val_acc: 0.5708\n",
      "Epoch 24/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2208 - acc: 0.5283 - val_loss: 0.6413 - val_acc: 0.6553\n",
      "Epoch 25/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 1.2146 - acc: 0.5403 - val_loss: 0.7442 - val_acc: 0.4108\n",
      "Epoch 26/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2131 - acc: 0.5381 - val_loss: 0.7049 - val_acc: 0.4685\n",
      "Epoch 27/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 1.2103 - acc: 0.5400 - val_loss: 0.6938 - val_acc: 0.5052\n",
      "Epoch 28/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 1.2001 - acc: 0.5468 - val_loss: 0.6597 - val_acc: 0.6209\n",
      "Epoch 29/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.2002 - acc: 0.5490 - val_loss: 0.6916 - val_acc: 0.5068\n",
      "Epoch 30/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.1910 - acc: 0.5576 - val_loss: 0.6810 - val_acc: 0.5272\n",
      "Epoch 31/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.1884 - acc: 0.5592 - val_loss: 0.7178 - val_acc: 0.4743\n",
      "Epoch 32/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 1.1786 - acc: 0.5700 - val_loss: 0.7496 - val_acc: 0.4255\n",
      "Epoch 33/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 1.1742 - acc: 0.5730 - val_loss: 0.7371 - val_acc: 0.4674\n",
      "Epoch 34/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.1647 - acc: 0.5744 - val_loss: 0.6889 - val_acc: 0.5155\n",
      "Epoch 35/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.1573 - acc: 0.5842 - val_loss: 0.7027 - val_acc: 0.4992\n",
      "Epoch 36/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.1581 - acc: 0.5815 - val_loss: 0.6896 - val_acc: 0.5492\n",
      "Epoch 37/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 1.1425 - acc: 0.5845 - val_loss: 0.6674 - val_acc: 0.5572\n",
      "Epoch 38/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 1.1410 - acc: 0.5937 - val_loss: 0.6821 - val_acc: 0.5379\n",
      "Epoch 39/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.1300 - acc: 0.5993 - val_loss: 0.7086 - val_acc: 0.5177\n",
      "Epoch 40/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.1142 - acc: 0.6162 - val_loss: 0.6741 - val_acc: 0.5460\n",
      "Epoch 41/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.1151 - acc: 0.6110 - val_loss: 0.6820 - val_acc: 0.5613\n",
      "Epoch 42/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.1051 - acc: 0.6195 - val_loss: 0.7025 - val_acc: 0.4905\n",
      "Epoch 43/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 1.0960 - acc: 0.6176 - val_loss: 0.7057 - val_acc: 0.5545\n",
      "Epoch 44/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.0846 - acc: 0.6315 - val_loss: 0.7345 - val_acc: 0.4860\n",
      "Epoch 45/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 1.0787 - acc: 0.6345 - val_loss: 0.6976 - val_acc: 0.5080\n",
      "Epoch 46/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 1.0647 - acc: 0.6437 - val_loss: 0.7199 - val_acc: 0.4930\n",
      "Epoch 47/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.0474 - acc: 0.6459 - val_loss: 0.6670 - val_acc: 0.5649\n",
      "Epoch 48/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 1.0528 - acc: 0.6463 - val_loss: 0.6320 - val_acc: 0.6480\n",
      "Epoch 49/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.0352 - acc: 0.6588 - val_loss: 0.6489 - val_acc: 0.6165\n",
      "Epoch 50/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 1.0330 - acc: 0.6600 - val_loss: 0.6818 - val_acc: 0.5627\n",
      "Epoch 51/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.0243 - acc: 0.6618 - val_loss: 0.6477 - val_acc: 0.6444\n",
      "Epoch 52/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 1.0176 - acc: 0.6624 - val_loss: 0.6513 - val_acc: 0.6373\n",
      "Epoch 53/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.9910 - acc: 0.6813 - val_loss: 0.6190 - val_acc: 0.6292\n",
      "Epoch 54/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.9928 - acc: 0.6788 - val_loss: 0.6752 - val_acc: 0.5802\n",
      "Epoch 55/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.9802 - acc: 0.6864 - val_loss: 0.6700 - val_acc: 0.5909\n",
      "Epoch 56/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.9652 - acc: 0.6920 - val_loss: 0.6288 - val_acc: 0.6620\n",
      "Epoch 57/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.9562 - acc: 0.6985 - val_loss: 0.6287 - val_acc: 0.6198\n",
      "Epoch 58/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.9523 - acc: 0.7004 - val_loss: 0.7172 - val_acc: 0.5319\n",
      "Epoch 59/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.9435 - acc: 0.6993 - val_loss: 0.6364 - val_acc: 0.6588\n",
      "Epoch 60/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.9255 - acc: 0.7078 - val_loss: 0.6311 - val_acc: 0.6177\n",
      "Epoch 61/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.9153 - acc: 0.7098 - val_loss: 0.5870 - val_acc: 0.7084\n",
      "Epoch 62/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.9102 - acc: 0.7227 - val_loss: 0.6049 - val_acc: 0.6794\n",
      "Epoch 63/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.8941 - acc: 0.7212 - val_loss: 0.6361 - val_acc: 0.6424\n",
      "Epoch 64/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.8896 - acc: 0.7256 - val_loss: 0.6143 - val_acc: 0.6593\n",
      "Epoch 65/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.8723 - acc: 0.7322 - val_loss: 0.6784 - val_acc: 0.6210\n",
      "Epoch 66/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.8697 - acc: 0.7321 - val_loss: 0.5236 - val_acc: 0.7605\n",
      "Epoch 67/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.8592 - acc: 0.7393 - val_loss: 0.6337 - val_acc: 0.6126\n",
      "Epoch 68/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.8538 - acc: 0.7415 - val_loss: 0.6601 - val_acc: 0.5848\n",
      "Epoch 69/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.8401 - acc: 0.7433 - val_loss: 0.5900 - val_acc: 0.6768\n",
      "Epoch 70/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.8426 - acc: 0.7493 - val_loss: 0.5780 - val_acc: 0.6882\n",
      "Epoch 71/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.8090 - acc: 0.7578 - val_loss: 0.6279 - val_acc: 0.6580\n",
      "Epoch 72/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.8096 - acc: 0.7563 - val_loss: 0.6247 - val_acc: 0.6441\n",
      "Epoch 73/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.8014 - acc: 0.7620 - val_loss: 0.5469 - val_acc: 0.7137\n",
      "Epoch 74/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.7983 - acc: 0.7650 - val_loss: 0.6583 - val_acc: 0.6243\n",
      "Epoch 75/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.7845 - acc: 0.7673 - val_loss: 0.6321 - val_acc: 0.6459\n",
      "Epoch 76/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.7757 - acc: 0.7650 - val_loss: 0.5249 - val_acc: 0.7596\n",
      "Epoch 77/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.7673 - acc: 0.7744 - val_loss: 0.6206 - val_acc: 0.6819\n",
      "Epoch 78/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.7575 - acc: 0.7822 - val_loss: 0.6164 - val_acc: 0.6707\n",
      "Epoch 79/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.7454 - acc: 0.7838 - val_loss: 0.6022 - val_acc: 0.6752\n",
      "Epoch 80/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.7375 - acc: 0.7848 - val_loss: 0.5582 - val_acc: 0.7392\n",
      "Epoch 81/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.7380 - acc: 0.7900 - val_loss: 0.6407 - val_acc: 0.6300\n",
      "Epoch 82/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.7312 - acc: 0.7845 - val_loss: 0.5865 - val_acc: 0.7108\n",
      "Epoch 83/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.7168 - acc: 0.7948 - val_loss: 0.5695 - val_acc: 0.7210\n",
      "Epoch 84/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.7050 - acc: 0.7943 - val_loss: 0.5823 - val_acc: 0.7179\n",
      "Epoch 85/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.7074 - acc: 0.7978 - val_loss: 0.5734 - val_acc: 0.7103\n",
      "Epoch 86/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.6885 - acc: 0.8035 - val_loss: 0.5709 - val_acc: 0.7149\n",
      "Epoch 87/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.6946 - acc: 0.7986 - val_loss: 0.5555 - val_acc: 0.7403\n",
      "Epoch 88/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.6731 - acc: 0.8094 - val_loss: 0.5783 - val_acc: 0.7179\n",
      "Epoch 89/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.6709 - acc: 0.8095 - val_loss: 0.6242 - val_acc: 0.6713\n",
      "Epoch 90/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.6907 - acc: 0.8046 - val_loss: 0.6178 - val_acc: 0.6713\n",
      "Epoch 91/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.6712 - acc: 0.8124 - val_loss: 0.5504 - val_acc: 0.7250\n",
      "Epoch 92/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.6533 - acc: 0.8121 - val_loss: 0.5821 - val_acc: 0.7219\n",
      "Epoch 93/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.6469 - acc: 0.8200 - val_loss: 0.5222 - val_acc: 0.7600\n",
      "Epoch 94/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.6279 - acc: 0.8230 - val_loss: 0.5782 - val_acc: 0.6970\n",
      "Epoch 95/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.6197 - acc: 0.8274 - val_loss: 0.5899 - val_acc: 0.7136\n",
      "Epoch 96/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.6357 - acc: 0.8251 - val_loss: 0.5460 - val_acc: 0.7287\n",
      "Epoch 97/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.6017 - acc: 0.8328 - val_loss: 0.6060 - val_acc: 0.7192\n",
      "Epoch 98/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.6094 - acc: 0.8243 - val_loss: 0.5442 - val_acc: 0.7597\n",
      "Epoch 99/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5975 - acc: 0.8335 - val_loss: 0.5422 - val_acc: 0.7437\n",
      "Epoch 100/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5956 - acc: 0.8356 - val_loss: 0.5616 - val_acc: 0.7356\n",
      "Epoch 101/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.6066 - acc: 0.8288 - val_loss: 0.5327 - val_acc: 0.7578\n",
      "Epoch 102/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.5877 - acc: 0.8395 - val_loss: 0.5717 - val_acc: 0.7382\n",
      "Epoch 103/600\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.5917 - acc: 0.8365 - val_loss: 0.5548 - val_acc: 0.7464\n",
      "Epoch 104/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.5708 - acc: 0.8463 - val_loss: 0.5596 - val_acc: 0.7509\n",
      "Epoch 105/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5688 - acc: 0.8465 - val_loss: 0.5550 - val_acc: 0.7241\n",
      "Epoch 106/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5588 - acc: 0.8462 - val_loss: 0.5346 - val_acc: 0.7533\n",
      "Epoch 107/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5387 - acc: 0.8514 - val_loss: 0.5780 - val_acc: 0.7174\n",
      "Epoch 108/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.5560 - acc: 0.8450 - val_loss: 0.5643 - val_acc: 0.7327\n",
      "Epoch 109/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5550 - acc: 0.8507 - val_loss: 0.5593 - val_acc: 0.7372\n",
      "Epoch 110/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5374 - acc: 0.8581 - val_loss: 0.5537 - val_acc: 0.7359\n",
      "Epoch 111/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5350 - acc: 0.8569 - val_loss: 0.5766 - val_acc: 0.7262\n",
      "Epoch 112/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5152 - acc: 0.8603 - val_loss: 0.5999 - val_acc: 0.7010\n",
      "Epoch 113/600\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.5120 - acc: 0.8608 - val_loss: 0.5329 - val_acc: 0.7599\n",
      "Epoch 114/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5278 - acc: 0.8561 - val_loss: 0.5464 - val_acc: 0.7515\n",
      "Epoch 115/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5124 - acc: 0.8599 - val_loss: 0.5014 - val_acc: 0.7938\n",
      "Epoch 116/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5080 - acc: 0.8649 - val_loss: 0.5374 - val_acc: 0.7649\n",
      "Epoch 117/600\n",
      "332/332 [==============================] - 9s 26ms/step - loss: 0.4921 - acc: 0.8664 - val_loss: 0.5383 - val_acc: 0.7760\n",
      "Epoch 118/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.5000 - acc: 0.8672 - val_loss: 0.5498 - val_acc: 0.7465\n",
      "Epoch 119/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4904 - acc: 0.8702 - val_loss: 0.5186 - val_acc: 0.7759\n",
      "Epoch 120/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4818 - acc: 0.8714 - val_loss: 0.5746 - val_acc: 0.7442\n",
      "Epoch 121/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4848 - acc: 0.8681 - val_loss: 0.5226 - val_acc: 0.7751\n",
      "Epoch 122/600\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.4861 - acc: 0.8717 - val_loss: 0.5200 - val_acc: 0.7621\n",
      "Epoch 123/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4660 - acc: 0.8779 - val_loss: 0.5451 - val_acc: 0.7663\n",
      "Epoch 124/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4646 - acc: 0.8746 - val_loss: 0.5526 - val_acc: 0.7669\n",
      "Epoch 125/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4551 - acc: 0.8819 - val_loss: 0.5225 - val_acc: 0.7654\n",
      "Epoch 126/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4572 - acc: 0.8797 - val_loss: 0.5838 - val_acc: 0.7355\n",
      "Epoch 127/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.4606 - acc: 0.8761 - val_loss: 0.5369 - val_acc: 0.7632\n",
      "Epoch 128/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4514 - acc: 0.8811 - val_loss: 0.5369 - val_acc: 0.7724\n",
      "Epoch 129/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4467 - acc: 0.8861 - val_loss: 0.5316 - val_acc: 0.7566\n",
      "Epoch 130/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4250 - acc: 0.8868 - val_loss: 0.5448 - val_acc: 0.7607\n",
      "Epoch 131/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.4318 - acc: 0.8856 - val_loss: 0.5800 - val_acc: 0.7309\n",
      "Epoch 132/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.4315 - acc: 0.8828 - val_loss: 0.5280 - val_acc: 0.7750\n",
      "Epoch 133/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4481 - acc: 0.8811 - val_loss: 0.5254 - val_acc: 0.7853\n",
      "Epoch 134/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4359 - acc: 0.8838 - val_loss: 0.5385 - val_acc: 0.7851\n",
      "Epoch 135/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4350 - acc: 0.8847 - val_loss: 0.5614 - val_acc: 0.7552\n",
      "Epoch 136/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.4090 - acc: 0.8957 - val_loss: 0.5375 - val_acc: 0.7721\n",
      "Epoch 137/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.4225 - acc: 0.8886 - val_loss: 0.5096 - val_acc: 0.7960\n",
      "Epoch 138/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4037 - acc: 0.8951 - val_loss: 0.5228 - val_acc: 0.7762\n",
      "Epoch 139/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4050 - acc: 0.8948 - val_loss: 0.5228 - val_acc: 0.7826\n",
      "Epoch 140/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.4060 - acc: 0.8952 - val_loss: 0.5166 - val_acc: 0.7964\n",
      "Epoch 141/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.3974 - acc: 0.9000 - val_loss: 0.5317 - val_acc: 0.7798\n",
      "Epoch 142/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.4038 - acc: 0.8957 - val_loss: 0.5963 - val_acc: 0.7439\n",
      "Epoch 143/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3810 - acc: 0.9021 - val_loss: 0.5538 - val_acc: 0.7655\n",
      "Epoch 144/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3751 - acc: 0.9042 - val_loss: 0.5705 - val_acc: 0.7676\n",
      "Epoch 145/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.3770 - acc: 0.9018 - val_loss: 0.5787 - val_acc: 0.7677\n",
      "Epoch 146/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3902 - acc: 0.8989 - val_loss: 0.5534 - val_acc: 0.7711\n",
      "Epoch 147/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3861 - acc: 0.9005 - val_loss: 0.5614 - val_acc: 0.7569\n",
      "Epoch 148/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3750 - acc: 0.9015 - val_loss: 0.5203 - val_acc: 0.7990\n",
      "Epoch 149/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3792 - acc: 0.9030 - val_loss: 0.5614 - val_acc: 0.7749\n",
      "Epoch 150/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.3679 - acc: 0.9030 - val_loss: 0.5544 - val_acc: 0.7696\n",
      "Epoch 151/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3672 - acc: 0.9042 - val_loss: 0.5393 - val_acc: 0.7975\n",
      "Epoch 152/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3700 - acc: 0.9058 - val_loss: 0.5721 - val_acc: 0.7625\n",
      "Epoch 153/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3606 - acc: 0.9054 - val_loss: 0.5489 - val_acc: 0.7785\n",
      "Epoch 154/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.3611 - acc: 0.9073 - val_loss: 0.5257 - val_acc: 0.7987\n",
      "Epoch 155/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.3681 - acc: 0.9078 - val_loss: 0.5359 - val_acc: 0.7828\n",
      "Epoch 156/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3585 - acc: 0.9096 - val_loss: 0.5370 - val_acc: 0.7965\n",
      "Epoch 157/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3458 - acc: 0.9132 - val_loss: 0.5457 - val_acc: 0.7846\n",
      "Epoch 158/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3534 - acc: 0.9095 - val_loss: 0.5187 - val_acc: 0.7950\n",
      "Epoch 159/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3446 - acc: 0.9112 - val_loss: 0.4976 - val_acc: 0.8182\n",
      "Epoch 160/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.3416 - acc: 0.9129 - val_loss: 0.5425 - val_acc: 0.7940\n",
      "Epoch 161/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.3559 - acc: 0.9090 - val_loss: 0.5325 - val_acc: 0.7920\n",
      "Epoch 162/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3417 - acc: 0.9146 - val_loss: 0.5402 - val_acc: 0.7947\n",
      "Epoch 163/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3322 - acc: 0.9167 - val_loss: 0.5149 - val_acc: 0.8017\n",
      "Epoch 164/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.3318 - acc: 0.9126 - val_loss: 0.5553 - val_acc: 0.7888\n",
      "Epoch 165/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3232 - acc: 0.9191 - val_loss: 0.5518 - val_acc: 0.7907\n",
      "Epoch 166/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.3253 - acc: 0.9185 - val_loss: 0.5778 - val_acc: 0.7793\n",
      "Epoch 167/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3076 - acc: 0.9236 - val_loss: 0.5456 - val_acc: 0.8002\n",
      "Epoch 168/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3179 - acc: 0.9189 - val_loss: 0.5184 - val_acc: 0.8176\n",
      "Epoch 169/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.3198 - acc: 0.9198 - val_loss: 0.5494 - val_acc: 0.7884\n",
      "Epoch 170/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.3265 - acc: 0.9167 - val_loss: 0.5500 - val_acc: 0.8009\n",
      "Epoch 171/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.3224 - acc: 0.9170 - val_loss: 0.5364 - val_acc: 0.7967\n",
      "Epoch 172/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2946 - acc: 0.9268 - val_loss: 0.5659 - val_acc: 0.7854\n",
      "Epoch 173/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3197 - acc: 0.9170 - val_loss: 0.5429 - val_acc: 0.7996\n",
      "Epoch 174/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2946 - acc: 0.9278 - val_loss: 0.5740 - val_acc: 0.7953\n",
      "Epoch 175/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.3166 - acc: 0.9193 - val_loss: 0.5529 - val_acc: 0.7943\n",
      "Epoch 176/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.3047 - acc: 0.9243 - val_loss: 0.5375 - val_acc: 0.8020\n",
      "Epoch 177/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2986 - acc: 0.9274 - val_loss: 0.5221 - val_acc: 0.8107\n",
      "Epoch 178/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2964 - acc: 0.9267 - val_loss: 0.5588 - val_acc: 0.7835\n",
      "Epoch 179/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2941 - acc: 0.9274 - val_loss: 0.5745 - val_acc: 0.7810\n",
      "Epoch 180/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.3026 - acc: 0.9244 - val_loss: 0.5748 - val_acc: 0.7741\n",
      "Epoch 181/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.3020 - acc: 0.9252 - val_loss: 0.5818 - val_acc: 0.7744\n",
      "Epoch 182/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.3045 - acc: 0.9232 - val_loss: 0.5526 - val_acc: 0.7951\n",
      "Epoch 183/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2724 - acc: 0.9320 - val_loss: 0.5351 - val_acc: 0.8191\n",
      "Epoch 184/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2870 - acc: 0.9277 - val_loss: 0.5413 - val_acc: 0.8147\n",
      "Epoch 185/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.2969 - acc: 0.9262 - val_loss: 0.5441 - val_acc: 0.8056\n",
      "Epoch 186/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2867 - acc: 0.9315 - val_loss: 0.5448 - val_acc: 0.7995\n",
      "Epoch 187/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2837 - acc: 0.9308 - val_loss: 0.5248 - val_acc: 0.8187\n",
      "Epoch 188/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2933 - acc: 0.9292 - val_loss: 0.5221 - val_acc: 0.8100\n",
      "Epoch 189/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2717 - acc: 0.9348 - val_loss: 0.5473 - val_acc: 0.8025\n",
      "Epoch 190/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2900 - acc: 0.9289 - val_loss: 0.5598 - val_acc: 0.7907\n",
      "Epoch 191/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.2770 - acc: 0.9327 - val_loss: 0.5197 - val_acc: 0.8179\n",
      "Epoch 192/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.2677 - acc: 0.9325 - val_loss: 0.5397 - val_acc: 0.8202\n",
      "Epoch 193/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.2598 - acc: 0.9367 - val_loss: 0.5129 - val_acc: 0.8341\n",
      "Epoch 194/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2760 - acc: 0.9342 - val_loss: 0.5348 - val_acc: 0.8205\n",
      "Epoch 195/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2571 - acc: 0.9373 - val_loss: 0.5729 - val_acc: 0.7930\n",
      "Epoch 196/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2836 - acc: 0.9313 - val_loss: 0.5816 - val_acc: 0.7841\n",
      "Epoch 197/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2721 - acc: 0.9351 - val_loss: 0.5733 - val_acc: 0.7871\n",
      "Epoch 198/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2634 - acc: 0.9345 - val_loss: 0.5694 - val_acc: 0.8011\n",
      "Epoch 199/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2680 - acc: 0.9347 - val_loss: 0.5534 - val_acc: 0.8134\n",
      "Epoch 200/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2644 - acc: 0.9357 - val_loss: 0.5324 - val_acc: 0.8154\n",
      "Epoch 201/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2545 - acc: 0.9369 - val_loss: 0.5637 - val_acc: 0.7992\n",
      "Epoch 202/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.2445 - acc: 0.9414 - val_loss: 0.5330 - val_acc: 0.8168\n",
      "Epoch 203/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2671 - acc: 0.9369 - val_loss: 0.5703 - val_acc: 0.7920\n",
      "Epoch 204/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2767 - acc: 0.9356 - val_loss: 0.5235 - val_acc: 0.8119\n",
      "Epoch 205/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2525 - acc: 0.9386 - val_loss: 0.5493 - val_acc: 0.8091\n",
      "Epoch 206/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2535 - acc: 0.9406 - val_loss: 0.5597 - val_acc: 0.8111\n",
      "Epoch 207/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2542 - acc: 0.9396 - val_loss: 0.5568 - val_acc: 0.8091\n",
      "Epoch 208/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2582 - acc: 0.9388 - val_loss: 0.5419 - val_acc: 0.8183\n",
      "Epoch 209/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.2397 - acc: 0.9415 - val_loss: 0.5422 - val_acc: 0.8177\n",
      "Epoch 210/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2560 - acc: 0.9392 - val_loss: 0.5379 - val_acc: 0.8239\n",
      "Epoch 211/600\n",
      "332/332 [==============================] - 8s 24ms/step - loss: 0.2243 - acc: 0.9471 - val_loss: 0.5424 - val_acc: 0.8319\n",
      "Epoch 212/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.2424 - acc: 0.9424 - val_loss: 0.5837 - val_acc: 0.8053\n",
      "Epoch 213/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2447 - acc: 0.9429 - val_loss: 0.5316 - val_acc: 0.8179\n",
      "Epoch 214/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.2474 - acc: 0.9412 - val_loss: 0.5702 - val_acc: 0.7958\n",
      "Epoch 215/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2513 - acc: 0.9410 - val_loss: 0.5309 - val_acc: 0.8224\n",
      "Epoch 216/600\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.2307 - acc: 0.9448 - val_loss: 0.5453 - val_acc: 0.8290\n",
      "Epoch 217/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2540 - acc: 0.9405 - val_loss: 0.5136 - val_acc: 0.8319\n",
      "Epoch 218/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2325 - acc: 0.9460 - val_loss: 0.5426 - val_acc: 0.8156\n",
      "Epoch 219/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2329 - acc: 0.9467 - val_loss: 0.5292 - val_acc: 0.8227\n",
      "Epoch 220/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2368 - acc: 0.9436 - val_loss: 0.5195 - val_acc: 0.8311\n",
      "Epoch 221/600\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.2314 - acc: 0.9476 - val_loss: 0.5665 - val_acc: 0.8081\n",
      "Epoch 222/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2346 - acc: 0.9449 - val_loss: 0.5419 - val_acc: 0.8199\n",
      "Epoch 223/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2226 - acc: 0.9464 - val_loss: 0.5761 - val_acc: 0.8014\n",
      "Epoch 224/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2198 - acc: 0.9480 - val_loss: 0.5443 - val_acc: 0.8228\n",
      "Epoch 225/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2268 - acc: 0.9448 - val_loss: 0.5569 - val_acc: 0.8198\n",
      "Epoch 226/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2147 - acc: 0.9512 - val_loss: 0.5208 - val_acc: 0.8423\n",
      "Epoch 227/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2174 - acc: 0.9487 - val_loss: 0.5389 - val_acc: 0.8253\n",
      "Epoch 228/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2221 - acc: 0.9470 - val_loss: 0.5296 - val_acc: 0.8337\n",
      "Epoch 229/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2226 - acc: 0.9476 - val_loss: 0.5269 - val_acc: 0.8322\n",
      "Epoch 230/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2180 - acc: 0.9512 - val_loss: 0.5528 - val_acc: 0.8138\n",
      "Epoch 231/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2095 - acc: 0.9490 - val_loss: 0.5376 - val_acc: 0.8175\n",
      "Epoch 232/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2174 - acc: 0.9481 - val_loss: 0.5376 - val_acc: 0.8280\n",
      "Epoch 233/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2175 - acc: 0.9487 - val_loss: 0.5111 - val_acc: 0.8451\n",
      "Epoch 234/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2077 - acc: 0.9518 - val_loss: 0.5371 - val_acc: 0.8271\n",
      "Epoch 235/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2199 - acc: 0.9460 - val_loss: 0.5364 - val_acc: 0.8253\n",
      "Epoch 236/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.2061 - acc: 0.9538 - val_loss: 0.5474 - val_acc: 0.8179\n",
      "Epoch 237/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2111 - acc: 0.9506 - val_loss: 0.5364 - val_acc: 0.8234\n",
      "Epoch 238/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2026 - acc: 0.9529 - val_loss: 0.5518 - val_acc: 0.8224\n",
      "Epoch 239/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2114 - acc: 0.9522 - val_loss: 0.5484 - val_acc: 0.8247\n",
      "Epoch 240/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2117 - acc: 0.9513 - val_loss: 0.5238 - val_acc: 0.8293\n",
      "Epoch 241/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1981 - acc: 0.9544 - val_loss: 0.5418 - val_acc: 0.8335\n",
      "Epoch 242/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2032 - acc: 0.9512 - val_loss: 0.5407 - val_acc: 0.8344\n",
      "Epoch 243/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.2099 - acc: 0.9510 - val_loss: 0.5597 - val_acc: 0.8192\n",
      "Epoch 244/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.2004 - acc: 0.9545 - val_loss: 0.5406 - val_acc: 0.8315\n",
      "Epoch 245/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.2034 - acc: 0.9554 - val_loss: 0.5136 - val_acc: 0.8458\n",
      "Epoch 246/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2060 - acc: 0.9506 - val_loss: 0.5475 - val_acc: 0.8204\n",
      "Epoch 247/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2074 - acc: 0.9521 - val_loss: 0.5446 - val_acc: 0.8211\n",
      "Epoch 248/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1951 - acc: 0.9526 - val_loss: 0.5327 - val_acc: 0.8429\n",
      "Epoch 249/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2000 - acc: 0.9528 - val_loss: 0.5308 - val_acc: 0.8341\n",
      "Epoch 250/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.2059 - acc: 0.9534 - val_loss: 0.5353 - val_acc: 0.8264\n",
      "Epoch 251/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1888 - acc: 0.9556 - val_loss: 0.5327 - val_acc: 0.8283\n",
      "Epoch 252/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1899 - acc: 0.9565 - val_loss: 0.5448 - val_acc: 0.8289\n",
      "Epoch 253/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1863 - acc: 0.9565 - val_loss: 0.5378 - val_acc: 0.8366\n",
      "Epoch 254/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1843 - acc: 0.9595 - val_loss: 0.5266 - val_acc: 0.8443\n",
      "Epoch 255/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.1754 - acc: 0.9591 - val_loss: 0.5736 - val_acc: 0.8160\n",
      "Epoch 256/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1934 - acc: 0.9561 - val_loss: 0.5532 - val_acc: 0.8276\n",
      "Epoch 257/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.2006 - acc: 0.9529 - val_loss: 0.5370 - val_acc: 0.8298\n",
      "Epoch 258/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1804 - acc: 0.9601 - val_loss: 0.5269 - val_acc: 0.8380\n",
      "Epoch 259/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1780 - acc: 0.9586 - val_loss: 0.5254 - val_acc: 0.8423\n",
      "Epoch 260/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1839 - acc: 0.9609 - val_loss: 0.5704 - val_acc: 0.8046\n",
      "Epoch 261/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.1864 - acc: 0.9579 - val_loss: 0.5719 - val_acc: 0.8108\n",
      "Epoch 262/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1702 - acc: 0.9612 - val_loss: 0.5447 - val_acc: 0.8283\n",
      "Epoch 263/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1957 - acc: 0.9562 - val_loss: 0.5167 - val_acc: 0.8395\n",
      "Epoch 264/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1836 - acc: 0.9586 - val_loss: 0.5240 - val_acc: 0.8413\n",
      "Epoch 265/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1607 - acc: 0.9626 - val_loss: 0.5445 - val_acc: 0.8360\n",
      "Epoch 266/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1711 - acc: 0.9618 - val_loss: 0.5679 - val_acc: 0.8277\n",
      "Epoch 267/600\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.1932 - acc: 0.9550 - val_loss: 0.5931 - val_acc: 0.8030\n",
      "Epoch 268/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1778 - acc: 0.9594 - val_loss: 0.5862 - val_acc: 0.8063\n",
      "Epoch 269/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1726 - acc: 0.9587 - val_loss: 0.5505 - val_acc: 0.8324\n",
      "Epoch 270/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1694 - acc: 0.9610 - val_loss: 0.5437 - val_acc: 0.8454\n",
      "Epoch 271/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.1681 - acc: 0.9614 - val_loss: 0.5443 - val_acc: 0.8449\n",
      "Epoch 272/600\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.1775 - acc: 0.9633 - val_loss: 0.5475 - val_acc: 0.8344\n",
      "Epoch 273/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1545 - acc: 0.9657 - val_loss: 0.5698 - val_acc: 0.8310\n",
      "Epoch 274/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.1799 - acc: 0.9594 - val_loss: 0.5319 - val_acc: 0.8381\n",
      "Epoch 275/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1757 - acc: 0.9615 - val_loss: 0.5677 - val_acc: 0.8175\n",
      "Epoch 276/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.1738 - acc: 0.9607 - val_loss: 0.5643 - val_acc: 0.8167\n",
      "Epoch 277/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1651 - acc: 0.9622 - val_loss: 0.5498 - val_acc: 0.8331\n",
      "Epoch 278/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1670 - acc: 0.9625 - val_loss: 0.5449 - val_acc: 0.8417\n",
      "Epoch 279/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1615 - acc: 0.9636 - val_loss: 0.5618 - val_acc: 0.8288\n",
      "Epoch 280/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1773 - acc: 0.9605 - val_loss: 0.5496 - val_acc: 0.8355\n",
      "Epoch 281/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1716 - acc: 0.9612 - val_loss: 0.5241 - val_acc: 0.8494\n",
      "Epoch 282/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.1667 - acc: 0.9626 - val_loss: 0.5290 - val_acc: 0.8415\n",
      "Epoch 283/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1666 - acc: 0.9635 - val_loss: 0.5539 - val_acc: 0.8198\n",
      "Epoch 284/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1554 - acc: 0.9650 - val_loss: 0.5583 - val_acc: 0.8299\n",
      "Epoch 285/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1649 - acc: 0.9626 - val_loss: 0.5352 - val_acc: 0.8458\n",
      "Epoch 286/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1628 - acc: 0.9639 - val_loss: 0.5372 - val_acc: 0.8384\n",
      "Epoch 287/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1819 - acc: 0.9597 - val_loss: 0.5643 - val_acc: 0.8162\n",
      "Epoch 288/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1654 - acc: 0.9628 - val_loss: 0.5398 - val_acc: 0.8349\n",
      "Epoch 289/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1550 - acc: 0.9640 - val_loss: 0.5376 - val_acc: 0.8486\n",
      "Epoch 290/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1535 - acc: 0.9665 - val_loss: 0.5315 - val_acc: 0.8495\n",
      "Epoch 291/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1517 - acc: 0.9670 - val_loss: 0.5753 - val_acc: 0.8189\n",
      "Epoch 292/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1567 - acc: 0.9668 - val_loss: 0.5794 - val_acc: 0.8202\n",
      "Epoch 293/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1589 - acc: 0.9655 - val_loss: 0.5168 - val_acc: 0.8509\n",
      "Epoch 294/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1458 - acc: 0.9676 - val_loss: 0.5483 - val_acc: 0.8424\n",
      "Epoch 295/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1400 - acc: 0.9703 - val_loss: 0.5380 - val_acc: 0.8554\n",
      "Epoch 296/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1582 - acc: 0.9647 - val_loss: 0.5652 - val_acc: 0.8347\n",
      "Epoch 297/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1465 - acc: 0.9668 - val_loss: 0.5470 - val_acc: 0.8455\n",
      "Epoch 298/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1589 - acc: 0.9646 - val_loss: 0.5371 - val_acc: 0.8438\n",
      "Epoch 299/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1524 - acc: 0.9670 - val_loss: 0.5394 - val_acc: 0.8418\n",
      "Epoch 300/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1435 - acc: 0.9687 - val_loss: 0.5448 - val_acc: 0.8440\n",
      "Epoch 301/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1480 - acc: 0.9671 - val_loss: 0.5455 - val_acc: 0.8497\n",
      "Epoch 302/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.1495 - acc: 0.9648 - val_loss: 0.5415 - val_acc: 0.8512\n",
      "Epoch 303/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1589 - acc: 0.9642 - val_loss: 0.5226 - val_acc: 0.8533\n",
      "Epoch 304/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1488 - acc: 0.9679 - val_loss: 0.6049 - val_acc: 0.8158\n",
      "Epoch 305/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1566 - acc: 0.9652 - val_loss: 0.5647 - val_acc: 0.8368\n",
      "Epoch 306/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1368 - acc: 0.9692 - val_loss: 0.5449 - val_acc: 0.8460\n",
      "Epoch 307/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1439 - acc: 0.9693 - val_loss: 0.5460 - val_acc: 0.8505\n",
      "Epoch 308/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1559 - acc: 0.9673 - val_loss: 0.5361 - val_acc: 0.8542\n",
      "Epoch 309/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.1508 - acc: 0.9663 - val_loss: 0.5661 - val_acc: 0.8336\n",
      "Epoch 310/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1467 - acc: 0.9699 - val_loss: 0.5782 - val_acc: 0.8320\n",
      "Epoch 311/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1334 - acc: 0.9707 - val_loss: 0.5736 - val_acc: 0.8421\n",
      "Epoch 312/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1494 - acc: 0.9684 - val_loss: 0.5427 - val_acc: 0.8488\n",
      "Epoch 313/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1509 - acc: 0.9660 - val_loss: 0.5422 - val_acc: 0.8421\n",
      "Epoch 314/600\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.1411 - acc: 0.9696 - val_loss: 0.5540 - val_acc: 0.8396\n",
      "Epoch 315/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1488 - acc: 0.9683 - val_loss: 0.5518 - val_acc: 0.8381\n",
      "Epoch 316/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.1429 - acc: 0.9693 - val_loss: 0.5292 - val_acc: 0.8567\n",
      "Epoch 317/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1394 - acc: 0.9706 - val_loss: 0.5661 - val_acc: 0.8292\n",
      "Epoch 318/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1387 - acc: 0.9698 - val_loss: 0.5845 - val_acc: 0.8292\n",
      "Epoch 319/600\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.1335 - acc: 0.9717 - val_loss: 0.5518 - val_acc: 0.8500\n",
      "Epoch 320/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1442 - acc: 0.9698 - val_loss: 0.5726 - val_acc: 0.8358\n",
      "Epoch 321/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.1304 - acc: 0.9710 - val_loss: 0.5484 - val_acc: 0.8445\n",
      "Epoch 322/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1402 - acc: 0.9700 - val_loss: 0.5724 - val_acc: 0.8324\n",
      "Epoch 323/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.1425 - acc: 0.9673 - val_loss: 0.5440 - val_acc: 0.8553\n",
      "Epoch 324/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1441 - acc: 0.9687 - val_loss: 0.5484 - val_acc: 0.8447\n",
      "Epoch 325/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1408 - acc: 0.9698 - val_loss: 0.5508 - val_acc: 0.8343\n",
      "Epoch 326/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1221 - acc: 0.9726 - val_loss: 0.5364 - val_acc: 0.8608\n",
      "Epoch 327/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1330 - acc: 0.9725 - val_loss: 0.5341 - val_acc: 0.8506\n",
      "Epoch 328/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1291 - acc: 0.9701 - val_loss: 0.5548 - val_acc: 0.8439\n",
      "Epoch 329/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1413 - acc: 0.9693 - val_loss: 0.5420 - val_acc: 0.8508\n",
      "Epoch 330/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1320 - acc: 0.9732 - val_loss: 0.5471 - val_acc: 0.8498\n",
      "Epoch 331/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1250 - acc: 0.9705 - val_loss: 0.5409 - val_acc: 0.8488\n",
      "Epoch 332/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1221 - acc: 0.9737 - val_loss: 0.5911 - val_acc: 0.8252\n",
      "Epoch 333/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1313 - acc: 0.9700 - val_loss: 0.5611 - val_acc: 0.8460\n",
      "Epoch 334/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1388 - acc: 0.9708 - val_loss: 0.5580 - val_acc: 0.8379\n",
      "Epoch 335/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.1365 - acc: 0.9705 - val_loss: 0.5666 - val_acc: 0.8353\n",
      "Epoch 336/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1243 - acc: 0.9737 - val_loss: 0.5464 - val_acc: 0.8462\n",
      "Epoch 337/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1431 - acc: 0.9694 - val_loss: 0.5361 - val_acc: 0.8506\n",
      "Epoch 338/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1227 - acc: 0.9738 - val_loss: 0.5779 - val_acc: 0.8353\n",
      "Epoch 339/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1370 - acc: 0.9724 - val_loss: 0.5982 - val_acc: 0.8246\n",
      "Epoch 340/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1223 - acc: 0.9729 - val_loss: 0.5284 - val_acc: 0.8650\n",
      "Epoch 341/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1216 - acc: 0.9749 - val_loss: 0.5467 - val_acc: 0.8464\n",
      "Epoch 342/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1313 - acc: 0.9726 - val_loss: 0.5429 - val_acc: 0.8529\n",
      "Epoch 343/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1238 - acc: 0.9738 - val_loss: 0.5330 - val_acc: 0.8553\n",
      "Epoch 344/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1154 - acc: 0.9750 - val_loss: 0.5633 - val_acc: 0.8336\n",
      "Epoch 345/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1223 - acc: 0.9729 - val_loss: 0.5554 - val_acc: 0.8439\n",
      "Epoch 346/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1155 - acc: 0.9755 - val_loss: 0.5536 - val_acc: 0.8518\n",
      "Epoch 347/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1205 - acc: 0.9738 - val_loss: 0.5494 - val_acc: 0.8476\n",
      "Epoch 348/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.1188 - acc: 0.9736 - val_loss: 0.5497 - val_acc: 0.8480\n",
      "Epoch 349/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1192 - acc: 0.9727 - val_loss: 0.5435 - val_acc: 0.8575\n",
      "Epoch 350/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1188 - acc: 0.9753 - val_loss: 0.5666 - val_acc: 0.8399\n",
      "Epoch 351/600\n",
      "332/332 [==============================] - 8s 24ms/step - loss: 0.1210 - acc: 0.9730 - val_loss: 0.5562 - val_acc: 0.8460\n",
      "Epoch 352/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1193 - acc: 0.9734 - val_loss: 0.5741 - val_acc: 0.8467\n",
      "Epoch 353/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1104 - acc: 0.9754 - val_loss: 0.5830 - val_acc: 0.8389\n",
      "Epoch 354/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1216 - acc: 0.9745 - val_loss: 0.5846 - val_acc: 0.8329\n",
      "Epoch 355/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.1308 - acc: 0.9722 - val_loss: 0.5632 - val_acc: 0.8371\n",
      "Epoch 356/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.1304 - acc: 0.9721 - val_loss: 0.5525 - val_acc: 0.8502\n",
      "Epoch 357/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1252 - acc: 0.9740 - val_loss: 0.5740 - val_acc: 0.8340\n",
      "Epoch 358/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1027 - acc: 0.9784 - val_loss: 0.5794 - val_acc: 0.8333\n",
      "Epoch 359/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1206 - acc: 0.9752 - val_loss: 0.5297 - val_acc: 0.8562\n",
      "Epoch 360/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1226 - acc: 0.9741 - val_loss: 0.5437 - val_acc: 0.8501\n",
      "Epoch 361/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1220 - acc: 0.9736 - val_loss: 0.5675 - val_acc: 0.8393\n",
      "Epoch 362/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1163 - acc: 0.9760 - val_loss: 0.5977 - val_acc: 0.8265\n",
      "Epoch 363/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1192 - acc: 0.9744 - val_loss: 0.5718 - val_acc: 0.8404\n",
      "Epoch 364/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1103 - acc: 0.9756 - val_loss: 0.5551 - val_acc: 0.8589\n",
      "Epoch 365/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1115 - acc: 0.9768 - val_loss: 0.5803 - val_acc: 0.8420\n",
      "Epoch 366/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1156 - acc: 0.9759 - val_loss: 0.5966 - val_acc: 0.8364\n",
      "Epoch 367/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1225 - acc: 0.9742 - val_loss: 0.5800 - val_acc: 0.8245\n",
      "Epoch 368/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1142 - acc: 0.9765 - val_loss: 0.5646 - val_acc: 0.8419\n",
      "Epoch 369/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1063 - acc: 0.9768 - val_loss: 0.5830 - val_acc: 0.8357\n",
      "Epoch 370/600\n",
      "332/332 [==============================] - 7s 23ms/step - loss: 0.1058 - acc: 0.9778 - val_loss: 0.5582 - val_acc: 0.8501\n",
      "Epoch 371/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1078 - acc: 0.9774 - val_loss: 0.5739 - val_acc: 0.8335\n",
      "Epoch 372/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1126 - acc: 0.9756 - val_loss: 0.5539 - val_acc: 0.8541\n",
      "Epoch 373/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1164 - acc: 0.9759 - val_loss: 0.5487 - val_acc: 0.8407\n",
      "Epoch 374/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.1183 - acc: 0.9756 - val_loss: 0.5550 - val_acc: 0.8476\n",
      "Epoch 375/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1197 - acc: 0.9749 - val_loss: 0.5632 - val_acc: 0.8460\n",
      "Epoch 376/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1026 - acc: 0.9774 - val_loss: 0.5838 - val_acc: 0.8398\n",
      "Epoch 377/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1148 - acc: 0.9764 - val_loss: 0.5648 - val_acc: 0.8557\n",
      "Epoch 378/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.1174 - acc: 0.9762 - val_loss: 0.5915 - val_acc: 0.8322\n",
      "Epoch 379/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1085 - acc: 0.9769 - val_loss: 0.6011 - val_acc: 0.8197\n",
      "Epoch 380/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1140 - acc: 0.9756 - val_loss: 0.5710 - val_acc: 0.8410\n",
      "Epoch 381/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1066 - acc: 0.9772 - val_loss: 0.5746 - val_acc: 0.8390\n",
      "Epoch 382/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1129 - acc: 0.9767 - val_loss: 0.5520 - val_acc: 0.8423\n",
      "Epoch 383/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.1067 - acc: 0.9768 - val_loss: 0.5655 - val_acc: 0.8522\n",
      "Epoch 384/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0967 - acc: 0.9799 - val_loss: 0.5765 - val_acc: 0.8404\n",
      "Epoch 385/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1075 - acc: 0.9775 - val_loss: 0.5690 - val_acc: 0.8521\n",
      "Epoch 386/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0985 - acc: 0.9802 - val_loss: 0.5699 - val_acc: 0.8513\n",
      "Epoch 387/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1151 - acc: 0.9771 - val_loss: 0.5580 - val_acc: 0.8518\n",
      "Epoch 388/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1139 - acc: 0.9769 - val_loss: 0.5616 - val_acc: 0.8404\n",
      "Epoch 389/600\n",
      "332/332 [==============================] - 7s 23ms/step - loss: 0.1129 - acc: 0.9769 - val_loss: 0.5562 - val_acc: 0.8331\n",
      "Epoch 390/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1003 - acc: 0.9788 - val_loss: 0.5711 - val_acc: 0.8299\n",
      "Epoch 391/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1022 - acc: 0.9785 - val_loss: 0.5585 - val_acc: 0.8413\n",
      "Epoch 392/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.1014 - acc: 0.9792 - val_loss: 0.5604 - val_acc: 0.8483\n",
      "Epoch 393/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1077 - acc: 0.9775 - val_loss: 0.5580 - val_acc: 0.8517\n",
      "Epoch 394/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1012 - acc: 0.9796 - val_loss: 0.5947 - val_acc: 0.8265\n",
      "Epoch 395/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1046 - acc: 0.9768 - val_loss: 0.5695 - val_acc: 0.8487\n",
      "Epoch 396/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1024 - acc: 0.9784 - val_loss: 0.5798 - val_acc: 0.8342\n",
      "Epoch 397/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0946 - acc: 0.9804 - val_loss: 0.5701 - val_acc: 0.8511\n",
      "Epoch 398/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0998 - acc: 0.9795 - val_loss: 0.5988 - val_acc: 0.8362\n",
      "Epoch 399/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1173 - acc: 0.9755 - val_loss: 0.5778 - val_acc: 0.8320\n",
      "Epoch 400/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0990 - acc: 0.9790 - val_loss: 0.5583 - val_acc: 0.8468\n",
      "Epoch 401/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0887 - acc: 0.9811 - val_loss: 0.5624 - val_acc: 0.8606\n",
      "Epoch 402/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1032 - acc: 0.9776 - val_loss: 0.5641 - val_acc: 0.8523\n",
      "Epoch 403/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1018 - acc: 0.9793 - val_loss: 0.5593 - val_acc: 0.8529\n",
      "Epoch 404/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1060 - acc: 0.9787 - val_loss: 0.5904 - val_acc: 0.8334\n",
      "Epoch 405/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0953 - acc: 0.9789 - val_loss: 0.5923 - val_acc: 0.8327\n",
      "Epoch 406/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0959 - acc: 0.9792 - val_loss: 0.5592 - val_acc: 0.8532\n",
      "Epoch 407/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0970 - acc: 0.9801 - val_loss: 0.5796 - val_acc: 0.8412\n",
      "Epoch 408/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0966 - acc: 0.9814 - val_loss: 0.5779 - val_acc: 0.8434\n",
      "Epoch 409/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0981 - acc: 0.9793 - val_loss: 0.5634 - val_acc: 0.8577\n",
      "Epoch 410/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0936 - acc: 0.9814 - val_loss: 0.6117 - val_acc: 0.8269\n",
      "Epoch 411/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.1075 - acc: 0.9790 - val_loss: 0.5703 - val_acc: 0.8507\n",
      "Epoch 412/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0987 - acc: 0.9783 - val_loss: 0.5557 - val_acc: 0.8626\n",
      "Epoch 413/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1033 - acc: 0.9802 - val_loss: 0.5687 - val_acc: 0.8471\n",
      "Epoch 414/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1021 - acc: 0.9784 - val_loss: 0.5790 - val_acc: 0.8422\n",
      "Epoch 415/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0855 - acc: 0.9815 - val_loss: 0.5499 - val_acc: 0.8623\n",
      "Epoch 416/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0972 - acc: 0.9795 - val_loss: 0.5637 - val_acc: 0.8464\n",
      "Epoch 417/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1017 - acc: 0.9791 - val_loss: 0.5476 - val_acc: 0.8607\n",
      "Epoch 418/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1060 - acc: 0.9787 - val_loss: 0.5543 - val_acc: 0.8542\n",
      "Epoch 419/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0996 - acc: 0.9797 - val_loss: 0.5743 - val_acc: 0.8454\n",
      "Epoch 420/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0848 - acc: 0.9818 - val_loss: 0.5550 - val_acc: 0.8609\n",
      "Epoch 421/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1013 - acc: 0.9802 - val_loss: 0.5673 - val_acc: 0.8421\n",
      "Epoch 422/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0922 - acc: 0.9816 - val_loss: 0.5793 - val_acc: 0.8399\n",
      "Epoch 423/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0811 - acc: 0.9832 - val_loss: 0.5590 - val_acc: 0.8512\n",
      "Epoch 424/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0832 - acc: 0.9819 - val_loss: 0.5720 - val_acc: 0.8560\n",
      "Epoch 425/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0960 - acc: 0.9804 - val_loss: 0.5850 - val_acc: 0.8456\n",
      "Epoch 426/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1060 - acc: 0.9793 - val_loss: 0.5637 - val_acc: 0.8469\n",
      "Epoch 427/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.1008 - acc: 0.9785 - val_loss: 0.5517 - val_acc: 0.8471\n",
      "Epoch 428/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0921 - acc: 0.9812 - val_loss: 0.6029 - val_acc: 0.8270\n",
      "Epoch 429/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0946 - acc: 0.9799 - val_loss: 0.5605 - val_acc: 0.8595\n",
      "Epoch 430/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0917 - acc: 0.9824 - val_loss: 0.5560 - val_acc: 0.8563\n",
      "Epoch 431/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0887 - acc: 0.9817 - val_loss: 0.5501 - val_acc: 0.8623\n",
      "Epoch 432/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0865 - acc: 0.9813 - val_loss: 0.5663 - val_acc: 0.8575\n",
      "Epoch 433/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0875 - acc: 0.9810 - val_loss: 0.5662 - val_acc: 0.8499\n",
      "Epoch 434/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0994 - acc: 0.9794 - val_loss: 0.5827 - val_acc: 0.8373\n",
      "Epoch 435/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0898 - acc: 0.9824 - val_loss: 0.5788 - val_acc: 0.8345\n",
      "Epoch 436/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0960 - acc: 0.9796 - val_loss: 0.5787 - val_acc: 0.8375\n",
      "Epoch 437/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0961 - acc: 0.9814 - val_loss: 0.5738 - val_acc: 0.8358\n",
      "Epoch 438/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0979 - acc: 0.9798 - val_loss: 0.5413 - val_acc: 0.8609\n",
      "Epoch 439/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0947 - acc: 0.9810 - val_loss: 0.5447 - val_acc: 0.8570\n",
      "Epoch 440/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0960 - acc: 0.9806 - val_loss: 0.5810 - val_acc: 0.8432\n",
      "Epoch 441/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0907 - acc: 0.9813 - val_loss: 0.5689 - val_acc: 0.8506\n",
      "Epoch 442/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0942 - acc: 0.9806 - val_loss: 0.5657 - val_acc: 0.8453\n",
      "Epoch 443/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.1008 - acc: 0.9801 - val_loss: 0.5598 - val_acc: 0.8515\n",
      "Epoch 444/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0892 - acc: 0.9822 - val_loss: 0.5614 - val_acc: 0.8565\n",
      "Epoch 445/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0973 - acc: 0.9799 - val_loss: 0.5788 - val_acc: 0.8402\n",
      "Epoch 446/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0874 - acc: 0.9822 - val_loss: 0.5629 - val_acc: 0.8485\n",
      "Epoch 447/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1055 - acc: 0.9808 - val_loss: 0.5394 - val_acc: 0.8617\n",
      "Epoch 448/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0923 - acc: 0.9815 - val_loss: 0.5470 - val_acc: 0.8530\n",
      "Epoch 449/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0927 - acc: 0.9809 - val_loss: 0.5653 - val_acc: 0.8449\n",
      "Epoch 450/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0882 - acc: 0.9823 - val_loss: 0.5730 - val_acc: 0.8399\n",
      "Epoch 451/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0877 - acc: 0.9818 - val_loss: 0.5667 - val_acc: 0.8479\n",
      "Epoch 452/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0954 - acc: 0.9819 - val_loss: 0.5440 - val_acc: 0.8598\n",
      "Epoch 453/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0905 - acc: 0.9810 - val_loss: 0.5461 - val_acc: 0.8529\n",
      "Epoch 454/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0942 - acc: 0.9815 - val_loss: 0.5293 - val_acc: 0.8590\n",
      "Epoch 455/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0934 - acc: 0.9810 - val_loss: 0.5477 - val_acc: 0.8575\n",
      "Epoch 456/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0798 - acc: 0.9845 - val_loss: 0.6012 - val_acc: 0.8292\n",
      "Epoch 457/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.1033 - acc: 0.9791 - val_loss: 0.5674 - val_acc: 0.8413\n",
      "Epoch 458/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0778 - acc: 0.9840 - val_loss: 0.5686 - val_acc: 0.8429\n",
      "Epoch 459/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0871 - acc: 0.9824 - val_loss: 0.5697 - val_acc: 0.8426\n",
      "Epoch 460/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0784 - acc: 0.9843 - val_loss: 0.5743 - val_acc: 0.8401\n",
      "Epoch 461/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0838 - acc: 0.9809 - val_loss: 0.5603 - val_acc: 0.8497\n",
      "Epoch 462/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0954 - acc: 0.9809 - val_loss: 0.5737 - val_acc: 0.8335\n",
      "Epoch 463/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0839 - acc: 0.9838 - val_loss: 0.5828 - val_acc: 0.8480\n",
      "Epoch 464/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0893 - acc: 0.9835 - val_loss: 0.5791 - val_acc: 0.8539\n",
      "Epoch 465/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0964 - acc: 0.9813 - val_loss: 0.5758 - val_acc: 0.8421\n",
      "Epoch 466/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0815 - acc: 0.9831 - val_loss: 0.5552 - val_acc: 0.8544\n",
      "Epoch 467/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0971 - acc: 0.9796 - val_loss: 0.5699 - val_acc: 0.8410\n",
      "Epoch 468/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0776 - acc: 0.9844 - val_loss: 0.5739 - val_acc: 0.8360\n",
      "Epoch 469/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0964 - acc: 0.9800 - val_loss: 0.5688 - val_acc: 0.8397\n",
      "Epoch 470/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0731 - acc: 0.9850 - val_loss: 0.5680 - val_acc: 0.8495\n",
      "Epoch 471/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0833 - acc: 0.9841 - val_loss: 0.5708 - val_acc: 0.8471\n",
      "Epoch 472/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0930 - acc: 0.9831 - val_loss: 0.5521 - val_acc: 0.8573\n",
      "Epoch 473/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0829 - acc: 0.9831 - val_loss: 0.5721 - val_acc: 0.8477\n",
      "Epoch 474/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0811 - acc: 0.9834 - val_loss: 0.5852 - val_acc: 0.8463\n",
      "Epoch 475/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0891 - acc: 0.9832 - val_loss: 0.6266 - val_acc: 0.8192\n",
      "Epoch 476/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0838 - acc: 0.9819 - val_loss: 0.5782 - val_acc: 0.8483\n",
      "Epoch 477/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0808 - acc: 0.9839 - val_loss: 0.5942 - val_acc: 0.8377\n",
      "Epoch 478/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0857 - acc: 0.9828 - val_loss: 0.6007 - val_acc: 0.8352\n",
      "Epoch 479/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0833 - acc: 0.9821 - val_loss: 0.5819 - val_acc: 0.8464\n",
      "Epoch 480/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0759 - acc: 0.9840 - val_loss: 0.5797 - val_acc: 0.8633\n",
      "Epoch 481/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0814 - acc: 0.9838 - val_loss: 0.5679 - val_acc: 0.8474\n",
      "Epoch 482/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0912 - acc: 0.9814 - val_loss: 0.5751 - val_acc: 0.8454\n",
      "Epoch 483/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0699 - acc: 0.9857 - val_loss: 0.5839 - val_acc: 0.8444\n",
      "Epoch 484/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0818 - acc: 0.9836 - val_loss: 0.5738 - val_acc: 0.8499\n",
      "Epoch 485/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0851 - acc: 0.9846 - val_loss: 0.5772 - val_acc: 0.8442\n",
      "Epoch 486/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0931 - acc: 0.9818 - val_loss: 0.5856 - val_acc: 0.8379\n",
      "Epoch 487/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0754 - acc: 0.9847 - val_loss: 0.5706 - val_acc: 0.8651\n",
      "Epoch 488/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0894 - acc: 0.9817 - val_loss: 0.5949 - val_acc: 0.8444\n",
      "Epoch 489/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0801 - acc: 0.9836 - val_loss: 0.5661 - val_acc: 0.8544\n",
      "Epoch 490/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0835 - acc: 0.9825 - val_loss: 0.5913 - val_acc: 0.8432\n",
      "Epoch 491/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0794 - acc: 0.9829 - val_loss: 0.5744 - val_acc: 0.8566\n",
      "Epoch 492/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0815 - acc: 0.9833 - val_loss: 0.6205 - val_acc: 0.8216\n",
      "Epoch 493/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0777 - acc: 0.9836 - val_loss: 0.5759 - val_acc: 0.8465\n",
      "Epoch 494/600\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.0788 - acc: 0.9850 - val_loss: 0.6000 - val_acc: 0.8296\n",
      "Epoch 495/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0860 - acc: 0.9823 - val_loss: 0.5597 - val_acc: 0.8545\n",
      "Epoch 496/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0813 - acc: 0.9834 - val_loss: 0.5841 - val_acc: 0.8443\n",
      "Epoch 497/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0831 - acc: 0.9837 - val_loss: 0.5446 - val_acc: 0.8612\n",
      "Epoch 498/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0830 - acc: 0.9837 - val_loss: 0.5738 - val_acc: 0.8403\n",
      "Epoch 499/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0709 - acc: 0.9857 - val_loss: 0.5612 - val_acc: 0.8498\n",
      "Epoch 500/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0760 - acc: 0.9858 - val_loss: 0.5894 - val_acc: 0.8384\n",
      "Epoch 501/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0779 - acc: 0.9844 - val_loss: 0.5624 - val_acc: 0.8676\n",
      "Epoch 502/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0755 - acc: 0.9859 - val_loss: 0.5628 - val_acc: 0.8425\n",
      "Epoch 503/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0694 - acc: 0.9861 - val_loss: 0.5543 - val_acc: 0.8630\n",
      "Epoch 504/600\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.0806 - acc: 0.9833 - val_loss: 0.5801 - val_acc: 0.8496\n",
      "Epoch 505/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0739 - acc: 0.9856 - val_loss: 0.5739 - val_acc: 0.8460\n",
      "Epoch 506/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0787 - acc: 0.9842 - val_loss: 0.5513 - val_acc: 0.8645\n",
      "Epoch 507/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0770 - acc: 0.9845 - val_loss: 0.5572 - val_acc: 0.8446\n",
      "Epoch 508/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0734 - acc: 0.9854 - val_loss: 0.5933 - val_acc: 0.8353\n",
      "Epoch 509/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0711 - acc: 0.9854 - val_loss: 0.6126 - val_acc: 0.8259\n",
      "Epoch 510/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0712 - acc: 0.9849 - val_loss: 0.5792 - val_acc: 0.8516\n",
      "Epoch 511/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0818 - acc: 0.9840 - val_loss: 0.5757 - val_acc: 0.8485\n",
      "Epoch 512/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0715 - acc: 0.9850 - val_loss: 0.5722 - val_acc: 0.8453\n",
      "Epoch 513/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0819 - acc: 0.9864 - val_loss: 0.6029 - val_acc: 0.8211\n",
      "Epoch 514/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0766 - acc: 0.9841 - val_loss: 0.5648 - val_acc: 0.8476\n",
      "Epoch 515/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0850 - acc: 0.9833 - val_loss: 0.5700 - val_acc: 0.8368\n",
      "Epoch 516/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0823 - acc: 0.9842 - val_loss: 0.5596 - val_acc: 0.8556\n",
      "Epoch 517/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0689 - acc: 0.9872 - val_loss: 0.5593 - val_acc: 0.8566\n",
      "Epoch 518/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0760 - acc: 0.9859 - val_loss: 0.5473 - val_acc: 0.8545\n",
      "Epoch 519/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0775 - acc: 0.9846 - val_loss: 0.5671 - val_acc: 0.8537\n",
      "Epoch 520/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0813 - acc: 0.9851 - val_loss: 0.5395 - val_acc: 0.8504\n",
      "Epoch 521/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0705 - acc: 0.9866 - val_loss: 0.5443 - val_acc: 0.8550\n",
      "Epoch 522/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0779 - acc: 0.9841 - val_loss: 0.5696 - val_acc: 0.8431\n",
      "Epoch 523/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0750 - acc: 0.9847 - val_loss: 0.5749 - val_acc: 0.8505\n",
      "Epoch 524/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0681 - acc: 0.9848 - val_loss: 0.5807 - val_acc: 0.8552\n",
      "Epoch 525/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0845 - acc: 0.9848 - val_loss: 0.5529 - val_acc: 0.8560\n",
      "Epoch 526/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0812 - acc: 0.9843 - val_loss: 0.5665 - val_acc: 0.8506\n",
      "Epoch 527/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0688 - acc: 0.9867 - val_loss: 0.5465 - val_acc: 0.8555\n",
      "Epoch 528/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0707 - acc: 0.9860 - val_loss: 0.5569 - val_acc: 0.8499\n",
      "Epoch 529/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0720 - acc: 0.9856 - val_loss: 0.5441 - val_acc: 0.8625\n",
      "Epoch 530/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0745 - acc: 0.9867 - val_loss: 0.5409 - val_acc: 0.8491\n",
      "Epoch 531/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0730 - acc: 0.9853 - val_loss: 0.5670 - val_acc: 0.8509\n",
      "Epoch 532/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0715 - acc: 0.9867 - val_loss: 0.5798 - val_acc: 0.8440\n",
      "Epoch 533/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0592 - acc: 0.9873 - val_loss: 0.5836 - val_acc: 0.8466\n",
      "Epoch 534/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0667 - acc: 0.9867 - val_loss: 0.6027 - val_acc: 0.8380\n",
      "Epoch 535/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0694 - acc: 0.9864 - val_loss: 0.5945 - val_acc: 0.8460\n",
      "Epoch 536/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0837 - acc: 0.9834 - val_loss: 0.5711 - val_acc: 0.8499\n",
      "Epoch 537/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0708 - acc: 0.9853 - val_loss: 0.5777 - val_acc: 0.8482\n",
      "Epoch 538/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0710 - acc: 0.9848 - val_loss: 0.5680 - val_acc: 0.8553\n",
      "Epoch 539/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0776 - acc: 0.9854 - val_loss: 0.5541 - val_acc: 0.8563\n",
      "Epoch 540/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0747 - acc: 0.9856 - val_loss: 0.5753 - val_acc: 0.8482\n",
      "Epoch 541/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0655 - acc: 0.9864 - val_loss: 0.5661 - val_acc: 0.8567\n",
      "Epoch 542/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0724 - acc: 0.9852 - val_loss: 0.5600 - val_acc: 0.8604\n",
      "Epoch 543/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0757 - acc: 0.9850 - val_loss: 0.5814 - val_acc: 0.8428\n",
      "Epoch 544/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0732 - acc: 0.9857 - val_loss: 0.5568 - val_acc: 0.8589\n",
      "Epoch 545/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0792 - acc: 0.9834 - val_loss: 0.5478 - val_acc: 0.8524\n",
      "Epoch 546/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0810 - acc: 0.9844 - val_loss: 0.5589 - val_acc: 0.8495\n",
      "Epoch 547/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0744 - acc: 0.9847 - val_loss: 0.5700 - val_acc: 0.8445\n",
      "Epoch 548/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0759 - acc: 0.9850 - val_loss: 0.5637 - val_acc: 0.8445\n",
      "Epoch 549/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0722 - acc: 0.9858 - val_loss: 0.5500 - val_acc: 0.8560\n",
      "Epoch 550/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0721 - acc: 0.9862 - val_loss: 0.5762 - val_acc: 0.8406\n",
      "Epoch 551/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0722 - acc: 0.9853 - val_loss: 0.5667 - val_acc: 0.8477\n",
      "Epoch 552/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0794 - acc: 0.9850 - val_loss: 0.5759 - val_acc: 0.8371\n",
      "Epoch 553/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0696 - acc: 0.9857 - val_loss: 0.5685 - val_acc: 0.8392\n",
      "Epoch 554/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0702 - acc: 0.9865 - val_loss: 0.5763 - val_acc: 0.8414\n",
      "Epoch 555/600\n",
      "332/332 [==============================] - 8s 23ms/step - loss: 0.0631 - acc: 0.9882 - val_loss: 0.5659 - val_acc: 0.8534\n",
      "Epoch 556/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0711 - acc: 0.9859 - val_loss: 0.5850 - val_acc: 0.8404\n",
      "Epoch 557/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0746 - acc: 0.9855 - val_loss: 0.5784 - val_acc: 0.8480\n",
      "Epoch 558/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0736 - acc: 0.9859 - val_loss: 0.5846 - val_acc: 0.8404\n",
      "Epoch 559/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0715 - acc: 0.9864 - val_loss: 0.5758 - val_acc: 0.8493\n",
      "Epoch 560/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0655 - acc: 0.9871 - val_loss: 0.6012 - val_acc: 0.8326\n",
      "Epoch 561/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0664 - acc: 0.9869 - val_loss: 0.5686 - val_acc: 0.8545\n",
      "Epoch 562/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0715 - acc: 0.9854 - val_loss: 0.5666 - val_acc: 0.8600\n",
      "Epoch 563/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0674 - acc: 0.9869 - val_loss: 0.5690 - val_acc: 0.8513\n",
      "Epoch 564/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0711 - acc: 0.9865 - val_loss: 0.6157 - val_acc: 0.8266\n",
      "Epoch 565/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0681 - acc: 0.9864 - val_loss: 0.5720 - val_acc: 0.8510\n",
      "Epoch 566/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0746 - acc: 0.9863 - val_loss: 0.5941 - val_acc: 0.8360\n",
      "Epoch 567/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0719 - acc: 0.9867 - val_loss: 0.5484 - val_acc: 0.8592\n",
      "Epoch 568/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0631 - acc: 0.9883 - val_loss: 0.5569 - val_acc: 0.8552\n",
      "Epoch 569/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0716 - acc: 0.9873 - val_loss: 0.5807 - val_acc: 0.8409\n",
      "Epoch 570/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0685 - acc: 0.9859 - val_loss: 0.5699 - val_acc: 0.8373\n",
      "Epoch 571/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0867 - acc: 0.9838 - val_loss: 0.5602 - val_acc: 0.8425\n",
      "Epoch 572/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0667 - acc: 0.9872 - val_loss: 0.5696 - val_acc: 0.8485\n",
      "Epoch 573/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0696 - acc: 0.9866 - val_loss: 0.5641 - val_acc: 0.8523\n",
      "Epoch 574/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0661 - acc: 0.9862 - val_loss: 0.5604 - val_acc: 0.8562\n",
      "Epoch 575/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0732 - acc: 0.9855 - val_loss: 0.5757 - val_acc: 0.8464\n",
      "Epoch 576/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0664 - acc: 0.9878 - val_loss: 0.6023 - val_acc: 0.8289\n",
      "Epoch 577/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0764 - acc: 0.9847 - val_loss: 0.5540 - val_acc: 0.8566\n",
      "Epoch 578/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0660 - acc: 0.9863 - val_loss: 0.5655 - val_acc: 0.8534\n",
      "Epoch 579/600\n",
      "332/332 [==============================] - 6s 20ms/step - loss: 0.0655 - acc: 0.9875 - val_loss: 0.5644 - val_acc: 0.8518\n",
      "Epoch 580/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0623 - acc: 0.9872 - val_loss: 0.5712 - val_acc: 0.8579\n",
      "Epoch 581/600\n",
      "332/332 [==============================] - 7s 22ms/step - loss: 0.0614 - acc: 0.9879 - val_loss: 0.5648 - val_acc: 0.8556\n",
      "Epoch 582/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0724 - acc: 0.9859 - val_loss: 0.5699 - val_acc: 0.8559\n",
      "Epoch 583/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0801 - acc: 0.9835 - val_loss: 0.5955 - val_acc: 0.8381\n",
      "Epoch 584/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0794 - acc: 0.9858 - val_loss: 0.5635 - val_acc: 0.8468\n",
      "Epoch 585/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0724 - acc: 0.9869 - val_loss: 0.5512 - val_acc: 0.8575\n",
      "Epoch 586/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0774 - acc: 0.9866 - val_loss: 0.5771 - val_acc: 0.8302\n",
      "Epoch 587/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0604 - acc: 0.9885 - val_loss: 0.5478 - val_acc: 0.8593\n",
      "Epoch 588/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0689 - acc: 0.9869 - val_loss: 0.5599 - val_acc: 0.8500\n",
      "Epoch 589/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0641 - acc: 0.9878 - val_loss: 0.5559 - val_acc: 0.8636\n",
      "Epoch 590/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0664 - acc: 0.9874 - val_loss: 0.5773 - val_acc: 0.8455\n",
      "Epoch 591/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0640 - acc: 0.9875 - val_loss: 0.5755 - val_acc: 0.8517\n",
      "Epoch 592/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0732 - acc: 0.9848 - val_loss: 0.5640 - val_acc: 0.8530\n",
      "Epoch 593/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0709 - acc: 0.9871 - val_loss: 0.5735 - val_acc: 0.8399\n",
      "Epoch 594/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0621 - acc: 0.9871 - val_loss: 0.5681 - val_acc: 0.8486\n",
      "Epoch 595/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0678 - acc: 0.9873 - val_loss: 0.5700 - val_acc: 0.8478\n",
      "Epoch 596/600\n",
      "332/332 [==============================] - 7s 20ms/step - loss: 0.0586 - acc: 0.9880 - val_loss: 0.5716 - val_acc: 0.8512\n",
      "Epoch 597/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0738 - acc: 0.9859 - val_loss: 0.5630 - val_acc: 0.8447\n",
      "Epoch 598/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0645 - acc: 0.9866 - val_loss: 0.5880 - val_acc: 0.8302\n",
      "Epoch 599/600\n",
      "332/332 [==============================] - 7s 21ms/step - loss: 0.0696 - acc: 0.9876 - val_loss: 0.5723 - val_acc: 0.8479\n",
      "Epoch 600/600\n",
      "332/332 [==============================] - 6s 19ms/step - loss: 0.0563 - acc: 0.9886 - val_loss: 0.5919 - val_acc: 0.8592\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c8e99cc50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#datagen = ImageDataGenerator(\\\n",
    "#    rescale=1/255,\\\n",
    "#    validation_split=0.10,\\\n",
    "#    rotation_range=40,\\\n",
    "#    width_shift_range=0.2,\\\n",
    "#    height_shift_range=0.2,\\\n",
    "#    shear_range=0.2,\\\n",
    "#    zoom_range=0.2,\\\n",
    "#    horizontal_flip=True,\\\n",
    "#    fill_mode='nearest'\\\n",
    "#)\n",
    "\n",
    "\n",
    "#datagen.fit(train_features)\n",
    "weights = {0:1, 1:7.5}\n",
    "model.fit(train_features, train_target,class_weight = weights,batch_size=64,validation_split=0.3,\\\n",
    "           epochs=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c639a81d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T16:14:20.293814Z",
     "iopub.status.busy": "2023-02-11T16:14:20.293354Z",
     "iopub.status.idle": "2023-02-11T16:14:20.402740Z",
     "shell.execute_reply": "2023-02-11T16:14:20.401374Z"
    },
    "papermill": {
     "duration": 5.487748,
     "end_time": "2023-02-11T16:14:20.406077",
     "exception": false,
     "start_time": "2023-02-11T16:14:14.918329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save(\"/kaggle/working/trained_model_breast_cancer3.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b9ceb6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T16:14:32.121027Z",
     "iopub.status.busy": "2023-02-11T16:14:32.120561Z",
     "iopub.status.idle": "2023-02-11T16:14:32.127701Z",
     "shell.execute_reply": "2023-02-11T16:14:32.125440Z"
    },
    "papermill": {
     "duration": 5.994559,
     "end_time": "2023-02-11T16:14:32.132379",
     "exception": false,
     "start_time": "2023-02-11T16:14:26.137820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "#savedModel = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c915c25f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T16:14:43.006882Z",
     "iopub.status.busy": "2023-02-11T16:14:43.006427Z",
     "iopub.status.idle": "2023-02-11T16:14:52.194605Z",
     "shell.execute_reply": "2023-02-11T16:14:52.184649Z"
    },
    "papermill": {
     "duration": 14.549637,
     "end_time": "2023-02-11T16:14:52.209457",
     "exception": false,
     "start_time": "2023-02-11T16:14:37.659820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_features=[]\n",
    "for i in test['img_data']:\n",
    "    i=np.array(i)\n",
    "    test_features.append(i)\n",
    "test_features=np.array(test_features)\n",
    " \n",
    "\n",
    "    \n",
    "#featureTransform = test_features.reshape(len(test_features), 6400)\n",
    "scaler = MinMaxScaler()\n",
    "#featureTransform =scaler.fit_transform(featureTransform)\n",
    "norm_features= []\n",
    "for i in range(len(test_features)):\n",
    "    norm_features.append(scaler.fit_transform(test_features[i]))\n",
    "test_features=np.array(norm_features)\n",
    "\n",
    "\n",
    "#backTransform = featureTransform.reshape(len(test_features),80,80)\n",
    "test_features = test_features.reshape(len(test_features),95,95,1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "test_target = np.array(test['cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "707fd683",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T16:15:03.890534Z",
     "iopub.status.busy": "2023-02-11T16:15:03.890010Z",
     "iopub.status.idle": "2023-02-11T16:15:08.127304Z",
     "shell.execute_reply": "2023-02-11T16:15:08.125872Z"
    },
    "papermill": {
     "duration": 10.228286,
     "end_time": "2023-02-11T16:15:08.130832",
     "exception": false,
     "start_time": "2023-02-11T16:14:57.902546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-11 16:15:04.126858: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 468686300 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = model.predict(test_features)\n",
    "bin_pred = []\n",
    "for i in pred:\n",
    "    if i>=0.5:\n",
    "        bin_pred.append(1)\n",
    "    else:\n",
    "        bin_pred.append(0)\n",
    "bin_pred = np.array(bin_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c368387",
   "metadata": {
    "papermill": {
     "duration": 5.384349,
     "end_time": "2023-02-11T16:15:18.917080",
     "exception": false,
     "start_time": "2023-02-11T16:15:13.532731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db43e301",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T16:15:30.003258Z",
     "iopub.status.busy": "2023-02-11T16:15:30.001566Z",
     "iopub.status.idle": "2023-02-11T16:15:30.079765Z",
     "shell.execute_reply": "2023-02-11T16:15:30.076607Z"
    },
    "papermill": {
     "duration": 5.525252,
     "end_time": "2023-02-11T16:15:30.085994",
     "exception": false,
     "start_time": "2023-02-11T16:15:24.560742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8555803743356697\n",
      "0.9005930778082677 0.5539739027283511\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "acc = sklearn.metrics.accuracy_score(test_target, bin_pred)\n",
    "print(acc)\n",
    "\n",
    "countzero=0\n",
    "countone=0\n",
    "countzerot=0\n",
    "countonet=0\n",
    "for i, j in zip(test_target, bin_pred):\n",
    "    if i==0 and j==0:\n",
    "        countzero+=1\n",
    "    if i==1 and j==1:\n",
    "        countone+=1\n",
    "    if i==1:\n",
    "        countonet+=1\n",
    "    if i==0:\n",
    "        countzerot+=1\n",
    "print(countzero/countzerot,countone/countonet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfd04eed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-11T16:15:41.888102Z",
     "iopub.status.busy": "2023-02-11T16:15:41.887639Z",
     "iopub.status.idle": "2023-02-11T16:15:41.899815Z",
     "shell.execute_reply": "2023-02-11T16:15:41.898386Z"
    },
    "papermill": {
     "duration": 5.646013,
     "end_time": "2023-02-11T16:15:41.904408",
     "exception": false,
     "start_time": "2023-02-11T16:15:36.258395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4990649211862142\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives )\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives )\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "\n",
    "print(f1_m(test_target,bin_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5002.567201,
   "end_time": "2023-02-11T16:15:51.457805",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-11T14:52:28.890604",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
