{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "151c7e74",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T16:03:13.844828Z",
     "iopub.status.busy": "2023-01-30T16:03:13.843797Z",
     "iopub.status.idle": "2023-01-30T16:03:22.315936Z",
     "shell.execute_reply": "2023-01-30T16:03:22.314696Z"
    },
    "papermill": {
     "duration": 8.486333,
     "end_time": "2023-01-30T16:03:22.319173",
     "exception": false,
     "start_time": "2023-01-30T16:03:13.832840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "from PIL import Image as im\n",
    "import random\n",
    "from scipy import ndimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b66caf62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T16:03:22.335810Z",
     "iopub.status.busy": "2023-01-30T16:03:22.335081Z",
     "iopub.status.idle": "2023-01-30T16:03:36.437317Z",
     "shell.execute_reply": "2023-01-30T16:03:36.435847Z"
    },
    "papermill": {
     "duration": 14.114156,
     "end_time": "2023-01-30T16:03:36.440648",
     "exception": false,
     "start_time": "2023-01-30T16:03:22.326492",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dicomsdl\r\n",
      "  Downloading dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: dicomsdl\r\n",
      "Successfully installed dicomsdl-0.109.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install dicomsdl\n",
    "#!pip install /kaggle/input/rsnapacks/dicomsdl-0.109.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "#import pydicom as dicom\n",
    "import dicomsdl as dicom\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from PIL import Image as im\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af9ffde8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T16:03:36.458919Z",
     "iopub.status.busy": "2023-01-30T16:03:36.458486Z",
     "iopub.status.idle": "2023-01-30T16:03:36.482364Z",
     "shell.execute_reply": "2023-01-30T16:03:36.481482Z"
    },
    "papermill": {
     "duration": 0.035925,
     "end_time": "2023-01-30T16:03:36.484753",
     "exception": false,
     "start_time": "2023-01-30T16:03:36.448828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasetPath = '/kaggle/input/rsna-breast-cancer-detection/train.csv'\n",
    "imgPath = '/kaggle/input/rsna-breast-cancer-detection/train_images/'\n",
    "\n",
    "def crop(sideName, imgName):\n",
    "    \"\"\"\n",
    "    This function is used to crop the breast images. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :sideName = Laterality of breast if it is right or left\n",
    "    :imgName = Image pixel data of the DCM images\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    if sideName == 'L':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col==0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = max(colind)\n",
    "        imgName = imgName[0:512,0:crop_size]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "        \n",
    "    if sideName == 'R':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col!=0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = min(colind)\n",
    "        imgName = imgName[0:512,crop_size:512]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "    \n",
    "    return imgName    \n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "def crop_reverse(sideName, imgName):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to crop the breast images but in the reverse order.\n",
    "    Because the laterality is defined wrongly for some images. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :sideName = Laterality of breast if it is right or left\n",
    "    :imgName = Image pixel data of the DCM images\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if sideName == 'R':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col==0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = max(colind)\n",
    "        imgName = imgName[0:512,0:crop_size]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "        \n",
    "    if sideName == 'L':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col!=0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = min(colind)\n",
    "        imgName = imgName[0:512,crop_size:512]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "    \n",
    "    return imgName    \n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "def img_process(i,filename,sides):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to process the images which will be used for the training/test dataset. It takes three arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :i = Index of the image in the dataframe\n",
    "    :filename = Path of the image\n",
    "    :sides = List of all images' laterality\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #ds = dicom.dcmread(filename)\n",
    "    dsraw = dicom.open(filename)\n",
    "    ds = dsraw.pixelData()\n",
    "    \n",
    "    ds = (ds - ds.min()) / (ds.max() - ds.min())\n",
    "    if dsraw.PhotometricInterpretation == \"MONOCHROME1\":  \n",
    "        ds = 1 - ds\n",
    "    ds = (ds * 255).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    #ds = cv2.normalize(ds, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    ds = cv2.resize(ds,(512,512))\n",
    "    \n",
    "    #ds = np.where(ds >= 0.999, 0,ds)\n",
    "    \n",
    "    try:\n",
    "        ds = np.array(crop(sides[i], ds))   \n",
    "    except:\n",
    "        ds = np.array(crop_reverse(sides[i], ds))\n",
    "    \n",
    "\n",
    "    #train_data.loc[i,'img_data'] = [img_fin]\n",
    "    #train_data.to_csv('/kaggle/working/training_img_data.csv') \n",
    "    return ds\n",
    "    gc.collect()\n",
    "\n",
    "def dcmToPix(datasetPath, imgPath):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to process all the images which will be used for the training/test dataset. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :datasetPath = Path of the cancer dataset\n",
    "    :imgPath = Path of the image dataset\n",
    "   \n",
    "    Output:-\n",
    "    :return = Array of all the processed images\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    dataset = pd.read_csv(datasetPath)\n",
    "    \n",
    "    patient_ids = dataset['patient_id']\n",
    "    image_ids = dataset['image_id']\n",
    "    sides  = dataset['laterality']\n",
    "\n",
    "    imgData = []\n",
    "\n",
    "    for pi, ii, leng in zip(patient_ids, image_ids, range(len(patient_ids))):\n",
    "        imgData.append(imgPath + str(pi) + '/' + str(ii) + '.dcm')\n",
    "\n",
    "    dataset['img_data'] = \" \"\n",
    "    \n",
    "    result = Parallel(n_jobs=128)(\\\n",
    "    delayed(img_process)(i, fname, sides) for i, fname in zip(range(len(imgData)),tqdm(imgData))\\\n",
    "    )\n",
    "    \n",
    "    dataset['img_data'] = result\n",
    "    dataset.to_pickle('imgData.pkl' )\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "824be3b5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-01-30T16:03:36.502762Z",
     "iopub.status.busy": "2023-01-30T16:03:36.502364Z",
     "iopub.status.idle": "2023-01-30T16:03:45.057164Z",
     "shell.execute_reply": "2023-01-30T16:03:45.056121Z"
    },
    "papermill": {
     "duration": 8.567365,
     "end_time": "2023-01-30T16:03:45.060092",
     "exception": false,
     "start_time": "2023-01-30T16:03:36.492727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with (open('/kaggle/input/output/imgData.pkl', \"rb\")) as openfile:\n",
    "     imgData = pickle.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626d7a07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T16:03:45.077884Z",
     "iopub.status.busy": "2023-01-30T16:03:45.077090Z",
     "iopub.status.idle": "2023-01-30T16:03:45.082010Z",
     "shell.execute_reply": "2023-01-30T16:03:45.080948Z"
    },
    "papermill": {
     "duration": 0.016301,
     "end_time": "2023-01-30T16:03:45.084362",
     "exception": false,
     "start_time": "2023-01-30T16:03:45.068061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#datacancer = pd.read_csv(datasetPath)\n",
    "#imgDataFrame = {'cancer':datacancer['cancer'][:50], 'img_data':imgData}\n",
    "#imgData2 = pd.DataFrame(imgDataFrame)\n",
    "\n",
    "#imgData=imgData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb70bc77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T16:03:45.101299Z",
     "iopub.status.busy": "2023-01-30T16:03:45.100903Z",
     "iopub.status.idle": "2023-01-30T16:03:45.275260Z",
     "shell.execute_reply": "2023-01-30T16:03:45.273985Z"
    },
    "papermill": {
     "duration": 0.186306,
     "end_time": "2023-01-30T16:03:45.278291",
     "exception": false,
     "start_time": "2023-01-30T16:03:45.091985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgdata_pos = imgData[imgData['cancer'] == 1]\n",
    "imgdata_neg = imgData[imgData['cancer'] == 0]\n",
    "\n",
    "imgdata_pos = imgdata_pos.sample(frac = 1)\n",
    "imgdata_neg = imgdata_neg.sample(frac = 1)\n",
    "\n",
    "imgdata_neg = imgdata_neg.sample(frac= 1)\n",
    "\n",
    "frames = 45*[imgdata_pos]\n",
    "frames.append(imgdata_neg)\n",
    "imgdata_shuff = pd.concat(frames)\n",
    "imgdata_shuff = imgdata_shuff.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8da284f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T16:03:45.295725Z",
     "iopub.status.busy": "2023-01-30T16:03:45.295016Z",
     "iopub.status.idle": "2023-01-30T16:03:45.307841Z",
     "shell.execute_reply": "2023-01-30T16:03:45.306671Z"
    },
    "papermill": {
     "duration": 0.024277,
     "end_time": "2023-01-30T16:03:45.310302",
     "exception": false,
     "start_time": "2023-01-30T16:03:45.286025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    53548\n",
      "1    52110\n",
      "Name: cancer, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(imgdata_shuff['cancer'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af81b4e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T16:03:45.329376Z",
     "iopub.status.busy": "2023-01-30T16:03:45.328716Z",
     "iopub.status.idle": "2023-01-30T16:03:45.335507Z",
     "shell.execute_reply": "2023-01-30T16:03:45.334650Z"
    },
    "papermill": {
     "duration": 0.018181,
     "end_time": "2023-01-30T16:03:45.337782",
     "exception": false,
     "start_time": "2023-01-30T16:03:45.319601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_rotate(imgData):\n",
    "    #thresh = 0.15\n",
    "    \n",
    "    imgData = imgData.reshape(128,128)\n",
    "    imgData = ndimage.rotate(imgData, random.randint(0, 180), reshape=False)\n",
    "\n",
    "    #imgData = np.clip(imgData,thresh,1)\n",
    "    imgData = imgData[15:110,15:110]\n",
    "    \n",
    "    clahe = cv2.createCLAHE(clipLimit=random.uniform(8, 10), tileGridSize=(5,5))\n",
    "    imgData = clahe.apply(imgData)\n",
    "    #imgData = im.fromarray(imgData)\n",
    "    #imgData = np.asarray(imgData.rotate(random.randint(-20, 20)))\n",
    "    return imgData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49493725",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T16:03:45.355256Z",
     "iopub.status.busy": "2023-01-30T16:03:45.354564Z",
     "iopub.status.idle": "2023-01-30T16:10:27.765405Z",
     "shell.execute_reply": "2023-01-30T16:10:27.764194Z"
    },
    "papermill": {
     "duration": 402.422949,
     "end_time": "2023-01-30T16:10:27.768302",
     "exception": false,
     "start_time": "2023-01-30T16:03:45.345353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 105658/105658 [06:42<00:00, 262.59it/s]\n"
     ]
    }
   ],
   "source": [
    "imgDataList=[]\n",
    "for j in tqdm(imgdata_shuff['img_data']):\n",
    "    imgDataList.append(random_rotate(j))\n",
    "imgdata_shuff['img_data'] = imgDataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2750f54f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T16:10:28.241255Z",
     "iopub.status.busy": "2023-01-30T16:10:28.240853Z",
     "iopub.status.idle": "2023-01-30T16:10:59.515524Z",
     "shell.execute_reply": "2023-01-30T16:10:59.514073Z"
    },
    "papermill": {
     "duration": 31.514115,
     "end_time": "2023-01-30T16:10:59.518627",
     "exception": false,
     "start_time": "2023-01-30T16:10:28.004512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test = train_test_split(imgdata_shuff, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "train_target = np.array(train['cancer'])\n",
    "train_features=[]\n",
    "for i in train['img_data']:\n",
    "    i=np.array(i)\n",
    "    train_features.append(i)\n",
    "train_features=np.array(train_features)\n",
    "\n",
    "\n",
    "\n",
    "#featureTransform = train_features.reshape(len(train_features), 6400)\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#featureTransform = scaler.fit_transform(featureTransform)\n",
    "norm_features= []\n",
    "for i in range(len(train_features)):\n",
    "        norm_features.append(scaler.fit_transform(train_features[i]))\n",
    "train_features=np.array(norm_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#backTransform = featureTransform.reshape(len(train_features),80,80)\n",
    "#train_features = backTransform.reshape(len(train_features),80,80,1)\n",
    "train_features = train_features.reshape(len(train_features),95,95,1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "579433c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T16:11:00.015098Z",
     "iopub.status.busy": "2023-01-30T16:11:00.014655Z",
     "iopub.status.idle": "2023-01-30T16:11:00.034107Z",
     "shell.execute_reply": "2023-01-30T16:11:00.032867Z"
    },
    "papermill": {
     "duration": 0.265836,
     "end_time": "2023-01-30T16:11:00.036406",
     "exception": false,
     "start_time": "2023-01-30T16:10:59.770570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dense, Conv2D, Flatten,MaxPooling2D, Dropout, BatchNormalization, GlobalMaxPooling2D\n",
    "\n",
    "\n",
    "def myModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, 3, activation = \"relu\", input_shape = (95,95,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, 3, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(64, 3, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, 3, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(1024, activation = 'relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer =tf.keras.optimizers.Adam(learning_rate=0.0001),\\\n",
    "                  loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives )\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives )\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#loss = tf.keras.losses.BinaryFocalCrossentropy(\\\n",
    "#    apply_class_balancing=True, gamma=5, from_logits=True,\\\n",
    "#    reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "\n",
    "#model.compile(optimizer =tf.keras.optimizers.Adam(learning_rate=0.0001),\\\n",
    "#              loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02ddc3c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T16:11:00.588428Z",
     "iopub.status.busy": "2023-01-30T16:11:00.587886Z",
     "iopub.status.idle": "2023-01-30T16:11:00.592886Z",
     "shell.execute_reply": "2023-01-30T16:11:00.591913Z"
    },
    "papermill": {
     "duration": 0.246816,
     "end_time": "2023-01-30T16:11:00.595522",
     "exception": false,
     "start_time": "2023-01-30T16:11:00.348706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "#model = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecad4ad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T16:11:01.086863Z",
     "iopub.status.busy": "2023-01-30T16:11:01.085531Z",
     "iopub.status.idle": "2023-01-30T23:13:52.633413Z",
     "shell.execute_reply": "2023-01-30T23:13:52.632507Z"
    },
    "papermill": {
     "duration": 25375.900335,
     "end_time": "2023-01-30T23:13:56.743516",
     "exception": false,
     "start_time": "2023-01-30T16:11:00.843181",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 16:11:01.130560: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-01-30 16:11:05.777916: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "809/809 [==============================] - 353s 434ms/step - loss: 0.7490 - accuracy: 0.5364 - val_loss: 0.6777 - val_accuracy: 0.5684\n",
      "\n",
      "Epoch 00001: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 2/70\n",
      "809/809 [==============================] - 348s 430ms/step - loss: 0.6749 - accuracy: 0.5728 - val_loss: 0.6698 - val_accuracy: 0.5803\n",
      "\n",
      "Epoch 00002: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 3/70\n",
      "809/809 [==============================] - 351s 434ms/step - loss: 0.6592 - accuracy: 0.5991 - val_loss: 0.6615 - val_accuracy: 0.5909\n",
      "\n",
      "Epoch 00003: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 4/70\n",
      "809/809 [==============================] - 353s 437ms/step - loss: 0.6359 - accuracy: 0.6322 - val_loss: 0.6508 - val_accuracy: 0.6133\n",
      "\n",
      "Epoch 00004: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 5/70\n",
      "809/809 [==============================] - 353s 436ms/step - loss: 0.6061 - accuracy: 0.6656 - val_loss: 0.6481 - val_accuracy: 0.6126\n",
      "\n",
      "Epoch 00005: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 6/70\n",
      "809/809 [==============================] - 358s 442ms/step - loss: 0.5632 - accuracy: 0.7051 - val_loss: 0.6398 - val_accuracy: 0.6275\n",
      "\n",
      "Epoch 00006: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 7/70\n",
      "809/809 [==============================] - 360s 444ms/step - loss: 0.5172 - accuracy: 0.7425 - val_loss: 0.6375 - val_accuracy: 0.6354\n",
      "\n",
      "Epoch 00007: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 8/70\n",
      "809/809 [==============================] - 354s 438ms/step - loss: 0.4606 - accuracy: 0.7798 - val_loss: 0.6398 - val_accuracy: 0.6499\n",
      "\n",
      "Epoch 00008: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 9/70\n",
      "809/809 [==============================] - 350s 433ms/step - loss: 0.3995 - accuracy: 0.8188 - val_loss: 0.6440 - val_accuracy: 0.6560\n",
      "\n",
      "Epoch 00009: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 10/70\n",
      "809/809 [==============================] - 353s 437ms/step - loss: 0.3442 - accuracy: 0.8512 - val_loss: 0.6514 - val_accuracy: 0.6615\n",
      "\n",
      "Epoch 00010: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 11/70\n",
      "809/809 [==============================] - 358s 442ms/step - loss: 0.2880 - accuracy: 0.8805 - val_loss: 0.6775 - val_accuracy: 0.6700\n",
      "\n",
      "Epoch 00011: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 12/70\n",
      "809/809 [==============================] - 358s 442ms/step - loss: 0.2435 - accuracy: 0.9037 - val_loss: 0.6773 - val_accuracy: 0.6716\n",
      "\n",
      "Epoch 00012: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 13/70\n",
      "809/809 [==============================] - 356s 440ms/step - loss: 0.2075 - accuracy: 0.9189 - val_loss: 0.7351 - val_accuracy: 0.6684\n",
      "\n",
      "Epoch 00013: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 14/70\n",
      "809/809 [==============================] - 357s 441ms/step - loss: 0.1766 - accuracy: 0.9337 - val_loss: 0.7244 - val_accuracy: 0.6737\n",
      "\n",
      "Epoch 00014: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 15/70\n",
      "809/809 [==============================] - 353s 437ms/step - loss: 0.1522 - accuracy: 0.9442 - val_loss: 0.7680 - val_accuracy: 0.6737\n",
      "\n",
      "Epoch 00015: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 16/70\n",
      "809/809 [==============================] - 372s 459ms/step - loss: 0.1352 - accuracy: 0.9504 - val_loss: 0.7582 - val_accuracy: 0.6802\n",
      "\n",
      "Epoch 00016: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 17/70\n",
      "809/809 [==============================] - 374s 462ms/step - loss: 0.1193 - accuracy: 0.9575 - val_loss: 0.7856 - val_accuracy: 0.6755\n",
      "\n",
      "Epoch 00017: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 18/70\n",
      "809/809 [==============================] - 384s 474ms/step - loss: 0.1100 - accuracy: 0.9604 - val_loss: 0.7646 - val_accuracy: 0.6851\n",
      "\n",
      "Epoch 00018: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 19/70\n",
      "809/809 [==============================] - 368s 455ms/step - loss: 0.0993 - accuracy: 0.9649 - val_loss: 0.8322 - val_accuracy: 0.6822\n",
      "\n",
      "Epoch 00019: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 20/70\n",
      "809/809 [==============================] - 355s 439ms/step - loss: 0.0916 - accuracy: 0.9670 - val_loss: 0.7999 - val_accuracy: 0.6882\n",
      "\n",
      "Epoch 00020: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 21/70\n",
      "809/809 [==============================] - 360s 445ms/step - loss: 0.0867 - accuracy: 0.9689 - val_loss: 0.8008 - val_accuracy: 0.6906\n",
      "\n",
      "Epoch 00021: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 22/70\n",
      "809/809 [==============================] - 359s 444ms/step - loss: 0.0767 - accuracy: 0.9732 - val_loss: 0.8239 - val_accuracy: 0.6867\n",
      "\n",
      "Epoch 00022: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 23/70\n",
      "809/809 [==============================] - 357s 442ms/step - loss: 0.0726 - accuracy: 0.9751 - val_loss: 0.8533 - val_accuracy: 0.6860\n",
      "\n",
      "Epoch 00023: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 24/70\n",
      "809/809 [==============================] - 366s 452ms/step - loss: 0.0717 - accuracy: 0.9744 - val_loss: 0.8448 - val_accuracy: 0.6877\n",
      "\n",
      "Epoch 00024: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 25/70\n",
      "809/809 [==============================] - 356s 440ms/step - loss: 0.0665 - accuracy: 0.9765 - val_loss: 0.8619 - val_accuracy: 0.6860\n",
      "\n",
      "Epoch 00025: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 26/70\n",
      "809/809 [==============================] - 362s 447ms/step - loss: 0.0645 - accuracy: 0.9766 - val_loss: 0.9455 - val_accuracy: 0.6784\n",
      "\n",
      "Epoch 00026: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 27/70\n",
      "809/809 [==============================] - 363s 449ms/step - loss: 0.0610 - accuracy: 0.9786 - val_loss: 0.8641 - val_accuracy: 0.6901\n",
      "\n",
      "Epoch 00027: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 28/70\n",
      "809/809 [==============================] - 364s 450ms/step - loss: 0.0569 - accuracy: 0.9792 - val_loss: 0.8912 - val_accuracy: 0.6913\n",
      "\n",
      "Epoch 00028: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 29/70\n",
      "809/809 [==============================] - 364s 450ms/step - loss: 0.0552 - accuracy: 0.9807 - val_loss: 0.8717 - val_accuracy: 0.6923\n",
      "\n",
      "Epoch 00029: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 30/70\n",
      "809/809 [==============================] - 366s 453ms/step - loss: 0.0542 - accuracy: 0.9810 - val_loss: 0.8571 - val_accuracy: 0.6965\n",
      "\n",
      "Epoch 00030: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 31/70\n",
      "809/809 [==============================] - 362s 448ms/step - loss: 0.0531 - accuracy: 0.9809 - val_loss: 0.9191 - val_accuracy: 0.6965\n",
      "\n",
      "Epoch 00031: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 32/70\n",
      "809/809 [==============================] - 366s 452ms/step - loss: 0.0529 - accuracy: 0.9809 - val_loss: 0.9243 - val_accuracy: 0.6927\n",
      "\n",
      "Epoch 00032: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 33/70\n",
      "809/809 [==============================] - 365s 451ms/step - loss: 0.0498 - accuracy: 0.9824 - val_loss: 0.9390 - val_accuracy: 0.6941\n",
      "\n",
      "Epoch 00033: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 34/70\n",
      "809/809 [==============================] - 367s 453ms/step - loss: 0.0490 - accuracy: 0.9826 - val_loss: 0.9147 - val_accuracy: 0.6931\n",
      "\n",
      "Epoch 00034: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 35/70\n",
      "809/809 [==============================] - 368s 455ms/step - loss: 0.0486 - accuracy: 0.9831 - val_loss: 0.9522 - val_accuracy: 0.6923\n",
      "\n",
      "Epoch 00035: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 36/70\n",
      "809/809 [==============================] - 365s 452ms/step - loss: 0.0480 - accuracy: 0.9823 - val_loss: 0.9026 - val_accuracy: 0.6923\n",
      "\n",
      "Epoch 00036: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 37/70\n",
      "809/809 [==============================] - 368s 455ms/step - loss: 0.0432 - accuracy: 0.9849 - val_loss: 0.9828 - val_accuracy: 0.6911\n",
      "\n",
      "Epoch 00037: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 38/70\n",
      "809/809 [==============================] - 364s 450ms/step - loss: 0.0447 - accuracy: 0.9843 - val_loss: 1.0797 - val_accuracy: 0.6827\n",
      "\n",
      "Epoch 00038: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 39/70\n",
      "809/809 [==============================] - 369s 456ms/step - loss: 0.0451 - accuracy: 0.9836 - val_loss: 0.9753 - val_accuracy: 0.6925\n",
      "\n",
      "Epoch 00039: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 40/70\n",
      "809/809 [==============================] - 366s 452ms/step - loss: 0.0413 - accuracy: 0.9858 - val_loss: 0.9894 - val_accuracy: 0.7003\n",
      "\n",
      "Epoch 00040: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 41/70\n",
      "809/809 [==============================] - 360s 445ms/step - loss: 0.0410 - accuracy: 0.9862 - val_loss: 0.9335 - val_accuracy: 0.7023\n",
      "\n",
      "Epoch 00041: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 42/70\n",
      "809/809 [==============================] - 361s 446ms/step - loss: 0.0398 - accuracy: 0.9859 - val_loss: 0.9955 - val_accuracy: 0.7015\n",
      "\n",
      "Epoch 00042: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 43/70\n",
      "809/809 [==============================] - 362s 447ms/step - loss: 0.0404 - accuracy: 0.9856 - val_loss: 0.9814 - val_accuracy: 0.6998\n",
      "\n",
      "Epoch 00043: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 44/70\n",
      "809/809 [==============================] - 362s 447ms/step - loss: 0.0391 - accuracy: 0.9865 - val_loss: 0.9631 - val_accuracy: 0.6956\n",
      "\n",
      "Epoch 00044: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 45/70\n",
      "809/809 [==============================] - 361s 446ms/step - loss: 0.0392 - accuracy: 0.9858 - val_loss: 0.9907 - val_accuracy: 0.6965\n",
      "\n",
      "Epoch 00045: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 46/70\n",
      "809/809 [==============================] - 364s 450ms/step - loss: 0.0372 - accuracy: 0.9862 - val_loss: 0.9240 - val_accuracy: 0.7073\n",
      "\n",
      "Epoch 00046: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 47/70\n",
      "809/809 [==============================] - 362s 447ms/step - loss: 0.0352 - accuracy: 0.9872 - val_loss: 1.0142 - val_accuracy: 0.6997\n",
      "\n",
      "Epoch 00047: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 48/70\n",
      "809/809 [==============================] - 357s 441ms/step - loss: 0.0348 - accuracy: 0.9873 - val_loss: 1.0001 - val_accuracy: 0.6936\n",
      "\n",
      "Epoch 00048: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 49/70\n",
      "809/809 [==============================] - 356s 441ms/step - loss: 0.0361 - accuracy: 0.9871 - val_loss: 0.9464 - val_accuracy: 0.7073\n",
      "\n",
      "Epoch 00049: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 50/70\n",
      "809/809 [==============================] - 361s 446ms/step - loss: 0.0353 - accuracy: 0.9874 - val_loss: 1.0228 - val_accuracy: 0.6972\n",
      "\n",
      "Epoch 00050: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 51/70\n",
      "809/809 [==============================] - 357s 441ms/step - loss: 0.0364 - accuracy: 0.9869 - val_loss: 0.9979 - val_accuracy: 0.6968\n",
      "\n",
      "Epoch 00051: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 52/70\n",
      "809/809 [==============================] - 352s 435ms/step - loss: 0.0357 - accuracy: 0.9874 - val_loss: 0.9112 - val_accuracy: 0.7047\n",
      "\n",
      "Epoch 00052: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 53/70\n",
      "809/809 [==============================] - 360s 445ms/step - loss: 0.0332 - accuracy: 0.9882 - val_loss: 0.9252 - val_accuracy: 0.7124\n",
      "\n",
      "Epoch 00053: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 54/70\n",
      "809/809 [==============================] - 360s 445ms/step - loss: 0.0311 - accuracy: 0.9890 - val_loss: 1.0261 - val_accuracy: 0.7034\n",
      "\n",
      "Epoch 00054: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 55/70\n",
      "809/809 [==============================] - 355s 439ms/step - loss: 0.0328 - accuracy: 0.9882 - val_loss: 0.9973 - val_accuracy: 0.6976\n",
      "\n",
      "Epoch 00055: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 56/70\n",
      "809/809 [==============================] - 362s 448ms/step - loss: 0.0357 - accuracy: 0.9869 - val_loss: 0.9837 - val_accuracy: 0.7070\n",
      "\n",
      "Epoch 00056: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 57/70\n",
      "809/809 [==============================] - 375s 464ms/step - loss: 0.0315 - accuracy: 0.9889 - val_loss: 0.9913 - val_accuracy: 0.7029\n",
      "\n",
      "Epoch 00057: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 58/70\n",
      "809/809 [==============================] - 361s 446ms/step - loss: 0.0334 - accuracy: 0.9881 - val_loss: 0.9653 - val_accuracy: 0.7075\n",
      "\n",
      "Epoch 00058: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 59/70\n",
      "809/809 [==============================] - 370s 457ms/step - loss: 0.0295 - accuracy: 0.9897 - val_loss: 0.9791 - val_accuracy: 0.7081\n",
      "\n",
      "Epoch 00059: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 60/70\n",
      "809/809 [==============================] - 370s 457ms/step - loss: 0.0297 - accuracy: 0.9896 - val_loss: 0.9956 - val_accuracy: 0.7102\n",
      "\n",
      "Epoch 00060: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 61/70\n",
      "809/809 [==============================] - 370s 457ms/step - loss: 0.0309 - accuracy: 0.9889 - val_loss: 0.9904 - val_accuracy: 0.7109\n",
      "\n",
      "Epoch 00061: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 62/70\n",
      "809/809 [==============================] - 371s 459ms/step - loss: 0.0291 - accuracy: 0.9898 - val_loss: 1.0337 - val_accuracy: 0.7120\n",
      "\n",
      "Epoch 00062: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 63/70\n",
      "809/809 [==============================] - 365s 451ms/step - loss: 0.0306 - accuracy: 0.9888 - val_loss: 0.9346 - val_accuracy: 0.7123\n",
      "\n",
      "Epoch 00063: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 64/70\n",
      "809/809 [==============================] - 374s 462ms/step - loss: 0.0283 - accuracy: 0.9898 - val_loss: 1.0273 - val_accuracy: 0.7076\n",
      "\n",
      "Epoch 00064: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 65/70\n",
      "809/809 [==============================] - 380s 469ms/step - loss: 0.0301 - accuracy: 0.9888 - val_loss: 1.0037 - val_accuracy: 0.7033\n",
      "\n",
      "Epoch 00065: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 66/70\n",
      "809/809 [==============================] - 371s 458ms/step - loss: 0.0280 - accuracy: 0.9897 - val_loss: 0.9469 - val_accuracy: 0.7130\n",
      "\n",
      "Epoch 00066: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 67/70\n",
      "809/809 [==============================] - 365s 451ms/step - loss: 0.0278 - accuracy: 0.9898 - val_loss: 0.9760 - val_accuracy: 0.7136\n",
      "\n",
      "Epoch 00067: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 68/70\n",
      "809/809 [==============================] - 364s 450ms/step - loss: 0.0273 - accuracy: 0.9902 - val_loss: 0.9446 - val_accuracy: 0.7107\n",
      "\n",
      "Epoch 00068: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 69/70\n",
      "809/809 [==============================] - 363s 449ms/step - loss: 0.0297 - accuracy: 0.9892 - val_loss: 0.9353 - val_accuracy: 0.7182\n",
      "\n",
      "Epoch 00069: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 70/70\n",
      "809/809 [==============================] - 365s 452ms/step - loss: 0.0262 - accuracy: 0.9901 - val_loss: 0.9715 - val_accuracy: 0.7153\n",
      "\n",
      "Epoch 00070: saving model to /kaggle/working/training/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fea4d1bbe50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#weights = {0:1, 1:6}\n",
    "#model.fit(train_features, train_target,  class_weight=weights,validation_split=0.3,batch_size = 64,epochs=70)\n",
    "\n",
    "makeModel = myModel()\n",
    "\n",
    "if os.path.exists('/kaggle/working/training'):\n",
    "    os.rmdir('/kaggle/working/training')\n",
    "os.mkdir('/kaggle/working/training')\n",
    "\n",
    "path_checkpoint = \"/kaggle/working/training/cp.ckpt\"\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath=path_checkpoint,\\\n",
    "                                                 save_weights_only=True,\\\n",
    "                                                 verbose=1)\n",
    "#model.fit(train_features, train_target,validation_split=0.3,batch_size = 64,epochs=45)\n",
    "\n",
    "makeModel.fit(train_features, \\\n",
    "          train_target,  \\\n",
    "          epochs=70,\\\n",
    "          validation_split = 0.3,\\\n",
    "          batch_size=64,\\\n",
    "          callbacks=[callback]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d617ebf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:14:05.210395Z",
     "iopub.status.busy": "2023-01-30T23:14:05.209558Z",
     "iopub.status.idle": "2023-01-30T23:14:05.215097Z",
     "shell.execute_reply": "2023-01-30T23:14:05.214211Z"
    },
    "papermill": {
     "duration": 4.163752,
     "end_time": "2023-01-30T23:14:05.217688",
     "exception": false,
     "start_time": "2023-01-30T23:14:01.053936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.save(\"/kaggle/working/trained_model_breast_cancer3.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f576dcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:14:13.491031Z",
     "iopub.status.busy": "2023-01-30T23:14:13.490639Z",
     "iopub.status.idle": "2023-01-30T23:14:13.496273Z",
     "shell.execute_reply": "2023-01-30T23:14:13.495385Z"
    },
    "papermill": {
     "duration": 4.142431,
     "end_time": "2023-01-30T23:14:13.498336",
     "exception": false,
     "start_time": "2023-01-30T23:14:09.355905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "#savedModel = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03f93f31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:14:21.880410Z",
     "iopub.status.busy": "2023-01-30T23:14:21.879679Z",
     "iopub.status.idle": "2023-01-30T23:14:42.866268Z",
     "shell.execute_reply": "2023-01-30T23:14:42.865241Z"
    },
    "papermill": {
     "duration": 25.202105,
     "end_time": "2023-01-30T23:14:42.869047",
     "exception": false,
     "start_time": "2023-01-30T23:14:17.666942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_features=[]\n",
    "for i in test['img_data']:\n",
    "    i=np.array(i)\n",
    "    test_features.append(i)\n",
    "test_features=np.array(test_features)\n",
    " \n",
    "\n",
    "    \n",
    "#featureTransform = test_features.reshape(len(test_features), 6400)\n",
    "scaler = MinMaxScaler()\n",
    "#featureTransform =scaler.fit_transform(featureTransform)\n",
    "norm_features= []\n",
    "for i in range(len(test_features)):\n",
    "    norm_features.append(scaler.fit_transform(test_features[i]))\n",
    "test_features=np.array(norm_features)\n",
    "\n",
    "\n",
    "#backTransform = featureTransform.reshape(len(test_features),80,80)\n",
    "test_features = test_features.reshape(len(test_features),95,95,1)\n",
    "\n",
    "\n",
    "\n",
    "test_target = np.array(test['cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cd7d4c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:14:51.220552Z",
     "iopub.status.busy": "2023-01-30T23:14:51.219850Z",
     "iopub.status.idle": "2023-01-30T23:15:48.498168Z",
     "shell.execute_reply": "2023-01-30T23:15:48.497074Z"
    },
    "papermill": {
     "duration": 61.410716,
     "end_time": "2023-01-30T23:15:48.501480",
     "exception": false,
     "start_time": "2023-01-30T23:14:47.090764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "991/991 - 51s - loss: 0.9962 - accuracy: 0.7060\n",
      "[0.9962002038955688, 0.7060067057609558]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 23:15:46.045786: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "My_model = myModel()\n",
    "My_model.load_weights(path_checkpoint)\n",
    "accuracy = My_model.evaluate(test_features, test_target, verbose=2)\n",
    "print(accuracy)\n",
    "\n",
    "My_model.save('/kaggle/working/my_model')\n",
    "#new_model = tf.keras.models.load_model('/kaggle/working/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8dac6291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:15:56.763819Z",
     "iopub.status.busy": "2023-01-30T23:15:56.763415Z",
     "iopub.status.idle": "2023-01-30T23:16:49.832729Z",
     "shell.execute_reply": "2023-01-30T23:16:49.831525Z"
    },
    "papermill": {
     "duration": 57.25637,
     "end_time": "2023-01-30T23:16:49.835725",
     "exception": false,
     "start_time": "2023-01-30T23:15:52.579355",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('/kaggle/working/my_model')\n",
    "pred = new_model.predict(test_features)\n",
    "bin_pred = []\n",
    "for i in pred:\n",
    "    if i>=0.5:\n",
    "        bin_pred.append(1)\n",
    "    else:\n",
    "        bin_pred.append(0)\n",
    "bin_pred = np.array(bin_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3016a7ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:16:58.162944Z",
     "iopub.status.busy": "2023-01-30T23:16:58.161823Z",
     "iopub.status.idle": "2023-01-30T23:16:58.216978Z",
     "shell.execute_reply": "2023-01-30T23:16:58.215526Z"
    },
    "papermill": {
     "duration": 4.212697,
     "end_time": "2023-01-30T23:16:58.219748",
     "exception": false,
     "start_time": "2023-01-30T23:16:54.007051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7060066881191243\n",
      "0.7838638512448787 0.6279921682561738\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "acc = sklearn.metrics.accuracy_score(test_target, bin_pred)\n",
    "print(acc)\n",
    "\n",
    "countzero=0\n",
    "countone=0\n",
    "countzerot=0\n",
    "countonet=0\n",
    "for i, j in zip(test_target, bin_pred):\n",
    "    if i==0 and j==0:\n",
    "        countzero+=1\n",
    "    if i==1 and j==1:\n",
    "        countone+=1\n",
    "    if i==1:\n",
    "        countonet+=1\n",
    "    if i==0:\n",
    "        countzerot+=1\n",
    "print(countzero/countzerot,countone/countonet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16dac836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:17:06.500966Z",
     "iopub.status.busy": "2023-01-30T23:17:06.500335Z",
     "iopub.status.idle": "2023-01-30T23:17:06.512528Z",
     "shell.execute_reply": "2023-01-30T23:17:06.511363Z"
    },
    "papermill": {
     "duration": 4.164071,
     "end_time": "2023-01-30T23:17:06.515098",
     "exception": false,
     "start_time": "2023-01-30T23:17:02.351027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6809108029447013\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives )\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives )\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "\n",
    "print(f1_m(test_target,bin_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b64bad42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:17:14.838417Z",
     "iopub.status.busy": "2023-01-30T23:17:14.837568Z",
     "iopub.status.idle": "2023-01-30T23:17:47.472079Z",
     "shell.execute_reply": "2023-01-30T23:17:47.470513Z"
    },
    "papermill": {
     "duration": 36.814285,
     "end_time": "2023-01-30T23:17:47.475650",
     "exception": false,
     "start_time": "2023-01-30T23:17:10.661365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:00<00:00,  3.51it/s]\n"
     ]
    }
   ],
   "source": [
    "datasetPath = '/kaggle/input/rsna-breast-cancer-detection/test.csv'\n",
    "imgPath = '/kaggle/input/rsna-breast-cancer-detection/test_images/'\n",
    "\n",
    "testImgData = dcmToPix(datasetPath, imgPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "20ba39f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:17:55.729608Z",
     "iopub.status.busy": "2023-01-30T23:17:55.729096Z",
     "iopub.status.idle": "2023-01-30T23:17:55.766483Z",
     "shell.execute_reply": "2023-01-30T23:17:55.764946Z"
    },
    "papermill": {
     "duration": 4.149382,
     "end_time": "2023-01-30T23:17:55.769260",
     "exception": false,
     "start_time": "2023-01-30T23:17:51.619878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datacancer = pd.read_csv(datasetPath)\n",
    "imgDataFrame = {'img_data':testImgData}\n",
    "imgData2 = pd.DataFrame(imgDataFrame)\n",
    "testImgData=imgData2\n",
    "imgdata_shuff = testImgData.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86f1c119",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:18:04.165305Z",
     "iopub.status.busy": "2023-01-30T23:18:04.164859Z",
     "iopub.status.idle": "2023-01-30T23:18:04.196214Z",
     "shell.execute_reply": "2023-01-30T23:18:04.195345Z"
    },
    "papermill": {
     "duration": 4.165252,
     "end_time": "2023-01-30T23:18:04.198581",
     "exception": false,
     "start_time": "2023-01-30T23:18:00.033329",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 202.83it/s]\n"
     ]
    }
   ],
   "source": [
    "imgDataList=[]\n",
    "for j in tqdm(imgdata_shuff['img_data']):\n",
    "    imgDataList.append(random_rotate(j))\n",
    "imgdata_shuff['img_data'] = imgDataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bea424d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:18:12.522441Z",
     "iopub.status.busy": "2023-01-30T23:18:12.521607Z",
     "iopub.status.idle": "2023-01-30T23:18:12.891810Z",
     "shell.execute_reply": "2023-01-30T23:18:12.890770Z"
    },
    "papermill": {
     "duration": 4.541776,
     "end_time": "2023-01-30T23:18:12.894536",
     "exception": false,
     "start_time": "2023-01-30T23:18:08.352760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test=imgdata_shuff\n",
    "\n",
    "\n",
    "test_features=[]\n",
    "for i in test['img_data']:\n",
    "    i=np.array(i)\n",
    "    test_features.append(i)\n",
    "test_features=np.array(test_features)\n",
    " \n",
    "#featureTransform = test_features.reshape(len(test_features), 6400)\n",
    "scaler = MinMaxScaler()\n",
    "#featureTransform =scaler.fit_transform(featureTransform)\n",
    "norm_features= []\n",
    "for i in range(len(test_features)):\n",
    "    norm_features.append(scaler.fit_transform(test_features[i]))\n",
    "test_features=np.array(norm_features)\n",
    "\n",
    "\n",
    "#backTransform = featureTransform.reshape(len(test_features),80,80)\n",
    "test_features = test_features.reshape(len(test_features),95,95,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29eca9d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:18:21.212677Z",
     "iopub.status.busy": "2023-01-30T23:18:21.211861Z",
     "iopub.status.idle": "2023-01-30T23:18:21.319874Z",
     "shell.execute_reply": "2023-01-30T23:18:21.318423Z"
    },
    "papermill": {
     "duration": 4.314705,
     "end_time": "2023-01-30T23:18:21.322682",
     "exception": false,
     "start_time": "2023-01-30T23:18:17.007977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "pred = new_model.predict(test_features)\n",
    "bin_pred = []\n",
    "for i in pred:\n",
    "    if i>=0.5:\n",
    "        bin_pred.append(1)\n",
    "    else:\n",
    "        bin_pred.append(0)\n",
    "bin_pred = np.array(bin_pred)\n",
    "print(bin_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e1a8dab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-30T23:18:29.577494Z",
     "iopub.status.busy": "2023-01-30T23:18:29.576667Z",
     "iopub.status.idle": "2023-01-30T23:18:29.595008Z",
     "shell.execute_reply": "2023-01-30T23:18:29.593553Z"
    },
    "papermill": {
     "duration": 4.155898,
     "end_time": "2023-01-30T23:18:29.597625",
     "exception": false,
     "start_time": "2023-01-30T23:18:25.441727",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prediction_id  cancer\n",
      "0       10008_L       0\n",
      "1       10008_L       0\n",
      "2       10008_R       0\n",
      "3       10008_R       0\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n",
    "\n",
    "submissionFrame={'prediction_id':testData['prediction_id'],'cancer':bin_pred}\n",
    "submission = pd.DataFrame(submissionFrame)\n",
    "print(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26134.038712,
   "end_time": "2023-01-30T23:18:37.807388",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-01-30T16:03:03.768676",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
