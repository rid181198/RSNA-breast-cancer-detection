{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5429f498",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T09:35:38.543324Z",
     "iopub.status.busy": "2023-01-31T09:35:38.542663Z",
     "iopub.status.idle": "2023-01-31T09:35:47.136422Z",
     "shell.execute_reply": "2023-01-31T09:35:47.134995Z"
    },
    "papermill": {
     "duration": 8.607693,
     "end_time": "2023-01-31T09:35:47.139809",
     "exception": false,
     "start_time": "2023-01-31T09:35:38.532116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "from PIL import Image as im\n",
    "import random\n",
    "from scipy import ndimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cf77e86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T09:35:47.156846Z",
     "iopub.status.busy": "2023-01-31T09:35:47.156125Z",
     "iopub.status.idle": "2023-01-31T09:36:01.872040Z",
     "shell.execute_reply": "2023-01-31T09:36:01.870248Z"
    },
    "papermill": {
     "duration": 14.72819,
     "end_time": "2023-01-31T09:36:01.875712",
     "exception": false,
     "start_time": "2023-01-31T09:35:47.147522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dicomsdl\r\n",
      "  Downloading dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: dicomsdl\r\n",
      "Successfully installed dicomsdl-0.109.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install dicomsdl\n",
    "#!pip install /kaggle/input/rsnapacks/dicomsdl-0.109.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "#import pydicom as dicom\n",
    "import dicomsdl as dicom\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from PIL import Image as im\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fd546a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T09:36:01.896451Z",
     "iopub.status.busy": "2023-01-31T09:36:01.895924Z",
     "iopub.status.idle": "2023-01-31T09:36:01.921762Z",
     "shell.execute_reply": "2023-01-31T09:36:01.920437Z"
    },
    "papermill": {
     "duration": 0.04107,
     "end_time": "2023-01-31T09:36:01.925380",
     "exception": false,
     "start_time": "2023-01-31T09:36:01.884310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasetPath = '/kaggle/input/rsna-breast-cancer-detection/train.csv'\n",
    "imgPath = '/kaggle/input/rsna-breast-cancer-detection/train_images/'\n",
    "\n",
    "def crop(sideName, imgName):\n",
    "    \"\"\"\n",
    "    This function is used to crop the breast images. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :sideName = Laterality of breast if it is right or left\n",
    "    :imgName = Image pixel data of the DCM images\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    if sideName == 'L':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col==0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = max(colind)\n",
    "        imgName = imgName[0:512,0:crop_size]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "        \n",
    "    if sideName == 'R':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col!=0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = min(colind)\n",
    "        imgName = imgName[0:512,crop_size:512]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "    \n",
    "    return imgName    \n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "def crop_reverse(sideName, imgName):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to crop the breast images but in the reverse order.\n",
    "    Because the laterality is defined wrongly for some images. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :sideName = Laterality of breast if it is right or left\n",
    "    :imgName = Image pixel data of the DCM images\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if sideName == 'R':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col==0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = max(colind)\n",
    "        imgName = imgName[0:512,0:crop_size]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "        \n",
    "    if sideName == 'L':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col!=0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = min(colind)\n",
    "        imgName = imgName[0:512,crop_size:512]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "    \n",
    "    return imgName    \n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "def img_process(i,filename,sides):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to process the images which will be used for the training/test dataset. It takes three arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :i = Index of the image in the dataframe\n",
    "    :filename = Path of the image\n",
    "    :sides = List of all images' laterality\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #ds = dicom.dcmread(filename)\n",
    "    dsraw = dicom.open(filename)\n",
    "    ds = dsraw.pixelData()\n",
    "    \n",
    "    ds = (ds - ds.min()) / (ds.max() - ds.min())\n",
    "    if dsraw.PhotometricInterpretation == \"MONOCHROME1\":  \n",
    "        ds = 1 - ds\n",
    "    ds = (ds * 255).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    #ds = cv2.normalize(ds, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    ds = cv2.resize(ds,(512,512))\n",
    "    \n",
    "    #ds = np.where(ds >= 0.999, 0,ds)\n",
    "    \n",
    "    try:\n",
    "        ds = np.array(crop(sides[i], ds))   \n",
    "    except:\n",
    "        ds = np.array(crop_reverse(sides[i], ds))\n",
    "    \n",
    "\n",
    "    #train_data.loc[i,'img_data'] = [img_fin]\n",
    "    #train_data.to_csv('/kaggle/working/training_img_data.csv') \n",
    "    return ds\n",
    "    gc.collect()\n",
    "\n",
    "def dcmToPix(datasetPath, imgPath):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to process all the images which will be used for the training/test dataset. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :datasetPath = Path of the cancer dataset\n",
    "    :imgPath = Path of the image dataset\n",
    "   \n",
    "    Output:-\n",
    "    :return = Array of all the processed images\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    dataset = pd.read_csv(datasetPath)\n",
    "    \n",
    "    patient_ids = dataset['patient_id']\n",
    "    image_ids = dataset['image_id']\n",
    "    sides  = dataset['laterality']\n",
    "\n",
    "    imgData = []\n",
    "\n",
    "    for pi, ii, leng in zip(patient_ids, image_ids, range(len(patient_ids))):\n",
    "        imgData.append(imgPath + str(pi) + '/' + str(ii) + '.dcm')\n",
    "\n",
    "    dataset['img_data'] = \" \"\n",
    "    \n",
    "    result = Parallel(n_jobs=128)(\\\n",
    "    delayed(img_process)(i, fname, sides) for i, fname in zip(range(len(imgData)),tqdm(imgData))\\\n",
    "    )\n",
    "    \n",
    "    dataset['img_data'] = result\n",
    "    dataset.to_pickle('imgData.pkl' )\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706f9369",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-01-31T09:36:01.949908Z",
     "iopub.status.busy": "2023-01-31T09:36:01.949482Z",
     "iopub.status.idle": "2023-01-31T09:36:14.739269Z",
     "shell.execute_reply": "2023-01-31T09:36:14.738087Z"
    },
    "papermill": {
     "duration": 12.804611,
     "end_time": "2023-01-31T09:36:14.742184",
     "exception": false,
     "start_time": "2023-01-31T09:36:01.937573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with (open('/kaggle/input/output/imgData.pkl', \"rb\")) as openfile:\n",
    "     imgData = pickle.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b85ff0ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T09:36:14.760576Z",
     "iopub.status.busy": "2023-01-31T09:36:14.759508Z",
     "iopub.status.idle": "2023-01-31T09:36:14.764981Z",
     "shell.execute_reply": "2023-01-31T09:36:14.763828Z"
    },
    "papermill": {
     "duration": 0.017409,
     "end_time": "2023-01-31T09:36:14.767555",
     "exception": false,
     "start_time": "2023-01-31T09:36:14.750146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#datacancer = pd.read_csv(datasetPath)\n",
    "#imgDataFrame = {'cancer':datacancer['cancer'][:50], 'img_data':imgData}\n",
    "#imgData2 = pd.DataFrame(imgDataFrame)\n",
    "\n",
    "#imgData=imgData2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fbd23fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T09:36:14.787159Z",
     "iopub.status.busy": "2023-01-31T09:36:14.786708Z",
     "iopub.status.idle": "2023-01-31T09:36:14.876988Z",
     "shell.execute_reply": "2023-01-31T09:36:14.875703Z"
    },
    "papermill": {
     "duration": 0.104272,
     "end_time": "2023-01-31T09:36:14.879885",
     "exception": false,
     "start_time": "2023-01-31T09:36:14.775613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgdata_pos = imgData[imgData['cancer'] == 1]\n",
    "imgdata_neg = imgData[imgData['cancer'] == 0]\n",
    "\n",
    "imgdata_pos = imgdata_pos.sample(frac = 1)\n",
    "imgdata_neg = imgdata_neg.sample(frac = 1)\n",
    "\n",
    "imgdata_neg = imgdata_neg.sample(frac= 0.5)\n",
    "\n",
    "frames = 1*[imgdata_pos]\n",
    "frames.append(imgdata_neg)\n",
    "imgdata_shuff = pd.concat(frames)\n",
    "imgdata_shuff = imgdata_shuff.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ee1f740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T09:36:14.899070Z",
     "iopub.status.busy": "2023-01-31T09:36:14.898679Z",
     "iopub.status.idle": "2023-01-31T09:36:14.909441Z",
     "shell.execute_reply": "2023-01-31T09:36:14.908225Z"
    },
    "papermill": {
     "duration": 0.02323,
     "end_time": "2023-01-31T09:36:14.912174",
     "exception": false,
     "start_time": "2023-01-31T09:36:14.888944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    26774\n",
      "1     1158\n",
      "Name: cancer, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(imgdata_shuff['cancer'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "235efde5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T09:36:14.930304Z",
     "iopub.status.busy": "2023-01-31T09:36:14.929910Z",
     "iopub.status.idle": "2023-01-31T09:36:14.936017Z",
     "shell.execute_reply": "2023-01-31T09:36:14.934727Z"
    },
    "papermill": {
     "duration": 0.018371,
     "end_time": "2023-01-31T09:36:14.938602",
     "exception": false,
     "start_time": "2023-01-31T09:36:14.920231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_rotate(imgData):\n",
    "    #thresh = 0.15\n",
    "    \n",
    "    imgData = imgData.reshape(128,128)\n",
    "    #imgData = ndimage.rotate(imgData, random.randint(0, 180), reshape=False)\n",
    "\n",
    "    #imgData = np.clip(imgData,thresh,1)\n",
    "    imgData = imgData[15:110,15:110]\n",
    "    \n",
    "    #clahe = cv2.createCLAHE(clipLimit=random.uniform(8, 10), tileGridSize=(5,5))\n",
    "    #imgData = clahe.apply(imgData)\n",
    "    #imgData = im.fromarray(imgData)\n",
    "    #imgData = np.asarray(imgData.rotate(random.randint(-20, 20)))\n",
    "    return imgData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c69ba4f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T09:36:14.957605Z",
     "iopub.status.busy": "2023-01-31T09:36:14.956318Z",
     "iopub.status.idle": "2023-01-31T09:36:15.036315Z",
     "shell.execute_reply": "2023-01-31T09:36:15.035384Z"
    },
    "papermill": {
     "duration": 0.092153,
     "end_time": "2023-01-31T09:36:15.038836",
     "exception": false,
     "start_time": "2023-01-31T09:36:14.946683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27932/27932 [00:00<00:00, 463718.76it/s]\n"
     ]
    }
   ],
   "source": [
    "imgDataList=[]\n",
    "for j in tqdm(imgdata_shuff['img_data']):\n",
    "    imgDataList.append(random_rotate(j))\n",
    "imgdata_shuff['img_data'] = imgDataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3b9424",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T09:36:15.057375Z",
     "iopub.status.busy": "2023-01-31T09:36:15.056968Z",
     "iopub.status.idle": "2023-01-31T09:36:22.387181Z",
     "shell.execute_reply": "2023-01-31T09:36:22.386023Z"
    },
    "papermill": {
     "duration": 7.342448,
     "end_time": "2023-01-31T09:36:22.389899",
     "exception": false,
     "start_time": "2023-01-31T09:36:15.047451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test = train_test_split(imgdata_shuff, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "train_target = np.array(train['cancer'])\n",
    "train_features=[]\n",
    "for i in train['img_data']:\n",
    "    i=np.array(i)\n",
    "    train_features.append(i)\n",
    "train_features=np.array(train_features)\n",
    "\n",
    "\n",
    "\n",
    "#featureTransform = train_features.reshape(len(train_features), 6400)\n",
    "\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "#featureTransform = scaler.fit_transform(featureTransform)\n",
    "norm_features= []\n",
    "for i in range(len(train_features)):\n",
    "        norm_features.append(scaler.fit_transform(train_features[i]))\n",
    "train_features=np.array(norm_features)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#backTransform = featureTransform.reshape(len(train_features),80,80)\n",
    "#train_features = backTransform.reshape(len(train_features),80,80,1)\n",
    "train_features = train_features.reshape(len(train_features),95,95,1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b47048e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T09:36:22.408429Z",
     "iopub.status.busy": "2023-01-31T09:36:22.407966Z",
     "iopub.status.idle": "2023-01-31T09:36:22.426736Z",
     "shell.execute_reply": "2023-01-31T09:36:22.425446Z"
    },
    "papermill": {
     "duration": 0.031549,
     "end_time": "2023-01-31T09:36:22.429810",
     "exception": false,
     "start_time": "2023-01-31T09:36:22.398261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dense, Conv2D, Flatten,MaxPooling2D, Dropout, BatchNormalization, GlobalMaxPooling2D\n",
    "\n",
    "\n",
    "def myModel():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, 3, activation = \"relu\", input_shape = (95,95,1)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, 3, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(64, 3, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    #model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, 3, activation = \"relu\"))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    #model.add(Dropout(0.1))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(1024, activation = 'relu')) \n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer =tf.keras.optimizers.Adam(learning_rate=0.0001),\\\n",
    "                  loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "from keras import backend as K\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives )\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives )\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#loss = tf.keras.losses.BinaryFocalCrossentropy(\\\n",
    "#    apply_class_balancing=True, gamma=5, from_logits=True,\\\n",
    "#    reduction=tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "\n",
    "#model.compile(optimizer =tf.keras.optimizers.Adam(learning_rate=0.0001),\\\n",
    "#              loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc430f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T09:36:22.448136Z",
     "iopub.status.busy": "2023-01-31T09:36:22.447580Z",
     "iopub.status.idle": "2023-01-31T09:36:22.452800Z",
     "shell.execute_reply": "2023-01-31T09:36:22.451599Z"
    },
    "papermill": {
     "duration": 0.017482,
     "end_time": "2023-01-31T09:36:22.455532",
     "exception": false,
     "start_time": "2023-01-31T09:36:22.438050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "#model = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "888f3ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T09:36:22.474240Z",
     "iopub.status.busy": "2023-01-31T09:36:22.473585Z",
     "iopub.status.idle": "2023-01-31T11:59:37.606423Z",
     "shell.execute_reply": "2023-01-31T11:59:37.604893Z"
    },
    "papermill": {
     "duration": 8595.14516,
     "end_time": "2023-01-31T11:59:37.609008",
     "exception": false,
     "start_time": "2023-01-31T09:36:22.463848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 09:36:22.515916: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2023-01-31 09:36:23.626475: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "214/214 [==============================] - 88s 402ms/step - loss: 1.0323 - accuracy: 0.8255 - val_loss: 1.0720 - val_accuracy: 0.0406\n",
      "\n",
      "Epoch 00001: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 2/100\n",
      "214/214 [==============================] - 85s 398ms/step - loss: 0.6999 - accuracy: 0.8742 - val_loss: 0.3482 - val_accuracy: 0.9570\n",
      "\n",
      "Epoch 00002: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 3/100\n",
      "214/214 [==============================] - 85s 396ms/step - loss: 0.5997 - accuracy: 0.9025 - val_loss: 0.3620 - val_accuracy: 0.9102\n",
      "\n",
      "Epoch 00003: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 4/100\n",
      "214/214 [==============================] - 85s 395ms/step - loss: 0.4912 - accuracy: 0.9189 - val_loss: 0.3186 - val_accuracy: 0.8996\n",
      "\n",
      "Epoch 00004: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 5/100\n",
      "214/214 [==============================] - 85s 397ms/step - loss: 0.4002 - accuracy: 0.9344 - val_loss: 0.3358 - val_accuracy: 0.8861\n",
      "\n",
      "Epoch 00005: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 6/100\n",
      "214/214 [==============================] - 85s 399ms/step - loss: 0.3285 - accuracy: 0.9447 - val_loss: 0.2587 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00006: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 7/100\n",
      "214/214 [==============================] - 85s 398ms/step - loss: 0.2579 - accuracy: 0.9597 - val_loss: 0.2606 - val_accuracy: 0.9245\n",
      "\n",
      "Epoch 00007: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 8/100\n",
      "214/214 [==============================] - 85s 397ms/step - loss: 0.1978 - accuracy: 0.9687 - val_loss: 0.2367 - val_accuracy: 0.9451\n",
      "\n",
      "Epoch 00008: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 9/100\n",
      "214/214 [==============================] - 86s 400ms/step - loss: 0.1542 - accuracy: 0.9749 - val_loss: 0.2664 - val_accuracy: 0.9286\n",
      "\n",
      "Epoch 00009: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 10/100\n",
      "214/214 [==============================] - 85s 395ms/step - loss: 0.1413 - accuracy: 0.9758 - val_loss: 0.2803 - val_accuracy: 0.9340\n",
      "\n",
      "Epoch 00010: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 11/100\n",
      "214/214 [==============================] - 85s 397ms/step - loss: 0.1266 - accuracy: 0.9784 - val_loss: 0.2740 - val_accuracy: 0.9296\n",
      "\n",
      "Epoch 00011: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 12/100\n",
      "214/214 [==============================] - 85s 397ms/step - loss: 0.1137 - accuracy: 0.9809 - val_loss: 0.2741 - val_accuracy: 0.9429\n",
      "\n",
      "Epoch 00012: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 13/100\n",
      "214/214 [==============================] - 84s 391ms/step - loss: 0.0799 - accuracy: 0.9886 - val_loss: 0.3062 - val_accuracy: 0.9318\n",
      "\n",
      "Epoch 00013: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 14/100\n",
      "214/214 [==============================] - 85s 398ms/step - loss: 0.0836 - accuracy: 0.9857 - val_loss: 0.3648 - val_accuracy: 0.9570\n",
      "\n",
      "Epoch 00014: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 15/100\n",
      "214/214 [==============================] - 85s 399ms/step - loss: 0.0705 - accuracy: 0.9879 - val_loss: 0.3357 - val_accuracy: 0.9514\n",
      "\n",
      "Epoch 00015: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 16/100\n",
      "214/214 [==============================] - 85s 397ms/step - loss: 0.0545 - accuracy: 0.9912 - val_loss: 0.3233 - val_accuracy: 0.9400\n",
      "\n",
      "Epoch 00016: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 17/100\n",
      "214/214 [==============================] - 85s 400ms/step - loss: 0.0573 - accuracy: 0.9901 - val_loss: 0.3607 - val_accuracy: 0.9192\n",
      "\n",
      "Epoch 00017: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 18/100\n",
      "214/214 [==============================] - 86s 400ms/step - loss: 0.0808 - accuracy: 0.9862 - val_loss: 0.3299 - val_accuracy: 0.9499\n",
      "\n",
      "Epoch 00018: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 19/100\n",
      "214/214 [==============================] - 85s 397ms/step - loss: 0.0604 - accuracy: 0.9886 - val_loss: 0.3287 - val_accuracy: 0.9516\n",
      "\n",
      "Epoch 00019: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 20/100\n",
      "214/214 [==============================] - 86s 399ms/step - loss: 0.0547 - accuracy: 0.9901 - val_loss: 0.3547 - val_accuracy: 0.9420\n",
      "\n",
      "Epoch 00020: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 21/100\n",
      "214/214 [==============================] - 85s 398ms/step - loss: 0.0515 - accuracy: 0.9897 - val_loss: 0.3972 - val_accuracy: 0.9531\n",
      "\n",
      "Epoch 00021: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 22/100\n",
      "214/214 [==============================] - 85s 398ms/step - loss: 0.0385 - accuracy: 0.9934 - val_loss: 0.3775 - val_accuracy: 0.9446\n",
      "\n",
      "Epoch 00022: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 23/100\n",
      "214/214 [==============================] - 85s 397ms/step - loss: 0.0603 - accuracy: 0.9885 - val_loss: 0.4548 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00023: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 24/100\n",
      "214/214 [==============================] - 85s 395ms/step - loss: 0.0566 - accuracy: 0.9892 - val_loss: 0.3792 - val_accuracy: 0.9446\n",
      "\n",
      "Epoch 00024: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 25/100\n",
      "214/214 [==============================] - 86s 399ms/step - loss: 0.0812 - accuracy: 0.9864 - val_loss: 0.3638 - val_accuracy: 0.9267\n",
      "\n",
      "Epoch 00025: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 26/100\n",
      "214/214 [==============================] - 84s 393ms/step - loss: 0.0911 - accuracy: 0.9821 - val_loss: 0.4364 - val_accuracy: 0.9535\n",
      "\n",
      "Epoch 00026: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 27/100\n",
      "214/214 [==============================] - 85s 399ms/step - loss: 0.0600 - accuracy: 0.9882 - val_loss: 0.4160 - val_accuracy: 0.9528\n",
      "\n",
      "Epoch 00027: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 28/100\n",
      "214/214 [==============================] - 85s 398ms/step - loss: 0.0406 - accuracy: 0.9920 - val_loss: 0.3849 - val_accuracy: 0.9194\n",
      "\n",
      "Epoch 00028: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 29/100\n",
      "214/214 [==============================] - 84s 394ms/step - loss: 0.0278 - accuracy: 0.9954 - val_loss: 0.4307 - val_accuracy: 0.9470\n",
      "\n",
      "Epoch 00029: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 30/100\n",
      "214/214 [==============================] - 85s 396ms/step - loss: 0.0256 - accuracy: 0.9952 - val_loss: 0.4380 - val_accuracy: 0.9499\n",
      "\n",
      "Epoch 00030: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 31/100\n",
      "214/214 [==============================] - 85s 397ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 0.4367 - val_accuracy: 0.9501\n",
      "\n",
      "Epoch 00031: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 32/100\n",
      "214/214 [==============================] - 85s 399ms/step - loss: 0.0186 - accuracy: 0.9966 - val_loss: 0.4632 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00032: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 33/100\n",
      "214/214 [==============================] - 84s 394ms/step - loss: 0.0188 - accuracy: 0.9970 - val_loss: 0.4346 - val_accuracy: 0.9386\n",
      "\n",
      "Epoch 00033: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 34/100\n",
      "214/214 [==============================] - 86s 400ms/step - loss: 0.0556 - accuracy: 0.9893 - val_loss: 0.4610 - val_accuracy: 0.9519\n",
      "\n",
      "Epoch 00034: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 35/100\n",
      "214/214 [==============================] - 86s 404ms/step - loss: 0.0586 - accuracy: 0.9894 - val_loss: 0.4463 - val_accuracy: 0.9490\n",
      "\n",
      "Epoch 00035: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 36/100\n",
      "214/214 [==============================] - 85s 399ms/step - loss: 0.0334 - accuracy: 0.9939 - val_loss: 0.4628 - val_accuracy: 0.9564\n",
      "\n",
      "Epoch 00036: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 37/100\n",
      "214/214 [==============================] - 86s 402ms/step - loss: 0.0269 - accuracy: 0.9949 - val_loss: 0.4325 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00037: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 38/100\n",
      "214/214 [==============================] - 86s 402ms/step - loss: 0.0291 - accuracy: 0.9947 - val_loss: 0.4505 - val_accuracy: 0.9299\n",
      "\n",
      "Epoch 00038: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 39/100\n",
      "214/214 [==============================] - 85s 398ms/step - loss: 0.0308 - accuracy: 0.9946 - val_loss: 0.4433 - val_accuracy: 0.9408\n",
      "\n",
      "Epoch 00039: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 40/100\n",
      "214/214 [==============================] - 85s 396ms/step - loss: 0.0242 - accuracy: 0.9945 - val_loss: 0.5576 - val_accuracy: 0.9555\n",
      "\n",
      "Epoch 00040: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 41/100\n",
      "214/214 [==============================] - 85s 398ms/step - loss: 0.0294 - accuracy: 0.9949 - val_loss: 0.4826 - val_accuracy: 0.9426\n",
      "\n",
      "Epoch 00041: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 42/100\n",
      "214/214 [==============================] - 85s 398ms/step - loss: 0.0263 - accuracy: 0.9950 - val_loss: 0.5578 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00042: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 43/100\n",
      "214/214 [==============================] - 85s 398ms/step - loss: 0.0278 - accuracy: 0.9949 - val_loss: 0.4652 - val_accuracy: 0.9443\n",
      "\n",
      "Epoch 00043: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 44/100\n",
      "214/214 [==============================] - 86s 400ms/step - loss: 0.0311 - accuracy: 0.9934 - val_loss: 0.5988 - val_accuracy: 0.9576\n",
      "\n",
      "Epoch 00044: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 45/100\n",
      "214/214 [==============================] - 85s 399ms/step - loss: 0.0375 - accuracy: 0.9928 - val_loss: 0.4482 - val_accuracy: 0.9419\n",
      "\n",
      "Epoch 00045: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 46/100\n",
      "214/214 [==============================] - 86s 404ms/step - loss: 0.0256 - accuracy: 0.9950 - val_loss: 0.5274 - val_accuracy: 0.9535\n",
      "\n",
      "Epoch 00046: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 47/100\n",
      "214/214 [==============================] - 87s 406ms/step - loss: 0.0298 - accuracy: 0.9944 - val_loss: 0.5535 - val_accuracy: 0.9526\n",
      "\n",
      "Epoch 00047: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 48/100\n",
      "214/214 [==============================] - 86s 403ms/step - loss: 0.0192 - accuracy: 0.9963 - val_loss: 0.5879 - val_accuracy: 0.9541\n",
      "\n",
      "Epoch 00048: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 49/100\n",
      "214/214 [==============================] - 86s 404ms/step - loss: 0.0413 - accuracy: 0.9928 - val_loss: 0.4777 - val_accuracy: 0.9516\n",
      "\n",
      "Epoch 00049: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 50/100\n",
      "214/214 [==============================] - 85s 400ms/step - loss: 0.0525 - accuracy: 0.9906 - val_loss: 0.4488 - val_accuracy: 0.9417\n",
      "\n",
      "Epoch 00050: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 51/100\n",
      "214/214 [==============================] - 86s 401ms/step - loss: 0.0499 - accuracy: 0.9912 - val_loss: 0.5265 - val_accuracy: 0.9521\n",
      "\n",
      "Epoch 00051: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 52/100\n",
      "214/214 [==============================] - 86s 400ms/step - loss: 0.0225 - accuracy: 0.9961 - val_loss: 0.5204 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00052: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 53/100\n",
      "214/214 [==============================] - 86s 401ms/step - loss: 0.0159 - accuracy: 0.9972 - val_loss: 0.5118 - val_accuracy: 0.9463\n",
      "\n",
      "Epoch 00053: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 54/100\n",
      "214/214 [==============================] - 84s 394ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 0.6180 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00054: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 55/100\n",
      "214/214 [==============================] - 86s 402ms/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.5388 - val_accuracy: 0.9499\n",
      "\n",
      "Epoch 00055: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 56/100\n",
      "214/214 [==============================] - 86s 404ms/step - loss: 0.0267 - accuracy: 0.9948 - val_loss: 0.5139 - val_accuracy: 0.9403\n",
      "\n",
      "Epoch 00056: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 57/100\n",
      "214/214 [==============================] - 86s 400ms/step - loss: 0.0267 - accuracy: 0.9958 - val_loss: 0.5704 - val_accuracy: 0.9548\n",
      "\n",
      "Epoch 00057: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 58/100\n",
      "214/214 [==============================] - 86s 399ms/step - loss: 0.0204 - accuracy: 0.9957 - val_loss: 0.5430 - val_accuracy: 0.9512\n",
      "\n",
      "Epoch 00058: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 59/100\n",
      "214/214 [==============================] - 86s 402ms/step - loss: 0.0117 - accuracy: 0.9977 - val_loss: 0.5680 - val_accuracy: 0.9529\n",
      "\n",
      "Epoch 00059: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 60/100\n",
      "214/214 [==============================] - 85s 397ms/step - loss: 0.0186 - accuracy: 0.9963 - val_loss: 0.5443 - val_accuracy: 0.9441\n",
      "\n",
      "Epoch 00060: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 61/100\n",
      "214/214 [==============================] - 85s 399ms/step - loss: 0.0132 - accuracy: 0.9973 - val_loss: 0.5439 - val_accuracy: 0.9512\n",
      "\n",
      "Epoch 00061: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 62/100\n",
      "214/214 [==============================] - 87s 405ms/step - loss: 0.0225 - accuracy: 0.9949 - val_loss: 0.6758 - val_accuracy: 0.9565\n",
      "\n",
      "Epoch 00062: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 63/100\n",
      "214/214 [==============================] - 86s 403ms/step - loss: 0.0218 - accuracy: 0.9954 - val_loss: 0.5701 - val_accuracy: 0.9495\n",
      "\n",
      "Epoch 00063: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 64/100\n",
      "214/214 [==============================] - 86s 401ms/step - loss: 0.0313 - accuracy: 0.9941 - val_loss: 0.5378 - val_accuracy: 0.9509\n",
      "\n",
      "Epoch 00064: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 65/100\n",
      "214/214 [==============================] - 86s 404ms/step - loss: 0.0408 - accuracy: 0.9926 - val_loss: 0.5331 - val_accuracy: 0.9518\n",
      "\n",
      "Epoch 00065: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 66/100\n",
      "214/214 [==============================] - 86s 401ms/step - loss: 0.0102 - accuracy: 0.9977 - val_loss: 0.5640 - val_accuracy: 0.9553\n",
      "\n",
      "Epoch 00066: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 67/100\n",
      "214/214 [==============================] - 87s 407ms/step - loss: 0.0196 - accuracy: 0.9968 - val_loss: 0.4942 - val_accuracy: 0.9439\n",
      "\n",
      "Epoch 00067: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 68/100\n",
      "214/214 [==============================] - 86s 402ms/step - loss: 0.0194 - accuracy: 0.9955 - val_loss: 0.5828 - val_accuracy: 0.9543\n",
      "\n",
      "Epoch 00068: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 69/100\n",
      "214/214 [==============================] - 86s 402ms/step - loss: 0.0203 - accuracy: 0.9964 - val_loss: 0.6331 - val_accuracy: 0.9564\n",
      "\n",
      "Epoch 00069: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 70/100\n",
      "214/214 [==============================] - 87s 408ms/step - loss: 0.0312 - accuracy: 0.9932 - val_loss: 0.5296 - val_accuracy: 0.9502\n",
      "\n",
      "Epoch 00070: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 71/100\n",
      "214/214 [==============================] - 87s 406ms/step - loss: 0.0229 - accuracy: 0.9960 - val_loss: 0.5528 - val_accuracy: 0.9379\n",
      "\n",
      "Epoch 00071: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 72/100\n",
      "214/214 [==============================] - 87s 406ms/step - loss: 0.0286 - accuracy: 0.9941 - val_loss: 0.6183 - val_accuracy: 0.9569\n",
      "\n",
      "Epoch 00072: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 73/100\n",
      "214/214 [==============================] - 87s 408ms/step - loss: 0.0200 - accuracy: 0.9964 - val_loss: 0.5521 - val_accuracy: 0.9524\n",
      "\n",
      "Epoch 00073: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 74/100\n",
      "214/214 [==============================] - 86s 403ms/step - loss: 0.0118 - accuracy: 0.9972 - val_loss: 0.5804 - val_accuracy: 0.9531\n",
      "\n",
      "Epoch 00074: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 75/100\n",
      "214/214 [==============================] - 87s 405ms/step - loss: 0.0104 - accuracy: 0.9981 - val_loss: 0.5502 - val_accuracy: 0.9509\n",
      "\n",
      "Epoch 00075: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 76/100\n",
      "214/214 [==============================] - 85s 399ms/step - loss: 0.0197 - accuracy: 0.9966 - val_loss: 0.5864 - val_accuracy: 0.9519\n",
      "\n",
      "Epoch 00076: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 77/100\n",
      "214/214 [==============================] - 86s 403ms/step - loss: 0.0280 - accuracy: 0.9950 - val_loss: 0.5926 - val_accuracy: 0.9536\n",
      "\n",
      "Epoch 00077: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 78/100\n",
      "214/214 [==============================] - 86s 404ms/step - loss: 0.0311 - accuracy: 0.9939 - val_loss: 0.5111 - val_accuracy: 0.9487\n",
      "\n",
      "Epoch 00078: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 79/100\n",
      "214/214 [==============================] - 86s 403ms/step - loss: 0.0276 - accuracy: 0.9953 - val_loss: 0.6390 - val_accuracy: 0.9567\n",
      "\n",
      "Epoch 00079: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 80/100\n",
      "214/214 [==============================] - 87s 406ms/step - loss: 0.0249 - accuracy: 0.9954 - val_loss: 0.5005 - val_accuracy: 0.9475\n",
      "\n",
      "Epoch 00080: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 81/100\n",
      "214/214 [==============================] - 86s 404ms/step - loss: 0.0101 - accuracy: 0.9978 - val_loss: 0.6944 - val_accuracy: 0.9557\n",
      "\n",
      "Epoch 00081: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 82/100\n",
      "214/214 [==============================] - 87s 407ms/step - loss: 0.0203 - accuracy: 0.9965 - val_loss: 0.5057 - val_accuracy: 0.9414\n",
      "\n",
      "Epoch 00082: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 83/100\n",
      "214/214 [==============================] - 86s 404ms/step - loss: 0.0184 - accuracy: 0.9966 - val_loss: 0.5849 - val_accuracy: 0.9499\n",
      "\n",
      "Epoch 00083: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 84/100\n",
      "214/214 [==============================] - 87s 405ms/step - loss: 0.0196 - accuracy: 0.9968 - val_loss: 0.5547 - val_accuracy: 0.9472\n",
      "\n",
      "Epoch 00084: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 85/100\n",
      "214/214 [==============================] - 87s 406ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.6397 - val_accuracy: 0.9552\n",
      "\n",
      "Epoch 00085: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 86/100\n",
      "214/214 [==============================] - 87s 408ms/step - loss: 0.0086 - accuracy: 0.9980 - val_loss: 0.6517 - val_accuracy: 0.9550\n",
      "\n",
      "Epoch 00086: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 87/100\n",
      "214/214 [==============================] - 87s 405ms/step - loss: 0.0063 - accuracy: 0.9985 - val_loss: 0.6579 - val_accuracy: 0.9552\n",
      "\n",
      "Epoch 00087: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 88/100\n",
      "214/214 [==============================] - 87s 406ms/step - loss: 0.0059 - accuracy: 0.9988 - val_loss: 0.6419 - val_accuracy: 0.9550\n",
      "\n",
      "Epoch 00088: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 89/100\n",
      "214/214 [==============================] - 87s 405ms/step - loss: 0.0244 - accuracy: 0.9968 - val_loss: 0.6225 - val_accuracy: 0.9574\n",
      "\n",
      "Epoch 00089: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 90/100\n",
      "214/214 [==============================] - 87s 408ms/step - loss: 0.0207 - accuracy: 0.9963 - val_loss: 0.5991 - val_accuracy: 0.9516\n",
      "\n",
      "Epoch 00090: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 91/100\n",
      "214/214 [==============================] - 87s 406ms/step - loss: 0.0134 - accuracy: 0.9977 - val_loss: 0.6871 - val_accuracy: 0.9574\n",
      "\n",
      "Epoch 00091: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 92/100\n",
      "214/214 [==============================] - 87s 407ms/step - loss: 0.0191 - accuracy: 0.9967 - val_loss: 0.6481 - val_accuracy: 0.9523\n",
      "\n",
      "Epoch 00092: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 93/100\n",
      "214/214 [==============================] - 87s 406ms/step - loss: 0.0138 - accuracy: 0.9974 - val_loss: 0.6355 - val_accuracy: 0.9560\n",
      "\n",
      "Epoch 00093: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 94/100\n",
      "214/214 [==============================] - 87s 408ms/step - loss: 0.0094 - accuracy: 0.9990 - val_loss: 0.6064 - val_accuracy: 0.9465\n",
      "\n",
      "Epoch 00094: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 95/100\n",
      "214/214 [==============================] - 87s 405ms/step - loss: 0.0233 - accuracy: 0.9947 - val_loss: 0.6028 - val_accuracy: 0.9509\n",
      "\n",
      "Epoch 00095: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 96/100\n",
      "214/214 [==============================] - 87s 406ms/step - loss: 0.0107 - accuracy: 0.9978 - val_loss: 0.6101 - val_accuracy: 0.9512\n",
      "\n",
      "Epoch 00096: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 97/100\n",
      "214/214 [==============================] - 87s 405ms/step - loss: 0.0202 - accuracy: 0.9962 - val_loss: 0.6013 - val_accuracy: 0.9519\n",
      "\n",
      "Epoch 00097: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 98/100\n",
      "214/214 [==============================] - 87s 407ms/step - loss: 0.0263 - accuracy: 0.9953 - val_loss: 0.6583 - val_accuracy: 0.9529\n",
      "\n",
      "Epoch 00098: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 99/100\n",
      "214/214 [==============================] - 87s 406ms/step - loss: 0.0343 - accuracy: 0.9944 - val_loss: 0.6309 - val_accuracy: 0.9557\n",
      "\n",
      "Epoch 00099: saving model to /kaggle/working/training/cp.ckpt\n",
      "Epoch 100/100\n",
      "214/214 [==============================] - 87s 406ms/step - loss: 0.0149 - accuracy: 0.9973 - val_loss: 0.6632 - val_accuracy: 0.9560\n",
      "\n",
      "Epoch 00100: saving model to /kaggle/working/training/cp.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f235b65d990>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "weights = {0:1, 1:8}\n",
    "#model.fit(train_features, train_target,  class_weight=weights,validation_split=0.3,batch_size = 64,epochs=70)\n",
    "\n",
    "makeModel = myModel()\n",
    "\n",
    "if os.path.exists('/kaggle/working/training'):\n",
    "    os.rmdir('/kaggle/working/training')\n",
    "os.mkdir('/kaggle/working/training')\n",
    "\n",
    "path_checkpoint = \"/kaggle/working/training/cp.ckpt\"\n",
    "\n",
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath=path_checkpoint,\\\n",
    "                                                 save_weights_only=True,\\\n",
    "                                                 verbose=1)\n",
    "#model.fit(train_features, train_target,validation_split=0.3,batch_size = 64,epochs=45)\n",
    "\n",
    "makeModel.fit(train_features, \\\n",
    "          train_target,  \\\n",
    "          epochs=100,\\\n",
    "          validation_split = 0.3,\\\n",
    "          class_weight=weights,\\\n",
    "          batch_size=64,\\\n",
    "          callbacks=[callback]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3f951a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T11:59:40.583777Z",
     "iopub.status.busy": "2023-01-31T11:59:40.583245Z",
     "iopub.status.idle": "2023-01-31T11:59:40.588186Z",
     "shell.execute_reply": "2023-01-31T11:59:40.587244Z"
    },
    "papermill": {
     "duration": 1.495233,
     "end_time": "2023-01-31T11:59:40.590408",
     "exception": false,
     "start_time": "2023-01-31T11:59:39.095175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#model.save(\"/kaggle/working/trained_model_breast_cancer3.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df12475d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T11:59:43.390787Z",
     "iopub.status.busy": "2023-01-31T11:59:43.390028Z",
     "iopub.status.idle": "2023-01-31T11:59:43.394071Z",
     "shell.execute_reply": "2023-01-31T11:59:43.393249Z"
    },
    "papermill": {
     "duration": 1.464363,
     "end_time": "2023-01-31T11:59:43.396248",
     "exception": false,
     "start_time": "2023-01-31T11:59:41.931885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "#savedModel = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a991891",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T11:59:46.183175Z",
     "iopub.status.busy": "2023-01-31T11:59:46.182449Z",
     "iopub.status.idle": "2023-01-31T11:59:51.070010Z",
     "shell.execute_reply": "2023-01-31T11:59:51.068781Z"
    },
    "papermill": {
     "duration": 6.344265,
     "end_time": "2023-01-31T11:59:51.072905",
     "exception": false,
     "start_time": "2023-01-31T11:59:44.728640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_features=[]\n",
    "for i in test['img_data']:\n",
    "    i=np.array(i)\n",
    "    test_features.append(i)\n",
    "test_features=np.array(test_features)\n",
    " \n",
    "\n",
    "    \n",
    "#featureTransform = test_features.reshape(len(test_features), 6400)\n",
    "scaler = MinMaxScaler()\n",
    "#featureTransform =scaler.fit_transform(featureTransform)\n",
    "norm_features= []\n",
    "for i in range(len(test_features)):\n",
    "    norm_features.append(scaler.fit_transform(test_features[i]))\n",
    "test_features=np.array(norm_features)\n",
    "\n",
    "\n",
    "#backTransform = featureTransform.reshape(len(test_features),80,80)\n",
    "test_features = test_features.reshape(len(test_features),95,95,1)\n",
    "\n",
    "\n",
    "\n",
    "test_target = np.array(test['cancer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fabde44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T11:59:53.954148Z",
     "iopub.status.busy": "2023-01-31T11:59:53.953535Z",
     "iopub.status.idle": "2023-01-31T12:00:12.381154Z",
     "shell.execute_reply": "2023-01-31T12:00:12.379896Z"
    },
    "papermill": {
     "duration": 19.879701,
     "end_time": "2023-01-31T12:00:12.384615",
     "exception": false,
     "start_time": "2023-01-31T11:59:52.504914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "262/262 - 13s - loss: 0.6710 - accuracy: 0.9545\n",
      "[0.6710231304168701, 0.9545345902442932]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-31 12:00:09.860300: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "My_model = myModel()\n",
    "My_model.load_weights(path_checkpoint)\n",
    "accuracy = My_model.evaluate(test_features, test_target, verbose=2)\n",
    "print(accuracy)\n",
    "\n",
    "My_model.save('/kaggle/working/my_model')\n",
    "#new_model = tf.keras.models.load_model('/kaggle/working/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "169c83b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T12:00:15.203721Z",
     "iopub.status.busy": "2023-01-31T12:00:15.203248Z",
     "iopub.status.idle": "2023-01-31T12:00:30.013385Z",
     "shell.execute_reply": "2023-01-31T12:00:30.011722Z"
    },
    "papermill": {
     "duration": 16.245149,
     "end_time": "2023-01-31T12:00:30.017061",
     "exception": false,
     "start_time": "2023-01-31T12:00:13.771912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('/kaggle/working/my_model')\n",
    "pred = new_model.predict(test_features)\n",
    "bin_pred = []\n",
    "for i in pred:\n",
    "    if i>=0.5:\n",
    "        bin_pred.append(1)\n",
    "    else:\n",
    "        bin_pred.append(0)\n",
    "bin_pred = np.array(bin_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57f54573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T12:00:33.007832Z",
     "iopub.status.busy": "2023-01-31T12:00:33.007364Z",
     "iopub.status.idle": "2023-01-31T12:00:33.028253Z",
     "shell.execute_reply": "2023-01-31T12:00:33.026684Z"
    },
    "papermill": {
     "duration": 1.583533,
     "end_time": "2023-01-31T12:00:33.031108",
     "exception": false,
     "start_time": "2023-01-31T12:00:31.447575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9545346062052505\n",
      "0.9960134545907562 0.0113314447592068\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "acc = sklearn.metrics.accuracy_score(test_target, bin_pred)\n",
    "print(acc)\n",
    "\n",
    "countzero=0\n",
    "countone=0\n",
    "countzerot=0\n",
    "countonet=0\n",
    "for i, j in zip(test_target, bin_pred):\n",
    "    if i==0 and j==0:\n",
    "        countzero+=1\n",
    "    if i==1 and j==1:\n",
    "        countone+=1\n",
    "    if i==1:\n",
    "        countonet+=1\n",
    "    if i==0:\n",
    "        countzerot+=1\n",
    "print(countzero/countzerot,countone/countonet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a5a83bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T12:00:35.974377Z",
     "iopub.status.busy": "2023-01-31T12:00:35.973946Z",
     "iopub.status.idle": "2023-01-31T12:00:35.984233Z",
     "shell.execute_reply": "2023-01-31T12:00:35.982919Z"
    },
    "papermill": {
     "duration": 1.468437,
     "end_time": "2023-01-31T12:00:35.986558",
     "exception": false,
     "start_time": "2023-01-31T12:00:34.518121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02056555269922879\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives )\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives )\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "\n",
    "print(f1_m(test_target,bin_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51ae7435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T12:00:38.796176Z",
     "iopub.status.busy": "2023-01-31T12:00:38.795427Z",
     "iopub.status.idle": "2023-01-31T12:01:03.066702Z",
     "shell.execute_reply": "2023-01-31T12:01:03.065361Z"
    },
    "papermill": {
     "duration": 25.725793,
     "end_time": "2023-01-31T12:01:03.069778",
     "exception": false,
     "start_time": "2023-01-31T12:00:37.343985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:00<00:00, 10.64it/s]\n"
     ]
    }
   ],
   "source": [
    "datasetPath = '/kaggle/input/rsna-breast-cancer-detection/test.csv'\n",
    "imgPath = '/kaggle/input/rsna-breast-cancer-detection/test_images/'\n",
    "\n",
    "testImgData = dcmToPix(datasetPath, imgPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43c2936a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T12:01:05.929704Z",
     "iopub.status.busy": "2023-01-31T12:01:05.928857Z",
     "iopub.status.idle": "2023-01-31T12:01:05.948380Z",
     "shell.execute_reply": "2023-01-31T12:01:05.946716Z"
    },
    "papermill": {
     "duration": 1.481993,
     "end_time": "2023-01-31T12:01:05.951793",
     "exception": false,
     "start_time": "2023-01-31T12:01:04.469800",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datacancer = pd.read_csv(datasetPath)\n",
    "imgDataFrame = {'img_data':testImgData}\n",
    "imgData2 = pd.DataFrame(imgDataFrame)\n",
    "testImgData=imgData2\n",
    "imgdata_shuff = testImgData.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00266616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T12:01:08.873814Z",
     "iopub.status.busy": "2023-01-31T12:01:08.873410Z",
     "iopub.status.idle": "2023-01-31T12:01:08.886632Z",
     "shell.execute_reply": "2023-01-31T12:01:08.885505Z"
    },
    "papermill": {
     "duration": 1.473378,
     "end_time": "2023-01-31T12:01:08.889667",
     "exception": false,
     "start_time": "2023-01-31T12:01:07.416289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 11229.73it/s]\n"
     ]
    }
   ],
   "source": [
    "imgDataList=[]\n",
    "for j in tqdm(imgdata_shuff['img_data']):\n",
    "    imgDataList.append(random_rotate(j))\n",
    "imgdata_shuff['img_data'] = imgDataList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a7ee072",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T12:01:11.700003Z",
     "iopub.status.busy": "2023-01-31T12:01:11.699179Z",
     "iopub.status.idle": "2023-01-31T12:01:11.746119Z",
     "shell.execute_reply": "2023-01-31T12:01:11.745127Z"
    },
    "papermill": {
     "duration": 1.509248,
     "end_time": "2023-01-31T12:01:11.748719",
     "exception": false,
     "start_time": "2023-01-31T12:01:10.239471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test=imgdata_shuff\n",
    "\n",
    "\n",
    "test_features=[]\n",
    "for i in test['img_data']:\n",
    "    i=np.array(i)\n",
    "    test_features.append(i)\n",
    "test_features=np.array(test_features)\n",
    " \n",
    "#featureTransform = test_features.reshape(len(test_features), 6400)\n",
    "scaler = MinMaxScaler()\n",
    "#featureTransform =scaler.fit_transform(featureTransform)\n",
    "norm_features= []\n",
    "for i in range(len(test_features)):\n",
    "    norm_features.append(scaler.fit_transform(test_features[i]))\n",
    "test_features=np.array(norm_features)\n",
    "\n",
    "\n",
    "#backTransform = featureTransform.reshape(len(test_features),80,80)\n",
    "test_features = test_features.reshape(len(test_features),95,95,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06dd09d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T12:01:14.619653Z",
     "iopub.status.busy": "2023-01-31T12:01:14.618854Z",
     "iopub.status.idle": "2023-01-31T12:01:14.724274Z",
     "shell.execute_reply": "2023-01-31T12:01:14.722596Z"
    },
    "papermill": {
     "duration": 1.626487,
     "end_time": "2023-01-31T12:01:14.727470",
     "exception": false,
     "start_time": "2023-01-31T12:01:13.100983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "pred = new_model.predict(test_features)\n",
    "bin_pred = []\n",
    "for i in pred:\n",
    "    if i>=0.5:\n",
    "        bin_pred.append(1)\n",
    "    else:\n",
    "        bin_pred.append(0)\n",
    "bin_pred = np.array(bin_pred)\n",
    "print(bin_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5522d386",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-31T12:01:17.666444Z",
     "iopub.status.busy": "2023-01-31T12:01:17.665697Z",
     "iopub.status.idle": "2023-01-31T12:01:17.684160Z",
     "shell.execute_reply": "2023-01-31T12:01:17.682684Z"
    },
    "papermill": {
     "duration": 1.491078,
     "end_time": "2023-01-31T12:01:17.687242",
     "exception": false,
     "start_time": "2023-01-31T12:01:16.196164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  prediction_id  cancer\n",
      "0       10008_L       0\n",
      "1       10008_L       0\n",
      "2       10008_R       0\n",
      "3       10008_R       0\n"
     ]
    }
   ],
   "source": [
    "testData = pd.read_csv('/kaggle/input/rsna-breast-cancer-detection/test.csv')\n",
    "\n",
    "submissionFrame={'prediction_id':testData['prediction_id'],'cancer':bin_pred}\n",
    "submission = pd.DataFrame(submissionFrame)\n",
    "print(submission)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8752.880293,
   "end_time": "2023-01-31T12:01:22.217830",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-01-31T09:35:29.337537",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
