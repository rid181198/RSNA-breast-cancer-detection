{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32eb4d54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:43:22.053126Z",
     "iopub.status.busy": "2023-02-14T00:43:22.051984Z",
     "iopub.status.idle": "2023-02-14T00:43:30.262624Z",
     "shell.execute_reply": "2023-02-14T00:43:30.261446Z"
    },
    "papermill": {
     "duration": 8.220893,
     "end_time": "2023-02-14T00:43:30.265637",
     "exception": false,
     "start_time": "2023-02-14T00:43:22.044744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "from PIL import Image as im\n",
    "import random\n",
    "from scipy import ndimage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b4b17ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:43:30.277170Z",
     "iopub.status.busy": "2023-02-14T00:43:30.276070Z",
     "iopub.status.idle": "2023-02-14T00:43:44.763135Z",
     "shell.execute_reply": "2023-02-14T00:43:44.761875Z"
    },
    "papermill": {
     "duration": 14.495945,
     "end_time": "2023-02-14T00:43:44.766185",
     "exception": false,
     "start_time": "2023-02-14T00:43:30.270240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dicomsdl\r\n",
      "  Downloading dicomsdl-0.109.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: dicomsdl\r\n",
      "Successfully installed dicomsdl-0.109.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install dicomsdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c0fcc8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:43:44.779654Z",
     "iopub.status.busy": "2023-02-14T00:43:44.779245Z",
     "iopub.status.idle": "2023-02-14T00:43:44.787117Z",
     "shell.execute_reply": "2023-02-14T00:43:44.785888Z"
    },
    "papermill": {
     "duration": 0.017597,
     "end_time": "2023-02-14T00:43:44.789493",
     "exception": false,
     "start_time": "2023-02-14T00:43:44.771896",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#!pip install /kaggle/input/rsnapacks/dicomsdl-0.109.1-cp36-cp36m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "#import pydicom as dicom\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from PIL import Image as im\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from joblib import Parallel, delayed\n",
    "import gc\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09209d85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:43:44.801973Z",
     "iopub.status.busy": "2023-02-14T00:43:44.801576Z",
     "iopub.status.idle": "2023-02-14T00:43:44.823712Z",
     "shell.execute_reply": "2023-02-14T00:43:44.822545Z"
    },
    "papermill": {
     "duration": 0.031378,
     "end_time": "2023-02-14T00:43:44.826328",
     "exception": false,
     "start_time": "2023-02-14T00:43:44.794950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasetPath = '/kaggle/input/rsna-breast-cancer-detection/train.csv'\n",
    "imgPath = '/kaggle/input/rsna-breast-cancer-detection/train_images/'\n",
    "\n",
    "def crop(sideName, imgName):\n",
    "    \"\"\"\n",
    "    This function is used to crop the breast images. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :sideName = Laterality of breast if it is right or left\n",
    "    :imgName = Image pixel data of the DCM images\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    if sideName == 'L':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col==0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = max(colind)\n",
    "        imgName = imgName[0:512,0:crop_size]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "        \n",
    "    if sideName == 'R':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col!=0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = min(colind)\n",
    "        imgName = imgName[0:512,crop_size:512]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "    \n",
    "    return imgName    \n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "def crop_reverse(sideName, imgName):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to crop the breast images but in the reverse order.\n",
    "    Because the laterality is defined wrongly for some images. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :sideName = Laterality of breast if it is right or left\n",
    "    :imgName = Image pixel data of the DCM images\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if sideName == 'R':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col==0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = max(colind)\n",
    "        imgName = imgName[0:512,0:crop_size]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "        \n",
    "    if sideName == 'L':\n",
    "        colind=[]\n",
    "        for r,row in enumerate(imgName):\n",
    "            for c,col in enumerate(row):\n",
    "                if col!=0:\n",
    "                    colind.append(c)\n",
    "                    break\n",
    "        crop_size = min(colind)\n",
    "        imgName = imgName[0:512,crop_size:512]\n",
    "        imgName = cv2.resize(imgName,(128,128))\n",
    "    \n",
    "    return imgName    \n",
    "\n",
    "    gc.collect()\n",
    "    \n",
    "\n",
    "def img_process(i,filename,sides):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to process the images which will be used for the training/test dataset. It takes three arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :i = Index of the image in the dataframe\n",
    "    :filename = Path of the image\n",
    "    :sides = List of all images' laterality\n",
    "    \n",
    "    Output:-\n",
    "    :return = Output after cropping the image.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    #ds = dicom.dcmread(filename)\n",
    "    dsraw = dicom.open(filename)\n",
    "    ds = dsraw.pixelData()\n",
    "    \n",
    "    ds = (ds - ds.min()) / (ds.max() - ds.min())\n",
    "    if dsraw.PhotometricInterpretation == \"MONOCHROME1\":  \n",
    "        ds = 1 - ds\n",
    "    ds = (ds * 255).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    #ds = cv2.normalize(ds, None, 0, 1.0, cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    ds = cv2.resize(ds,(512,512))\n",
    "    \n",
    "    #ds = np.where(ds >= 0.999, 0,ds)\n",
    "    \n",
    "    try:\n",
    "        ds = np.array(crop(sides[i], ds))   \n",
    "    except:\n",
    "        ds = np.array(crop_reverse(sides[i], ds))\n",
    "    \n",
    "\n",
    "    #train_data.loc[i,'img_data'] = [img_fin]\n",
    "    #train_data.to_csv('/kaggle/working/training_img_data.csv') \n",
    "    return ds\n",
    "    gc.collect()\n",
    "\n",
    "def dcmToPix(datasetPath, imgPath):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is used to process all the images which will be used for the training/test dataset. It takes two arguments.\n",
    "    \n",
    "    Input:-\n",
    "    :datasetPath = Path of the cancer dataset\n",
    "    :imgPath = Path of the image dataset\n",
    "   \n",
    "    Output:-\n",
    "    :return = Array of all the processed images\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    dataset = pd.read_csv(datasetPath)\n",
    "    \n",
    "    patient_ids = dataset['patient_id']\n",
    "    image_ids = dataset['image_id']\n",
    "    sides  = dataset['laterality']\n",
    "\n",
    "    imgData = []\n",
    "\n",
    "    for pi, ii, leng in zip(patient_ids, image_ids, range(len(patient_ids))):\n",
    "        imgData.append(imgPath + str(pi) + '/' + str(ii) + '.dcm')\n",
    "\n",
    "    dataset['img_data'] = \" \"\n",
    "    \n",
    "    result = Parallel(n_jobs=128)(\\\n",
    "    delayed(img_process)(i, fname, sides) for i, fname in zip(range(len(imgData)),tqdm(imgData))\\\n",
    "    )\n",
    "    \n",
    "    dataset['img_data'] = result\n",
    "    dataset.to_pickle('imgData.pkl' )\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fefcc31b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-02-14T00:43:44.838590Z",
     "iopub.status.busy": "2023-02-14T00:43:44.838205Z",
     "iopub.status.idle": "2023-02-14T00:44:06.638549Z",
     "shell.execute_reply": "2023-02-14T00:44:06.637212Z"
    },
    "papermill": {
     "duration": 21.810067,
     "end_time": "2023-02-14T00:44:06.641796",
     "exception": false,
     "start_time": "2023-02-14T00:43:44.831729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 00:43:49.547658: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "with (open('/kaggle/input/processed/imgDataNew.pkl', \"rb\")) as openfile:\n",
    "     imgData = pickle.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e4c2c39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:44:06.654353Z",
     "iopub.status.busy": "2023-02-14T00:44:06.653942Z",
     "iopub.status.idle": "2023-02-14T00:44:07.996727Z",
     "shell.execute_reply": "2023-02-14T00:44:07.995519Z"
    },
    "papermill": {
     "duration": 1.351989,
     "end_time": "2023-02-14T00:44:07.999247",
     "exception": false,
     "start_time": "2023-02-14T00:44:06.647258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train,test = train_test_split(imgData, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "train_target = np.array(train['cancer'])\n",
    "train_features=[]\n",
    "for i in train['img_data_process']:\n",
    "    train_features.append(i)\n",
    "train_features=tf.convert_to_tensor(train_features)\n",
    "\n",
    "test_target = np.array(test['cancer'])\n",
    "test_features=[]\n",
    "for i in test['img_data_process']:\n",
    "    test_features.append(i)\n",
    "test_features=tf.convert_to_tensor(test_features)\n",
    "test_target = np.array(test['cancer'])\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ac0e89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:44:08.012593Z",
     "iopub.status.busy": "2023-02-14T00:44:08.011452Z",
     "iopub.status.idle": "2023-02-14T00:44:16.691321Z",
     "shell.execute_reply": "2023-02-14T00:44:16.689850Z"
    },
    "papermill": {
     "duration": 8.689466,
     "end_time": "2023-02-14T00:44:16.694169",
     "exception": false,
     "start_time": "2023-02-14T00:44:08.004703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "71688192/71686520 [==============================] - 3s 0us/step\n",
      "71696384/71686520 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import * #Efficient Net included here\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras import optimizers\n",
    "import tensorflow as tf\n",
    "#Use this to check if the GPU is configured correctly\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "input_shape=(95,95,3)\n",
    "conv_base = EfficientNetB4(weights=\"imagenet\", include_top=False, input_shape=input_shape)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
    "#avoid overfitting\n",
    "model.add(layers.Dropout(0.2, name=\"dropout_out\"))\n",
    "# Set NUMBER_OF_CLASSES to the number of your final predictions.\n",
    "model.add(layers.Dense(1, activation=\"sigmoid\", name=\"fc_out\"))\n",
    "conv_base.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fd2a950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:44:16.714322Z",
     "iopub.status.busy": "2023-02-14T00:44:16.713873Z",
     "iopub.status.idle": "2023-02-14T00:44:16.760690Z",
     "shell.execute_reply": "2023-02-14T00:44:16.758629Z"
    },
    "papermill": {
     "duration": 0.061042,
     "end_time": "2023-02-14T00:44:16.764700",
     "exception": false,
     "start_time": "2023-02-14T00:44:16.703658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "efficientnetb4 (Functional)  (None, 3, 3, 1792)        17673823  \n",
      "_________________________________________________________________\n",
      "gap (GlobalMaxPooling2D)     (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_out (Dropout)        (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "fc_out (Dense)               (None, 1)                 1793      \n",
      "=================================================================\n",
      "Total params: 17,675,616\n",
      "Trainable params: 1,793\n",
      "Non-trainable params: 17,673,823\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(\\\n",
    "    loss=\"binary_crossentropy\",\\\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\\\n",
    "    metrics=[\"acc\"],\\\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98407af2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:44:16.784212Z",
     "iopub.status.busy": "2023-02-14T00:44:16.783753Z",
     "iopub.status.idle": "2023-02-14T00:54:37.381442Z",
     "shell.execute_reply": "2023-02-14T00:54:37.380094Z"
    },
    "papermill": {
     "duration": 620.675868,
     "end_time": "2023-02-14T00:54:37.449585",
     "exception": false,
     "start_time": "2023-02-14T00:44:16.773717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-14 00:45:01.756940: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1190/1190 [==============================] - 539s 441ms/step - loss: 0.6032 - acc: 0.7483 - val_loss: 0.5344 - val_acc: 0.7826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f5828b3b250>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    shear_range=0.2,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)\n",
    "datagen.fit(train_features)\n",
    "\n",
    "\n",
    "#weights = {0:1, 1:8}\n",
    "model.fit(datagen.flow(train_features, train_target, batch_size=32,\\\n",
    "         subset='training'),\\\n",
    "         validation_data=datagen.flow(train_features, train_target,\\\n",
    "         batch_size=8, subset='validation'),\\\n",
    "         steps_per_epoch=len(train_features) / 32, epochs=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1ae9f85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:54:37.586186Z",
     "iopub.status.busy": "2023-02-14T00:54:37.585320Z",
     "iopub.status.idle": "2023-02-14T00:54:38.346240Z",
     "shell.execute_reply": "2023-02-14T00:54:38.344902Z"
    },
    "papermill": {
     "duration": 0.83309,
     "end_time": "2023-02-14T00:54:38.349317",
     "exception": false,
     "start_time": "2023-02-14T00:54:37.516227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "model.save(\"/kaggle/working/trained_model_breast_cancer3.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e697fc44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:54:38.484982Z",
     "iopub.status.busy": "2023-02-14T00:54:38.484172Z",
     "iopub.status.idle": "2023-02-14T00:54:38.489367Z",
     "shell.execute_reply": "2023-02-14T00:54:38.488231Z"
    },
    "papermill": {
     "duration": 0.075679,
     "end_time": "2023-02-14T00:54:38.491954",
     "exception": false,
     "start_time": "2023-02-14T00:54:38.416275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from tensorflow import keras\n",
    "#savedModel = keras.models.load_model(\"/kaggle/input/pre-trained-model-of-breast-cancer/trained_model_breast_cancer3.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4768708d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:54:38.630169Z",
     "iopub.status.busy": "2023-02-14T00:54:38.628861Z",
     "iopub.status.idle": "2023-02-14T00:57:59.602028Z",
     "shell.execute_reply": "2023-02-14T00:57:59.600625Z"
    },
    "papermill": {
     "duration": 201.046359,
     "end_time": "2023-02-14T00:57:59.605286",
     "exception": false,
     "start_time": "2023-02-14T00:54:38.558927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "test_datagen.fit(test_features)\n",
    "\n",
    "test_generator = test_datagen.flow(test_features, batch_size=1)\n",
    "pred = model.predict(test_features)\n",
    "bin_pred = []\n",
    "for i in pred:\n",
    "    if i>=0.5:\n",
    "        bin_pred.append(1)\n",
    "    else:\n",
    "        bin_pred.append(0)\n",
    "bin_pred = np.array(bin_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2442cf67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:57:59.745098Z",
     "iopub.status.busy": "2023-02-14T00:57:59.744250Z",
     "iopub.status.idle": "2023-02-14T00:57:59.777382Z",
     "shell.execute_reply": "2023-02-14T00:57:59.775893Z"
    },
    "papermill": {
     "duration": 0.107038,
     "end_time": "2023-02-14T00:57:59.780035",
     "exception": false,
     "start_time": "2023-02-14T00:57:59.672997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6925762587284087\n",
      "0.822198108820338 0.20414719626168223\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "acc = sklearn.metrics.accuracy_score(test_target, bin_pred)\n",
    "print(acc)\n",
    "\n",
    "countzero=0\n",
    "countone=0\n",
    "countzerot=0\n",
    "countonet=0\n",
    "for i, j in zip(test_target, bin_pred):\n",
    "    if i==0 and j==0:\n",
    "        countzero+=1\n",
    "    if i==1 and j==1:\n",
    "        countone+=1\n",
    "    if i==1:\n",
    "        countonet+=1\n",
    "    if i==0:\n",
    "        countzerot+=1\n",
    "print(countzero/countzerot,countone/countonet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "390fa529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T00:57:59.916691Z",
     "iopub.status.busy": "2023-02-14T00:57:59.915408Z",
     "iopub.status.idle": "2023-02-14T00:57:59.927321Z",
     "shell.execute_reply": "2023-02-14T00:57:59.925892Z"
    },
    "papermill": {
     "duration": 0.082602,
     "end_time": "2023-02-14T00:57:59.929624",
     "exception": false,
     "start_time": "2023-02-14T00:57:59.847022",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2178588125292193\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = np.sum(np.round(np.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives )\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = np.sum(np.round(np.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = np.sum(np.round(np.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives )\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))\n",
    "\n",
    "\n",
    "print(f1_m(test_target,bin_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 890.77962,
   "end_time": "2023-02-14T00:58:03.718414",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-14T00:43:12.938794",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
